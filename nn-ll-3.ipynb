{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Multi class classification using PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "72uHXNwevFan",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:25.952311Z",
     "end_time": "2023-04-19T00:18:26.027306Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tF\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ],
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J_kuRTECv6JN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4b624373-38d8-4c2b-a723-6294287a85d4",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:25.967308Z",
     "end_time": "2023-04-19T00:18:26.075306Z"
    }
   },
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          shuffle=False)"
   ],
   "execution_count": 63,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualize some examples from the dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x300 with 5 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    ax[i].imshow(train_dataset.data[i], cmap='gray')\n",
    "    ax[i].set_title(f'Label: {train_dataset.targets[i]}')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:26.010308Z",
     "end_time": "2023-04-19T00:18:26.834012Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKnQEpfSwLmP",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:26.836011Z",
     "end_time": "2023-04-19T00:18:26.849012Z"
    }
   },
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:26.850014Z",
     "end_time": "2023-04-19T00:18:26.882065Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define the loss function and the optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V9u2Yg0IyHgj",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:26.866742Z",
     "end_time": "2023-04-19T00:18:26.882065Z"
    }
   },
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFqyw6_ByLTu",
    "outputId": "bea5a85e-9fec-4fe2-aecf-b7b72adeb8a5",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:18:26.884068Z",
     "end_time": "2023-04-19T00:20:46.587509Z"
    }
   },
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch: [% d/% d], Step: [% d/% d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, (i + 1) // batch_size,\n",
    "                     len(train_dataset) // batch_size, loss.data))"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 1/ 5], Step: [ 1/ 600], Loss: 2.2282\n",
      "Epoch: [ 1/ 5], Step: [ 2/ 600], Loss: 2.0666\n",
      "Epoch: [ 1/ 5], Step: [ 3/ 600], Loss: 2.4843\n",
      "Epoch: [ 1/ 5], Step: [ 4/ 600], Loss: 2.1261\n",
      "Epoch: [ 1/ 5], Step: [ 5/ 600], Loss: 1.8883\n",
      "Epoch: [ 1/ 5], Step: [ 6/ 600], Loss: 0.9226\n",
      "Epoch: [ 1/ 5], Step: [ 7/ 600], Loss: 1.6433\n",
      "Epoch: [ 1/ 5], Step: [ 8/ 600], Loss: 1.7303\n",
      "Epoch: [ 1/ 5], Step: [ 9/ 600], Loss: 1.3454\n",
      "Epoch: [ 1/ 5], Step: [ 10/ 600], Loss: 2.1110\n",
      "Epoch: [ 1/ 5], Step: [ 11/ 600], Loss: 1.4458\n",
      "Epoch: [ 1/ 5], Step: [ 12/ 600], Loss: 2.2124\n",
      "Epoch: [ 1/ 5], Step: [ 13/ 600], Loss: 1.5544\n",
      "Epoch: [ 1/ 5], Step: [ 14/ 600], Loss: 1.9796\n",
      "Epoch: [ 1/ 5], Step: [ 15/ 600], Loss: 1.6980\n",
      "Epoch: [ 1/ 5], Step: [ 16/ 600], Loss: 1.0392\n",
      "Epoch: [ 1/ 5], Step: [ 17/ 600], Loss: 1.7927\n",
      "Epoch: [ 1/ 5], Step: [ 18/ 600], Loss: 0.8956\n",
      "Epoch: [ 1/ 5], Step: [ 19/ 600], Loss: 1.2341\n",
      "Epoch: [ 1/ 5], Step: [ 20/ 600], Loss: 1.7038\n",
      "Epoch: [ 1/ 5], Step: [ 21/ 600], Loss: 1.3665\n",
      "Epoch: [ 1/ 5], Step: [ 22/ 600], Loss: 1.1765\n",
      "Epoch: [ 1/ 5], Step: [ 23/ 600], Loss: 1.1272\n",
      "Epoch: [ 1/ 5], Step: [ 24/ 600], Loss: 2.1925\n",
      "Epoch: [ 1/ 5], Step: [ 25/ 600], Loss: 0.5924\n",
      "Epoch: [ 1/ 5], Step: [ 26/ 600], Loss: 0.8527\n",
      "Epoch: [ 1/ 5], Step: [ 27/ 600], Loss: 1.7026\n",
      "Epoch: [ 1/ 5], Step: [ 28/ 600], Loss: 1.4394\n",
      "Epoch: [ 1/ 5], Step: [ 29/ 600], Loss: 0.7923\n",
      "Epoch: [ 1/ 5], Step: [ 30/ 600], Loss: 1.0137\n",
      "Epoch: [ 1/ 5], Step: [ 31/ 600], Loss: 1.1274\n",
      "Epoch: [ 1/ 5], Step: [ 32/ 600], Loss: 0.9498\n",
      "Epoch: [ 1/ 5], Step: [ 33/ 600], Loss: 1.2440\n",
      "Epoch: [ 1/ 5], Step: [ 34/ 600], Loss: 0.4408\n",
      "Epoch: [ 1/ 5], Step: [ 35/ 600], Loss: 1.8769\n",
      "Epoch: [ 1/ 5], Step: [ 36/ 600], Loss: 1.9052\n",
      "Epoch: [ 1/ 5], Step: [ 37/ 600], Loss: 0.6145\n",
      "Epoch: [ 1/ 5], Step: [ 38/ 600], Loss: 0.4120\n",
      "Epoch: [ 1/ 5], Step: [ 39/ 600], Loss: 0.7969\n",
      "Epoch: [ 1/ 5], Step: [ 40/ 600], Loss: 0.5736\n",
      "Epoch: [ 1/ 5], Step: [ 41/ 600], Loss: 0.6946\n",
      "Epoch: [ 1/ 5], Step: [ 42/ 600], Loss: 0.7111\n",
      "Epoch: [ 1/ 5], Step: [ 43/ 600], Loss: 0.4476\n",
      "Epoch: [ 1/ 5], Step: [ 44/ 600], Loss: 0.3095\n",
      "Epoch: [ 1/ 5], Step: [ 45/ 600], Loss: 0.8210\n",
      "Epoch: [ 1/ 5], Step: [ 46/ 600], Loss: 4.3513\n",
      "Epoch: [ 1/ 5], Step: [ 47/ 600], Loss: 0.5792\n",
      "Epoch: [ 1/ 5], Step: [ 48/ 600], Loss: 1.4511\n",
      "Epoch: [ 1/ 5], Step: [ 49/ 600], Loss: 0.7521\n",
      "Epoch: [ 1/ 5], Step: [ 50/ 600], Loss: 0.8001\n",
      "Epoch: [ 1/ 5], Step: [ 51/ 600], Loss: 0.7411\n",
      "Epoch: [ 1/ 5], Step: [ 52/ 600], Loss: 0.5272\n",
      "Epoch: [ 1/ 5], Step: [ 53/ 600], Loss: 0.6077\n",
      "Epoch: [ 1/ 5], Step: [ 54/ 600], Loss: 0.2047\n",
      "Epoch: [ 1/ 5], Step: [ 55/ 600], Loss: 0.8755\n",
      "Epoch: [ 1/ 5], Step: [ 56/ 600], Loss: 0.5333\n",
      "Epoch: [ 1/ 5], Step: [ 57/ 600], Loss: 0.2804\n",
      "Epoch: [ 1/ 5], Step: [ 58/ 600], Loss: 1.6625\n",
      "Epoch: [ 1/ 5], Step: [ 59/ 600], Loss: 0.6279\n",
      "Epoch: [ 1/ 5], Step: [ 60/ 600], Loss: 1.1643\n",
      "Epoch: [ 1/ 5], Step: [ 61/ 600], Loss: 1.0114\n",
      "Epoch: [ 1/ 5], Step: [ 62/ 600], Loss: 0.2899\n",
      "Epoch: [ 1/ 5], Step: [ 63/ 600], Loss: 0.2776\n",
      "Epoch: [ 1/ 5], Step: [ 64/ 600], Loss: 2.0301\n",
      "Epoch: [ 1/ 5], Step: [ 65/ 600], Loss: 1.1448\n",
      "Epoch: [ 1/ 5], Step: [ 66/ 600], Loss: 0.2112\n",
      "Epoch: [ 1/ 5], Step: [ 67/ 600], Loss: 0.1889\n",
      "Epoch: [ 1/ 5], Step: [ 68/ 600], Loss: 0.1884\n",
      "Epoch: [ 1/ 5], Step: [ 69/ 600], Loss: 0.4184\n",
      "Epoch: [ 1/ 5], Step: [ 70/ 600], Loss: 0.4436\n",
      "Epoch: [ 1/ 5], Step: [ 71/ 600], Loss: 0.0941\n",
      "Epoch: [ 1/ 5], Step: [ 72/ 600], Loss: 0.3866\n",
      "Epoch: [ 1/ 5], Step: [ 73/ 600], Loss: 0.3128\n",
      "Epoch: [ 1/ 5], Step: [ 74/ 600], Loss: 0.3595\n",
      "Epoch: [ 1/ 5], Step: [ 75/ 600], Loss: 0.7528\n",
      "Epoch: [ 1/ 5], Step: [ 76/ 600], Loss: 0.9696\n",
      "Epoch: [ 1/ 5], Step: [ 77/ 600], Loss: 0.1889\n",
      "Epoch: [ 1/ 5], Step: [ 78/ 600], Loss: 1.3153\n",
      "Epoch: [ 1/ 5], Step: [ 79/ 600], Loss: 0.3298\n",
      "Epoch: [ 1/ 5], Step: [ 80/ 600], Loss: 0.0579\n",
      "Epoch: [ 1/ 5], Step: [ 81/ 600], Loss: 1.0153\n",
      "Epoch: [ 1/ 5], Step: [ 82/ 600], Loss: 1.1715\n",
      "Epoch: [ 1/ 5], Step: [ 83/ 600], Loss: 0.3081\n",
      "Epoch: [ 1/ 5], Step: [ 84/ 600], Loss: 0.3518\n",
      "Epoch: [ 1/ 5], Step: [ 85/ 600], Loss: 0.0582\n",
      "Epoch: [ 1/ 5], Step: [ 86/ 600], Loss: 1.1494\n",
      "Epoch: [ 1/ 5], Step: [ 87/ 600], Loss: 1.1277\n",
      "Epoch: [ 1/ 5], Step: [ 88/ 600], Loss: 1.0234\n",
      "Epoch: [ 1/ 5], Step: [ 89/ 600], Loss: 0.2468\n",
      "Epoch: [ 1/ 5], Step: [ 90/ 600], Loss: 0.3097\n",
      "Epoch: [ 1/ 5], Step: [ 91/ 600], Loss: 0.4092\n",
      "Epoch: [ 1/ 5], Step: [ 92/ 600], Loss: 1.1147\n",
      "Epoch: [ 1/ 5], Step: [ 93/ 600], Loss: 0.0509\n",
      "Epoch: [ 1/ 5], Step: [ 94/ 600], Loss: 0.6456\n",
      "Epoch: [ 1/ 5], Step: [ 95/ 600], Loss: 0.0431\n",
      "Epoch: [ 1/ 5], Step: [ 96/ 600], Loss: 0.4641\n",
      "Epoch: [ 1/ 5], Step: [ 97/ 600], Loss: 0.7554\n",
      "Epoch: [ 1/ 5], Step: [ 98/ 600], Loss: 0.0787\n",
      "Epoch: [ 1/ 5], Step: [ 99/ 600], Loss: 0.5833\n",
      "Epoch: [ 1/ 5], Step: [ 100/ 600], Loss: 0.1097\n",
      "Epoch: [ 1/ 5], Step: [ 101/ 600], Loss: 0.2095\n",
      "Epoch: [ 1/ 5], Step: [ 102/ 600], Loss: 0.4132\n",
      "Epoch: [ 1/ 5], Step: [ 103/ 600], Loss: 1.7952\n",
      "Epoch: [ 1/ 5], Step: [ 104/ 600], Loss: 2.7804\n",
      "Epoch: [ 1/ 5], Step: [ 105/ 600], Loss: 0.2834\n",
      "Epoch: [ 1/ 5], Step: [ 106/ 600], Loss: 1.8191\n",
      "Epoch: [ 1/ 5], Step: [ 107/ 600], Loss: 0.2682\n",
      "Epoch: [ 1/ 5], Step: [ 108/ 600], Loss: 1.1717\n",
      "Epoch: [ 1/ 5], Step: [ 109/ 600], Loss: 0.4976\n",
      "Epoch: [ 1/ 5], Step: [ 110/ 600], Loss: 1.0252\n",
      "Epoch: [ 1/ 5], Step: [ 111/ 600], Loss: 0.3131\n",
      "Epoch: [ 1/ 5], Step: [ 112/ 600], Loss: 0.1781\n",
      "Epoch: [ 1/ 5], Step: [ 113/ 600], Loss: 0.1446\n",
      "Epoch: [ 1/ 5], Step: [ 114/ 600], Loss: 0.0813\n",
      "Epoch: [ 1/ 5], Step: [ 115/ 600], Loss: 0.0080\n",
      "Epoch: [ 1/ 5], Step: [ 116/ 600], Loss: 0.0617\n",
      "Epoch: [ 1/ 5], Step: [ 117/ 600], Loss: 0.1404\n",
      "Epoch: [ 1/ 5], Step: [ 118/ 600], Loss: 0.0499\n",
      "Epoch: [ 1/ 5], Step: [ 119/ 600], Loss: 0.5078\n",
      "Epoch: [ 1/ 5], Step: [ 120/ 600], Loss: 0.5205\n",
      "Epoch: [ 1/ 5], Step: [ 121/ 600], Loss: 0.5416\n",
      "Epoch: [ 1/ 5], Step: [ 122/ 600], Loss: 1.5394\n",
      "Epoch: [ 1/ 5], Step: [ 123/ 600], Loss: 0.1659\n",
      "Epoch: [ 1/ 5], Step: [ 124/ 600], Loss: 1.7435\n",
      "Epoch: [ 1/ 5], Step: [ 125/ 600], Loss: 0.2905\n",
      "Epoch: [ 1/ 5], Step: [ 126/ 600], Loss: 1.2101\n",
      "Epoch: [ 1/ 5], Step: [ 127/ 600], Loss: 1.0652\n",
      "Epoch: [ 1/ 5], Step: [ 128/ 600], Loss: 0.0254\n",
      "Epoch: [ 1/ 5], Step: [ 129/ 600], Loss: 3.1132\n",
      "Epoch: [ 1/ 5], Step: [ 130/ 600], Loss: 1.1328\n",
      "Epoch: [ 1/ 5], Step: [ 131/ 600], Loss: 0.0246\n",
      "Epoch: [ 1/ 5], Step: [ 132/ 600], Loss: 0.1715\n",
      "Epoch: [ 1/ 5], Step: [ 133/ 600], Loss: 0.2506\n",
      "Epoch: [ 1/ 5], Step: [ 134/ 600], Loss: 0.2251\n",
      "Epoch: [ 1/ 5], Step: [ 135/ 600], Loss: 0.2441\n",
      "Epoch: [ 1/ 5], Step: [ 136/ 600], Loss: 0.0825\n",
      "Epoch: [ 1/ 5], Step: [ 137/ 600], Loss: 0.2177\n",
      "Epoch: [ 1/ 5], Step: [ 138/ 600], Loss: 0.8653\n",
      "Epoch: [ 1/ 5], Step: [ 139/ 600], Loss: 0.0407\n",
      "Epoch: [ 1/ 5], Step: [ 140/ 600], Loss: 2.1144\n",
      "Epoch: [ 1/ 5], Step: [ 141/ 600], Loss: 0.1274\n",
      "Epoch: [ 1/ 5], Step: [ 142/ 600], Loss: 0.2095\n",
      "Epoch: [ 1/ 5], Step: [ 143/ 600], Loss: 0.0343\n",
      "Epoch: [ 1/ 5], Step: [ 144/ 600], Loss: 1.5020\n",
      "Epoch: [ 1/ 5], Step: [ 145/ 600], Loss: 0.2322\n",
      "Epoch: [ 1/ 5], Step: [ 146/ 600], Loss: 0.4766\n",
      "Epoch: [ 1/ 5], Step: [ 147/ 600], Loss: 0.9706\n",
      "Epoch: [ 1/ 5], Step: [ 148/ 600], Loss: 0.2494\n",
      "Epoch: [ 1/ 5], Step: [ 149/ 600], Loss: 0.2257\n",
      "Epoch: [ 1/ 5], Step: [ 150/ 600], Loss: 0.6788\n",
      "Epoch: [ 1/ 5], Step: [ 151/ 600], Loss: 0.1896\n",
      "Epoch: [ 1/ 5], Step: [ 152/ 600], Loss: 2.2675\n",
      "Epoch: [ 1/ 5], Step: [ 153/ 600], Loss: 0.6294\n",
      "Epoch: [ 1/ 5], Step: [ 154/ 600], Loss: 0.1036\n",
      "Epoch: [ 1/ 5], Step: [ 155/ 600], Loss: 0.5439\n",
      "Epoch: [ 1/ 5], Step: [ 156/ 600], Loss: 0.4619\n",
      "Epoch: [ 1/ 5], Step: [ 157/ 600], Loss: 1.2540\n",
      "Epoch: [ 1/ 5], Step: [ 158/ 600], Loss: 0.2089\n",
      "Epoch: [ 1/ 5], Step: [ 159/ 600], Loss: 0.2528\n",
      "Epoch: [ 1/ 5], Step: [ 160/ 600], Loss: 0.4559\n",
      "Epoch: [ 1/ 5], Step: [ 161/ 600], Loss: 0.4205\n",
      "Epoch: [ 1/ 5], Step: [ 162/ 600], Loss: 1.0891\n",
      "Epoch: [ 1/ 5], Step: [ 163/ 600], Loss: 0.0716\n",
      "Epoch: [ 1/ 5], Step: [ 164/ 600], Loss: 0.1415\n",
      "Epoch: [ 1/ 5], Step: [ 165/ 600], Loss: 3.7494\n",
      "Epoch: [ 1/ 5], Step: [ 166/ 600], Loss: 1.1706\n",
      "Epoch: [ 1/ 5], Step: [ 167/ 600], Loss: 0.1635\n",
      "Epoch: [ 1/ 5], Step: [ 168/ 600], Loss: 1.1455\n",
      "Epoch: [ 1/ 5], Step: [ 169/ 600], Loss: 0.0538\n",
      "Epoch: [ 1/ 5], Step: [ 170/ 600], Loss: 2.7650\n",
      "Epoch: [ 1/ 5], Step: [ 171/ 600], Loss: 0.0589\n",
      "Epoch: [ 1/ 5], Step: [ 172/ 600], Loss: 0.0778\n",
      "Epoch: [ 1/ 5], Step: [ 173/ 600], Loss: 1.0212\n",
      "Epoch: [ 1/ 5], Step: [ 174/ 600], Loss: 0.1049\n",
      "Epoch: [ 1/ 5], Step: [ 175/ 600], Loss: 2.6416\n",
      "Epoch: [ 1/ 5], Step: [ 176/ 600], Loss: 0.0718\n",
      "Epoch: [ 1/ 5], Step: [ 177/ 600], Loss: 0.0939\n",
      "Epoch: [ 1/ 5], Step: [ 178/ 600], Loss: 0.0193\n",
      "Epoch: [ 1/ 5], Step: [ 179/ 600], Loss: 0.1262\n",
      "Epoch: [ 1/ 5], Step: [ 180/ 600], Loss: 1.3042\n",
      "Epoch: [ 1/ 5], Step: [ 181/ 600], Loss: 1.5262\n",
      "Epoch: [ 1/ 5], Step: [ 182/ 600], Loss: 1.4631\n",
      "Epoch: [ 1/ 5], Step: [ 183/ 600], Loss: 0.5080\n",
      "Epoch: [ 1/ 5], Step: [ 184/ 600], Loss: 0.0977\n",
      "Epoch: [ 1/ 5], Step: [ 185/ 600], Loss: 0.1451\n",
      "Epoch: [ 1/ 5], Step: [ 186/ 600], Loss: 0.2474\n",
      "Epoch: [ 1/ 5], Step: [ 187/ 600], Loss: 2.0452\n",
      "Epoch: [ 1/ 5], Step: [ 188/ 600], Loss: 0.0438\n",
      "Epoch: [ 1/ 5], Step: [ 189/ 600], Loss: 0.8569\n",
      "Epoch: [ 1/ 5], Step: [ 190/ 600], Loss: 1.2815\n",
      "Epoch: [ 1/ 5], Step: [ 191/ 600], Loss: 0.6793\n",
      "Epoch: [ 1/ 5], Step: [ 192/ 600], Loss: 0.8917\n",
      "Epoch: [ 1/ 5], Step: [ 193/ 600], Loss: 0.0151\n",
      "Epoch: [ 1/ 5], Step: [ 194/ 600], Loss: 0.8779\n",
      "Epoch: [ 1/ 5], Step: [ 195/ 600], Loss: 0.1575\n",
      "Epoch: [ 1/ 5], Step: [ 196/ 600], Loss: 0.1144\n",
      "Epoch: [ 1/ 5], Step: [ 197/ 600], Loss: 0.2583\n",
      "Epoch: [ 1/ 5], Step: [ 198/ 600], Loss: 0.4213\n",
      "Epoch: [ 1/ 5], Step: [ 199/ 600], Loss: 0.1399\n",
      "Epoch: [ 1/ 5], Step: [ 200/ 600], Loss: 0.1106\n",
      "Epoch: [ 1/ 5], Step: [ 201/ 600], Loss: 2.5354\n",
      "Epoch: [ 1/ 5], Step: [ 202/ 600], Loss: 0.1282\n",
      "Epoch: [ 1/ 5], Step: [ 203/ 600], Loss: 0.2535\n",
      "Epoch: [ 1/ 5], Step: [ 204/ 600], Loss: 0.2409\n",
      "Epoch: [ 1/ 5], Step: [ 205/ 600], Loss: 0.1219\n",
      "Epoch: [ 1/ 5], Step: [ 206/ 600], Loss: 0.0260\n",
      "Epoch: [ 1/ 5], Step: [ 207/ 600], Loss: 0.0316\n",
      "Epoch: [ 1/ 5], Step: [ 208/ 600], Loss: 4.5477\n",
      "Epoch: [ 1/ 5], Step: [ 209/ 600], Loss: 0.0164\n",
      "Epoch: [ 1/ 5], Step: [ 210/ 600], Loss: 0.1154\n",
      "Epoch: [ 1/ 5], Step: [ 211/ 600], Loss: 0.7669\n",
      "Epoch: [ 1/ 5], Step: [ 212/ 600], Loss: 0.1741\n",
      "Epoch: [ 1/ 5], Step: [ 213/ 600], Loss: 3.2126\n",
      "Epoch: [ 1/ 5], Step: [ 214/ 600], Loss: 3.4264\n",
      "Epoch: [ 1/ 5], Step: [ 215/ 600], Loss: 0.2190\n",
      "Epoch: [ 1/ 5], Step: [ 216/ 600], Loss: 0.9361\n",
      "Epoch: [ 1/ 5], Step: [ 217/ 600], Loss: 0.0778\n",
      "Epoch: [ 1/ 5], Step: [ 218/ 600], Loss: 3.2421\n",
      "Epoch: [ 1/ 5], Step: [ 219/ 600], Loss: 1.9509\n",
      "Epoch: [ 1/ 5], Step: [ 220/ 600], Loss: 0.0888\n",
      "Epoch: [ 1/ 5], Step: [ 221/ 600], Loss: 1.4409\n",
      "Epoch: [ 1/ 5], Step: [ 222/ 600], Loss: 1.4924\n",
      "Epoch: [ 1/ 5], Step: [ 223/ 600], Loss: 0.0673\n",
      "Epoch: [ 1/ 5], Step: [ 224/ 600], Loss: 0.0384\n",
      "Epoch: [ 1/ 5], Step: [ 225/ 600], Loss: 0.6093\n",
      "Epoch: [ 1/ 5], Step: [ 226/ 600], Loss: 0.0788\n",
      "Epoch: [ 1/ 5], Step: [ 227/ 600], Loss: 0.0099\n",
      "Epoch: [ 1/ 5], Step: [ 228/ 600], Loss: 0.2283\n",
      "Epoch: [ 1/ 5], Step: [ 229/ 600], Loss: 0.0476\n",
      "Epoch: [ 1/ 5], Step: [ 230/ 600], Loss: 0.4736\n",
      "Epoch: [ 1/ 5], Step: [ 231/ 600], Loss: 0.1025\n",
      "Epoch: [ 1/ 5], Step: [ 232/ 600], Loss: 0.0484\n",
      "Epoch: [ 1/ 5], Step: [ 233/ 600], Loss: 0.2206\n",
      "Epoch: [ 1/ 5], Step: [ 234/ 600], Loss: 0.1565\n",
      "Epoch: [ 1/ 5], Step: [ 235/ 600], Loss: 0.1252\n",
      "Epoch: [ 1/ 5], Step: [ 236/ 600], Loss: 0.7506\n",
      "Epoch: [ 1/ 5], Step: [ 237/ 600], Loss: 0.4431\n",
      "Epoch: [ 1/ 5], Step: [ 238/ 600], Loss: 0.1915\n",
      "Epoch: [ 1/ 5], Step: [ 239/ 600], Loss: 1.0913\n",
      "Epoch: [ 1/ 5], Step: [ 240/ 600], Loss: 0.5732\n",
      "Epoch: [ 1/ 5], Step: [ 241/ 600], Loss: 0.2158\n",
      "Epoch: [ 1/ 5], Step: [ 242/ 600], Loss: 0.0857\n",
      "Epoch: [ 1/ 5], Step: [ 243/ 600], Loss: 0.0277\n",
      "Epoch: [ 1/ 5], Step: [ 244/ 600], Loss: 3.8288\n",
      "Epoch: [ 1/ 5], Step: [ 245/ 600], Loss: 0.7573\n",
      "Epoch: [ 1/ 5], Step: [ 246/ 600], Loss: 0.1914\n",
      "Epoch: [ 1/ 5], Step: [ 247/ 600], Loss: 0.3142\n",
      "Epoch: [ 1/ 5], Step: [ 248/ 600], Loss: 0.0773\n",
      "Epoch: [ 1/ 5], Step: [ 249/ 600], Loss: 1.0193\n",
      "Epoch: [ 1/ 5], Step: [ 250/ 600], Loss: 0.3298\n",
      "Epoch: [ 1/ 5], Step: [ 251/ 600], Loss: 0.2119\n",
      "Epoch: [ 1/ 5], Step: [ 252/ 600], Loss: 0.1847\n",
      "Epoch: [ 1/ 5], Step: [ 253/ 600], Loss: 0.1021\n",
      "Epoch: [ 1/ 5], Step: [ 254/ 600], Loss: 0.1120\n",
      "Epoch: [ 1/ 5], Step: [ 255/ 600], Loss: 0.4408\n",
      "Epoch: [ 1/ 5], Step: [ 256/ 600], Loss: 0.0413\n",
      "Epoch: [ 1/ 5], Step: [ 257/ 600], Loss: 2.4024\n",
      "Epoch: [ 1/ 5], Step: [ 258/ 600], Loss: 0.6865\n",
      "Epoch: [ 1/ 5], Step: [ 259/ 600], Loss: 0.3717\n",
      "Epoch: [ 1/ 5], Step: [ 260/ 600], Loss: 0.1593\n",
      "Epoch: [ 1/ 5], Step: [ 261/ 600], Loss: 0.1038\n",
      "Epoch: [ 1/ 5], Step: [ 262/ 600], Loss: 0.2959\n",
      "Epoch: [ 1/ 5], Step: [ 263/ 600], Loss: 0.2380\n",
      "Epoch: [ 1/ 5], Step: [ 264/ 600], Loss: 0.0939\n",
      "Epoch: [ 1/ 5], Step: [ 265/ 600], Loss: 0.0186\n",
      "Epoch: [ 1/ 5], Step: [ 266/ 600], Loss: 1.2080\n",
      "Epoch: [ 1/ 5], Step: [ 267/ 600], Loss: 0.0680\n",
      "Epoch: [ 1/ 5], Step: [ 268/ 600], Loss: 0.2106\n",
      "Epoch: [ 1/ 5], Step: [ 269/ 600], Loss: 0.0419\n",
      "Epoch: [ 1/ 5], Step: [ 270/ 600], Loss: 0.0380\n",
      "Epoch: [ 1/ 5], Step: [ 271/ 600], Loss: 0.5054\n",
      "Epoch: [ 1/ 5], Step: [ 272/ 600], Loss: 0.1518\n",
      "Epoch: [ 1/ 5], Step: [ 273/ 600], Loss: 1.7957\n",
      "Epoch: [ 1/ 5], Step: [ 274/ 600], Loss: 0.6730\n",
      "Epoch: [ 1/ 5], Step: [ 275/ 600], Loss: 0.5184\n",
      "Epoch: [ 1/ 5], Step: [ 276/ 600], Loss: 0.3231\n",
      "Epoch: [ 1/ 5], Step: [ 277/ 600], Loss: 0.4498\n",
      "Epoch: [ 1/ 5], Step: [ 278/ 600], Loss: 0.3832\n",
      "Epoch: [ 1/ 5], Step: [ 279/ 600], Loss: 0.0252\n",
      "Epoch: [ 1/ 5], Step: [ 280/ 600], Loss: 0.0156\n",
      "Epoch: [ 1/ 5], Step: [ 281/ 600], Loss: 1.4746\n",
      "Epoch: [ 1/ 5], Step: [ 282/ 600], Loss: 0.1978\n",
      "Epoch: [ 1/ 5], Step: [ 283/ 600], Loss: 0.0011\n",
      "Epoch: [ 1/ 5], Step: [ 284/ 600], Loss: 0.4933\n",
      "Epoch: [ 1/ 5], Step: [ 285/ 600], Loss: 0.0120\n",
      "Epoch: [ 1/ 5], Step: [ 286/ 600], Loss: 0.8469\n",
      "Epoch: [ 1/ 5], Step: [ 287/ 600], Loss: 0.9354\n",
      "Epoch: [ 1/ 5], Step: [ 288/ 600], Loss: 1.2703\n",
      "Epoch: [ 1/ 5], Step: [ 289/ 600], Loss: 0.1422\n",
      "Epoch: [ 1/ 5], Step: [ 290/ 600], Loss: 0.3983\n",
      "Epoch: [ 1/ 5], Step: [ 291/ 600], Loss: 0.2542\n",
      "Epoch: [ 1/ 5], Step: [ 292/ 600], Loss: 0.2053\n",
      "Epoch: [ 1/ 5], Step: [ 293/ 600], Loss: 0.6341\n",
      "Epoch: [ 1/ 5], Step: [ 294/ 600], Loss: 0.2357\n",
      "Epoch: [ 1/ 5], Step: [ 295/ 600], Loss: 0.0337\n",
      "Epoch: [ 1/ 5], Step: [ 296/ 600], Loss: 0.0399\n",
      "Epoch: [ 1/ 5], Step: [ 297/ 600], Loss: 0.2020\n",
      "Epoch: [ 1/ 5], Step: [ 298/ 600], Loss: 2.8683\n",
      "Epoch: [ 1/ 5], Step: [ 299/ 600], Loss: 0.6930\n",
      "Epoch: [ 1/ 5], Step: [ 300/ 600], Loss: 0.9434\n",
      "Epoch: [ 1/ 5], Step: [ 301/ 600], Loss: 0.0898\n",
      "Epoch: [ 1/ 5], Step: [ 302/ 600], Loss: 0.1044\n",
      "Epoch: [ 1/ 5], Step: [ 303/ 600], Loss: 0.2033\n",
      "Epoch: [ 1/ 5], Step: [ 304/ 600], Loss: 1.9001\n",
      "Epoch: [ 1/ 5], Step: [ 305/ 600], Loss: 0.0809\n",
      "Epoch: [ 1/ 5], Step: [ 306/ 600], Loss: 0.1353\n",
      "Epoch: [ 1/ 5], Step: [ 307/ 600], Loss: 0.2231\n",
      "Epoch: [ 1/ 5], Step: [ 308/ 600], Loss: 0.0060\n",
      "Epoch: [ 1/ 5], Step: [ 309/ 600], Loss: 0.0891\n",
      "Epoch: [ 1/ 5], Step: [ 310/ 600], Loss: 0.1495\n",
      "Epoch: [ 1/ 5], Step: [ 311/ 600], Loss: 0.0092\n",
      "Epoch: [ 1/ 5], Step: [ 312/ 600], Loss: 0.2766\n",
      "Epoch: [ 1/ 5], Step: [ 313/ 600], Loss: 0.4269\n",
      "Epoch: [ 1/ 5], Step: [ 314/ 600], Loss: 0.0771\n",
      "Epoch: [ 1/ 5], Step: [ 315/ 600], Loss: 0.2979\n",
      "Epoch: [ 1/ 5], Step: [ 316/ 600], Loss: 0.0201\n",
      "Epoch: [ 1/ 5], Step: [ 317/ 600], Loss: 0.0567\n",
      "Epoch: [ 1/ 5], Step: [ 318/ 600], Loss: 0.0577\n",
      "Epoch: [ 1/ 5], Step: [ 319/ 600], Loss: 0.4859\n",
      "Epoch: [ 1/ 5], Step: [ 320/ 600], Loss: 0.0757\n",
      "Epoch: [ 1/ 5], Step: [ 321/ 600], Loss: 0.0268\n",
      "Epoch: [ 1/ 5], Step: [ 322/ 600], Loss: 0.7683\n",
      "Epoch: [ 1/ 5], Step: [ 323/ 600], Loss: 1.6479\n",
      "Epoch: [ 1/ 5], Step: [ 324/ 600], Loss: 0.0369\n",
      "Epoch: [ 1/ 5], Step: [ 325/ 600], Loss: 0.0080\n",
      "Epoch: [ 1/ 5], Step: [ 326/ 600], Loss: 0.0004\n",
      "Epoch: [ 1/ 5], Step: [ 327/ 600], Loss: 0.0080\n",
      "Epoch: [ 1/ 5], Step: [ 328/ 600], Loss: 0.3421\n",
      "Epoch: [ 1/ 5], Step: [ 329/ 600], Loss: 0.0595\n",
      "Epoch: [ 1/ 5], Step: [ 330/ 600], Loss: 0.0479\n",
      "Epoch: [ 1/ 5], Step: [ 331/ 600], Loss: 0.0359\n",
      "Epoch: [ 1/ 5], Step: [ 332/ 600], Loss: 0.6352\n",
      "Epoch: [ 1/ 5], Step: [ 333/ 600], Loss: 0.1060\n",
      "Epoch: [ 1/ 5], Step: [ 334/ 600], Loss: 0.3514\n",
      "Epoch: [ 1/ 5], Step: [ 335/ 600], Loss: 0.0065\n",
      "Epoch: [ 1/ 5], Step: [ 336/ 600], Loss: 0.1559\n",
      "Epoch: [ 1/ 5], Step: [ 337/ 600], Loss: 0.0738\n",
      "Epoch: [ 1/ 5], Step: [ 338/ 600], Loss: 0.0346\n",
      "Epoch: [ 1/ 5], Step: [ 339/ 600], Loss: 0.1190\n",
      "Epoch: [ 1/ 5], Step: [ 340/ 600], Loss: 0.1363\n",
      "Epoch: [ 1/ 5], Step: [ 341/ 600], Loss: 0.6617\n",
      "Epoch: [ 1/ 5], Step: [ 342/ 600], Loss: 1.5033\n",
      "Epoch: [ 1/ 5], Step: [ 343/ 600], Loss: 0.0371\n",
      "Epoch: [ 1/ 5], Step: [ 344/ 600], Loss: 0.0057\n",
      "Epoch: [ 1/ 5], Step: [ 345/ 600], Loss: 0.3828\n",
      "Epoch: [ 1/ 5], Step: [ 346/ 600], Loss: 0.3350\n",
      "Epoch: [ 1/ 5], Step: [ 347/ 600], Loss: 0.0602\n",
      "Epoch: [ 1/ 5], Step: [ 348/ 600], Loss: 0.1314\n",
      "Epoch: [ 1/ 5], Step: [ 349/ 600], Loss: 0.4122\n",
      "Epoch: [ 1/ 5], Step: [ 350/ 600], Loss: 0.6403\n",
      "Epoch: [ 1/ 5], Step: [ 351/ 600], Loss: 0.0926\n",
      "Epoch: [ 1/ 5], Step: [ 352/ 600], Loss: 0.0674\n",
      "Epoch: [ 1/ 5], Step: [ 353/ 600], Loss: 2.8510\n",
      "Epoch: [ 1/ 5], Step: [ 354/ 600], Loss: 0.0168\n",
      "Epoch: [ 1/ 5], Step: [ 355/ 600], Loss: 0.0640\n",
      "Epoch: [ 1/ 5], Step: [ 356/ 600], Loss: 1.3140\n",
      "Epoch: [ 1/ 5], Step: [ 357/ 600], Loss: 0.0179\n",
      "Epoch: [ 1/ 5], Step: [ 358/ 600], Loss: 3.5575\n",
      "Epoch: [ 1/ 5], Step: [ 359/ 600], Loss: 0.2007\n",
      "Epoch: [ 1/ 5], Step: [ 360/ 600], Loss: 0.0551\n",
      "Epoch: [ 1/ 5], Step: [ 361/ 600], Loss: 0.3167\n",
      "Epoch: [ 1/ 5], Step: [ 362/ 600], Loss: 0.0484\n",
      "Epoch: [ 1/ 5], Step: [ 363/ 600], Loss: 3.5870\n",
      "Epoch: [ 1/ 5], Step: [ 364/ 600], Loss: 0.2589\n",
      "Epoch: [ 1/ 5], Step: [ 365/ 600], Loss: 0.0344\n",
      "Epoch: [ 1/ 5], Step: [ 366/ 600], Loss: 0.2511\n",
      "Epoch: [ 1/ 5], Step: [ 367/ 600], Loss: 1.3355\n",
      "Epoch: [ 1/ 5], Step: [ 368/ 600], Loss: 0.0214\n",
      "Epoch: [ 1/ 5], Step: [ 369/ 600], Loss: 0.1965\n",
      "Epoch: [ 1/ 5], Step: [ 370/ 600], Loss: 0.7564\n",
      "Epoch: [ 1/ 5], Step: [ 371/ 600], Loss: 0.1412\n",
      "Epoch: [ 1/ 5], Step: [ 372/ 600], Loss: 0.0286\n",
      "Epoch: [ 1/ 5], Step: [ 373/ 600], Loss: 0.0576\n",
      "Epoch: [ 1/ 5], Step: [ 374/ 600], Loss: 0.8941\n",
      "Epoch: [ 1/ 5], Step: [ 375/ 600], Loss: 0.1469\n",
      "Epoch: [ 1/ 5], Step: [ 376/ 600], Loss: 3.0503\n",
      "Epoch: [ 1/ 5], Step: [ 377/ 600], Loss: 0.7508\n",
      "Epoch: [ 1/ 5], Step: [ 378/ 600], Loss: 0.3107\n",
      "Epoch: [ 1/ 5], Step: [ 379/ 600], Loss: 0.8114\n",
      "Epoch: [ 1/ 5], Step: [ 380/ 600], Loss: 0.1654\n",
      "Epoch: [ 1/ 5], Step: [ 381/ 600], Loss: 0.0264\n",
      "Epoch: [ 1/ 5], Step: [ 382/ 600], Loss: 0.2803\n",
      "Epoch: [ 1/ 5], Step: [ 383/ 600], Loss: 0.0408\n",
      "Epoch: [ 1/ 5], Step: [ 384/ 600], Loss: 0.7033\n",
      "Epoch: [ 1/ 5], Step: [ 385/ 600], Loss: 0.0106\n",
      "Epoch: [ 1/ 5], Step: [ 386/ 600], Loss: 4.3566\n",
      "Epoch: [ 1/ 5], Step: [ 387/ 600], Loss: 0.0756\n",
      "Epoch: [ 1/ 5], Step: [ 388/ 600], Loss: 0.4593\n",
      "Epoch: [ 1/ 5], Step: [ 389/ 600], Loss: 0.0903\n",
      "Epoch: [ 1/ 5], Step: [ 390/ 600], Loss: 1.3404\n",
      "Epoch: [ 1/ 5], Step: [ 391/ 600], Loss: 0.0421\n",
      "Epoch: [ 1/ 5], Step: [ 392/ 600], Loss: 1.4490\n",
      "Epoch: [ 1/ 5], Step: [ 393/ 600], Loss: 0.8604\n",
      "Epoch: [ 1/ 5], Step: [ 394/ 600], Loss: 0.0226\n",
      "Epoch: [ 1/ 5], Step: [ 395/ 600], Loss: 0.1593\n",
      "Epoch: [ 1/ 5], Step: [ 396/ 600], Loss: 0.3754\n",
      "Epoch: [ 1/ 5], Step: [ 397/ 600], Loss: 0.3135\n",
      "Epoch: [ 1/ 5], Step: [ 398/ 600], Loss: 0.0165\n",
      "Epoch: [ 1/ 5], Step: [ 399/ 600], Loss: 0.0914\n",
      "Epoch: [ 1/ 5], Step: [ 400/ 600], Loss: 0.4645\n",
      "Epoch: [ 1/ 5], Step: [ 401/ 600], Loss: 0.0648\n",
      "Epoch: [ 1/ 5], Step: [ 402/ 600], Loss: 0.0029\n",
      "Epoch: [ 1/ 5], Step: [ 403/ 600], Loss: 0.1251\n",
      "Epoch: [ 1/ 5], Step: [ 404/ 600], Loss: 0.0588\n",
      "Epoch: [ 1/ 5], Step: [ 405/ 600], Loss: 2.7642\n",
      "Epoch: [ 1/ 5], Step: [ 406/ 600], Loss: 0.1851\n",
      "Epoch: [ 1/ 5], Step: [ 407/ 600], Loss: 0.0427\n",
      "Epoch: [ 1/ 5], Step: [ 408/ 600], Loss: 0.0404\n",
      "Epoch: [ 1/ 5], Step: [ 409/ 600], Loss: 0.4220\n",
      "Epoch: [ 1/ 5], Step: [ 410/ 600], Loss: 0.2587\n",
      "Epoch: [ 1/ 5], Step: [ 411/ 600], Loss: 0.2184\n",
      "Epoch: [ 1/ 5], Step: [ 412/ 600], Loss: 0.3397\n",
      "Epoch: [ 1/ 5], Step: [ 413/ 600], Loss: 0.0029\n",
      "Epoch: [ 1/ 5], Step: [ 414/ 600], Loss: 0.0546\n",
      "Epoch: [ 1/ 5], Step: [ 415/ 600], Loss: 0.0137\n",
      "Epoch: [ 1/ 5], Step: [ 416/ 600], Loss: 0.6985\n",
      "Epoch: [ 1/ 5], Step: [ 417/ 600], Loss: 0.0440\n",
      "Epoch: [ 1/ 5], Step: [ 418/ 600], Loss: 0.2756\n",
      "Epoch: [ 1/ 5], Step: [ 419/ 600], Loss: 0.2298\n",
      "Epoch: [ 1/ 5], Step: [ 420/ 600], Loss: 0.6244\n",
      "Epoch: [ 1/ 5], Step: [ 421/ 600], Loss: 0.0147\n",
      "Epoch: [ 1/ 5], Step: [ 422/ 600], Loss: 0.2140\n",
      "Epoch: [ 1/ 5], Step: [ 423/ 600], Loss: 0.0333\n",
      "Epoch: [ 1/ 5], Step: [ 424/ 600], Loss: 0.7070\n",
      "Epoch: [ 1/ 5], Step: [ 425/ 600], Loss: 0.4813\n",
      "Epoch: [ 1/ 5], Step: [ 426/ 600], Loss: 0.4438\n",
      "Epoch: [ 1/ 5], Step: [ 427/ 600], Loss: 1.1319\n",
      "Epoch: [ 1/ 5], Step: [ 428/ 600], Loss: 1.7514\n",
      "Epoch: [ 1/ 5], Step: [ 429/ 600], Loss: 0.0519\n",
      "Epoch: [ 1/ 5], Step: [ 430/ 600], Loss: 0.0262\n",
      "Epoch: [ 1/ 5], Step: [ 431/ 600], Loss: 1.1192\n",
      "Epoch: [ 1/ 5], Step: [ 432/ 600], Loss: 0.0126\n",
      "Epoch: [ 1/ 5], Step: [ 433/ 600], Loss: 0.0694\n",
      "Epoch: [ 1/ 5], Step: [ 434/ 600], Loss: 0.0126\n",
      "Epoch: [ 1/ 5], Step: [ 435/ 600], Loss: 0.1572\n",
      "Epoch: [ 1/ 5], Step: [ 436/ 600], Loss: 0.0727\n",
      "Epoch: [ 1/ 5], Step: [ 437/ 600], Loss: 0.0260\n",
      "Epoch: [ 1/ 5], Step: [ 438/ 600], Loss: 0.0150\n",
      "Epoch: [ 1/ 5], Step: [ 439/ 600], Loss: 0.1054\n",
      "Epoch: [ 1/ 5], Step: [ 440/ 600], Loss: 0.0181\n",
      "Epoch: [ 1/ 5], Step: [ 441/ 600], Loss: 0.4046\n",
      "Epoch: [ 1/ 5], Step: [ 442/ 600], Loss: 0.0132\n",
      "Epoch: [ 1/ 5], Step: [ 443/ 600], Loss: 0.0223\n",
      "Epoch: [ 1/ 5], Step: [ 444/ 600], Loss: 0.0255\n",
      "Epoch: [ 1/ 5], Step: [ 445/ 600], Loss: 0.1791\n",
      "Epoch: [ 1/ 5], Step: [ 446/ 600], Loss: 0.0082\n",
      "Epoch: [ 1/ 5], Step: [ 447/ 600], Loss: 0.6184\n",
      "Epoch: [ 1/ 5], Step: [ 448/ 600], Loss: 0.9105\n",
      "Epoch: [ 1/ 5], Step: [ 449/ 600], Loss: 0.2322\n",
      "Epoch: [ 1/ 5], Step: [ 450/ 600], Loss: 0.0283\n",
      "Epoch: [ 1/ 5], Step: [ 451/ 600], Loss: 0.0002\n",
      "Epoch: [ 1/ 5], Step: [ 452/ 600], Loss: 0.0334\n",
      "Epoch: [ 1/ 5], Step: [ 453/ 600], Loss: 0.0519\n",
      "Epoch: [ 1/ 5], Step: [ 454/ 600], Loss: 0.0530\n",
      "Epoch: [ 1/ 5], Step: [ 455/ 600], Loss: 0.6329\n",
      "Epoch: [ 1/ 5], Step: [ 456/ 600], Loss: 0.1794\n",
      "Epoch: [ 1/ 5], Step: [ 457/ 600], Loss: 0.0708\n",
      "Epoch: [ 1/ 5], Step: [ 458/ 600], Loss: 0.4918\n",
      "Epoch: [ 1/ 5], Step: [ 459/ 600], Loss: 0.5757\n",
      "Epoch: [ 1/ 5], Step: [ 460/ 600], Loss: 0.0024\n",
      "Epoch: [ 1/ 5], Step: [ 461/ 600], Loss: 0.0031\n",
      "Epoch: [ 1/ 5], Step: [ 462/ 600], Loss: 1.3383\n",
      "Epoch: [ 1/ 5], Step: [ 463/ 600], Loss: 0.3566\n",
      "Epoch: [ 1/ 5], Step: [ 464/ 600], Loss: 0.1811\n",
      "Epoch: [ 1/ 5], Step: [ 465/ 600], Loss: 0.3280\n",
      "Epoch: [ 1/ 5], Step: [ 466/ 600], Loss: 0.1545\n",
      "Epoch: [ 1/ 5], Step: [ 467/ 600], Loss: 0.2570\n",
      "Epoch: [ 1/ 5], Step: [ 468/ 600], Loss: 0.1716\n",
      "Epoch: [ 1/ 5], Step: [ 469/ 600], Loss: 0.1736\n",
      "Epoch: [ 1/ 5], Step: [ 470/ 600], Loss: 0.0297\n",
      "Epoch: [ 1/ 5], Step: [ 471/ 600], Loss: 0.0441\n",
      "Epoch: [ 1/ 5], Step: [ 472/ 600], Loss: 0.0571\n",
      "Epoch: [ 1/ 5], Step: [ 473/ 600], Loss: 1.0121\n",
      "Epoch: [ 1/ 5], Step: [ 474/ 600], Loss: 0.2012\n",
      "Epoch: [ 1/ 5], Step: [ 475/ 600], Loss: 0.0552\n",
      "Epoch: [ 1/ 5], Step: [ 476/ 600], Loss: 0.0359\n",
      "Epoch: [ 1/ 5], Step: [ 477/ 600], Loss: 0.1090\n",
      "Epoch: [ 1/ 5], Step: [ 478/ 600], Loss: 0.0009\n",
      "Epoch: [ 1/ 5], Step: [ 479/ 600], Loss: 0.0877\n",
      "Epoch: [ 1/ 5], Step: [ 480/ 600], Loss: 0.0242\n",
      "Epoch: [ 1/ 5], Step: [ 481/ 600], Loss: 0.0251\n",
      "Epoch: [ 1/ 5], Step: [ 482/ 600], Loss: 1.4090\n",
      "Epoch: [ 1/ 5], Step: [ 483/ 600], Loss: 0.8413\n",
      "Epoch: [ 1/ 5], Step: [ 484/ 600], Loss: 0.1896\n",
      "Epoch: [ 1/ 5], Step: [ 485/ 600], Loss: 0.1362\n",
      "Epoch: [ 1/ 5], Step: [ 486/ 600], Loss: 0.4224\n",
      "Epoch: [ 1/ 5], Step: [ 487/ 600], Loss: 0.0048\n",
      "Epoch: [ 1/ 5], Step: [ 488/ 600], Loss: 0.0337\n",
      "Epoch: [ 1/ 5], Step: [ 489/ 600], Loss: 0.0040\n",
      "Epoch: [ 1/ 5], Step: [ 490/ 600], Loss: 0.0543\n",
      "Epoch: [ 1/ 5], Step: [ 491/ 600], Loss: 0.0101\n",
      "Epoch: [ 1/ 5], Step: [ 492/ 600], Loss: 0.0854\n",
      "Epoch: [ 1/ 5], Step: [ 493/ 600], Loss: 0.8074\n",
      "Epoch: [ 1/ 5], Step: [ 494/ 600], Loss: 0.0655\n",
      "Epoch: [ 1/ 5], Step: [ 495/ 600], Loss: 0.2032\n",
      "Epoch: [ 1/ 5], Step: [ 496/ 600], Loss: 0.0230\n",
      "Epoch: [ 1/ 5], Step: [ 497/ 600], Loss: 0.5233\n",
      "Epoch: [ 1/ 5], Step: [ 498/ 600], Loss: 0.0416\n",
      "Epoch: [ 1/ 5], Step: [ 499/ 600], Loss: 0.1428\n",
      "Epoch: [ 1/ 5], Step: [ 500/ 600], Loss: 0.0541\n",
      "Epoch: [ 1/ 5], Step: [ 501/ 600], Loss: 0.3716\n",
      "Epoch: [ 1/ 5], Step: [ 502/ 600], Loss: 1.3480\n",
      "Epoch: [ 1/ 5], Step: [ 503/ 600], Loss: 0.0708\n",
      "Epoch: [ 1/ 5], Step: [ 504/ 600], Loss: 0.0446\n",
      "Epoch: [ 1/ 5], Step: [ 505/ 600], Loss: 0.4555\n",
      "Epoch: [ 1/ 5], Step: [ 506/ 600], Loss: 0.0197\n",
      "Epoch: [ 1/ 5], Step: [ 507/ 600], Loss: 0.0058\n",
      "Epoch: [ 1/ 5], Step: [ 508/ 600], Loss: 0.0031\n",
      "Epoch: [ 1/ 5], Step: [ 509/ 600], Loss: 0.0737\n",
      "Epoch: [ 1/ 5], Step: [ 510/ 600], Loss: 0.1928\n",
      "Epoch: [ 1/ 5], Step: [ 511/ 600], Loss: 0.0291\n",
      "Epoch: [ 1/ 5], Step: [ 512/ 600], Loss: 0.3539\n",
      "Epoch: [ 1/ 5], Step: [ 513/ 600], Loss: 0.3789\n",
      "Epoch: [ 1/ 5], Step: [ 514/ 600], Loss: 0.0663\n",
      "Epoch: [ 1/ 5], Step: [ 515/ 600], Loss: 0.4134\n",
      "Epoch: [ 1/ 5], Step: [ 516/ 600], Loss: 0.0555\n",
      "Epoch: [ 1/ 5], Step: [ 517/ 600], Loss: 0.7788\n",
      "Epoch: [ 1/ 5], Step: [ 518/ 600], Loss: 0.3057\n",
      "Epoch: [ 1/ 5], Step: [ 519/ 600], Loss: 0.1010\n",
      "Epoch: [ 1/ 5], Step: [ 520/ 600], Loss: 0.1791\n",
      "Epoch: [ 1/ 5], Step: [ 521/ 600], Loss: 2.7707\n",
      "Epoch: [ 1/ 5], Step: [ 522/ 600], Loss: 0.0244\n",
      "Epoch: [ 1/ 5], Step: [ 523/ 600], Loss: 0.0813\n",
      "Epoch: [ 1/ 5], Step: [ 524/ 600], Loss: 0.3007\n",
      "Epoch: [ 1/ 5], Step: [ 525/ 600], Loss: 0.0415\n",
      "Epoch: [ 1/ 5], Step: [ 526/ 600], Loss: 0.8842\n",
      "Epoch: [ 1/ 5], Step: [ 527/ 600], Loss: 0.0900\n",
      "Epoch: [ 1/ 5], Step: [ 528/ 600], Loss: 0.2845\n",
      "Epoch: [ 1/ 5], Step: [ 529/ 600], Loss: 0.9109\n",
      "Epoch: [ 1/ 5], Step: [ 530/ 600], Loss: 0.1465\n",
      "Epoch: [ 1/ 5], Step: [ 531/ 600], Loss: 0.0835\n",
      "Epoch: [ 1/ 5], Step: [ 532/ 600], Loss: 0.1344\n",
      "Epoch: [ 1/ 5], Step: [ 533/ 600], Loss: 0.1816\n",
      "Epoch: [ 1/ 5], Step: [ 534/ 600], Loss: 0.1181\n",
      "Epoch: [ 1/ 5], Step: [ 535/ 600], Loss: 0.5474\n",
      "Epoch: [ 1/ 5], Step: [ 536/ 600], Loss: 3.0285\n",
      "Epoch: [ 1/ 5], Step: [ 537/ 600], Loss: 0.1292\n",
      "Epoch: [ 1/ 5], Step: [ 538/ 600], Loss: 0.4728\n",
      "Epoch: [ 1/ 5], Step: [ 539/ 600], Loss: 0.0540\n",
      "Epoch: [ 1/ 5], Step: [ 540/ 600], Loss: 0.3743\n",
      "Epoch: [ 1/ 5], Step: [ 541/ 600], Loss: 0.4588\n",
      "Epoch: [ 1/ 5], Step: [ 542/ 600], Loss: 1.1341\n",
      "Epoch: [ 1/ 5], Step: [ 543/ 600], Loss: 0.5266\n",
      "Epoch: [ 1/ 5], Step: [ 544/ 600], Loss: 0.1695\n",
      "Epoch: [ 1/ 5], Step: [ 545/ 600], Loss: 0.4234\n",
      "Epoch: [ 1/ 5], Step: [ 546/ 600], Loss: 0.1749\n",
      "Epoch: [ 1/ 5], Step: [ 547/ 600], Loss: 0.0328\n",
      "Epoch: [ 1/ 5], Step: [ 548/ 600], Loss: 0.0539\n",
      "Epoch: [ 1/ 5], Step: [ 549/ 600], Loss: 0.0087\n",
      "Epoch: [ 1/ 5], Step: [ 550/ 600], Loss: 0.8988\n",
      "Epoch: [ 1/ 5], Step: [ 551/ 600], Loss: 0.7528\n",
      "Epoch: [ 1/ 5], Step: [ 552/ 600], Loss: 0.0521\n",
      "Epoch: [ 1/ 5], Step: [ 553/ 600], Loss: 0.3309\n",
      "Epoch: [ 1/ 5], Step: [ 554/ 600], Loss: 0.1325\n",
      "Epoch: [ 1/ 5], Step: [ 555/ 600], Loss: 0.0722\n",
      "Epoch: [ 1/ 5], Step: [ 556/ 600], Loss: 0.2156\n",
      "Epoch: [ 1/ 5], Step: [ 557/ 600], Loss: 3.1892\n",
      "Epoch: [ 1/ 5], Step: [ 558/ 600], Loss: 0.0146\n",
      "Epoch: [ 1/ 5], Step: [ 559/ 600], Loss: 0.0496\n",
      "Epoch: [ 1/ 5], Step: [ 560/ 600], Loss: 3.1039\n",
      "Epoch: [ 1/ 5], Step: [ 561/ 600], Loss: 0.1305\n",
      "Epoch: [ 1/ 5], Step: [ 562/ 600], Loss: 2.0937\n",
      "Epoch: [ 1/ 5], Step: [ 563/ 600], Loss: 0.8072\n",
      "Epoch: [ 1/ 5], Step: [ 564/ 600], Loss: 0.1303\n",
      "Epoch: [ 1/ 5], Step: [ 565/ 600], Loss: 0.0066\n",
      "Epoch: [ 1/ 5], Step: [ 566/ 600], Loss: 0.5511\n",
      "Epoch: [ 1/ 5], Step: [ 567/ 600], Loss: 0.0806\n",
      "Epoch: [ 1/ 5], Step: [ 568/ 600], Loss: 0.1319\n",
      "Epoch: [ 1/ 5], Step: [ 569/ 600], Loss: 0.1158\n",
      "Epoch: [ 1/ 5], Step: [ 570/ 600], Loss: 0.0007\n",
      "Epoch: [ 1/ 5], Step: [ 571/ 600], Loss: 0.0670\n",
      "Epoch: [ 1/ 5], Step: [ 572/ 600], Loss: 0.0622\n",
      "Epoch: [ 1/ 5], Step: [ 573/ 600], Loss: 0.5010\n",
      "Epoch: [ 1/ 5], Step: [ 574/ 600], Loss: 0.0907\n",
      "Epoch: [ 1/ 5], Step: [ 575/ 600], Loss: 0.0216\n",
      "Epoch: [ 1/ 5], Step: [ 576/ 600], Loss: 0.0222\n",
      "Epoch: [ 1/ 5], Step: [ 577/ 600], Loss: 0.0707\n",
      "Epoch: [ 1/ 5], Step: [ 578/ 600], Loss: 0.0112\n",
      "Epoch: [ 1/ 5], Step: [ 579/ 600], Loss: 3.3845\n",
      "Epoch: [ 1/ 5], Step: [ 580/ 600], Loss: 0.2591\n",
      "Epoch: [ 1/ 5], Step: [ 581/ 600], Loss: 0.3346\n",
      "Epoch: [ 1/ 5], Step: [ 582/ 600], Loss: 0.0710\n",
      "Epoch: [ 1/ 5], Step: [ 583/ 600], Loss: 0.1467\n",
      "Epoch: [ 1/ 5], Step: [ 584/ 600], Loss: 0.4500\n",
      "Epoch: [ 1/ 5], Step: [ 585/ 600], Loss: 0.6123\n",
      "Epoch: [ 1/ 5], Step: [ 586/ 600], Loss: 0.0522\n",
      "Epoch: [ 1/ 5], Step: [ 587/ 600], Loss: 0.0048\n",
      "Epoch: [ 1/ 5], Step: [ 588/ 600], Loss: 0.0847\n",
      "Epoch: [ 1/ 5], Step: [ 589/ 600], Loss: 0.0705\n",
      "Epoch: [ 1/ 5], Step: [ 590/ 600], Loss: 0.8963\n",
      "Epoch: [ 1/ 5], Step: [ 591/ 600], Loss: 0.2123\n",
      "Epoch: [ 1/ 5], Step: [ 592/ 600], Loss: 0.0012\n",
      "Epoch: [ 1/ 5], Step: [ 593/ 600], Loss: 0.0774\n",
      "Epoch: [ 1/ 5], Step: [ 594/ 600], Loss: 0.0084\n",
      "Epoch: [ 1/ 5], Step: [ 595/ 600], Loss: 0.0331\n",
      "Epoch: [ 1/ 5], Step: [ 596/ 600], Loss: 0.4683\n",
      "Epoch: [ 1/ 5], Step: [ 597/ 600], Loss: 2.4893\n",
      "Epoch: [ 1/ 5], Step: [ 598/ 600], Loss: 1.8380\n",
      "Epoch: [ 1/ 5], Step: [ 599/ 600], Loss: 0.0010\n",
      "Epoch: [ 1/ 5], Step: [ 600/ 600], Loss: 0.0035\n",
      "Epoch: [ 2/ 5], Step: [ 1/ 600], Loss: 0.0025\n",
      "Epoch: [ 2/ 5], Step: [ 2/ 600], Loss: 0.1873\n",
      "Epoch: [ 2/ 5], Step: [ 3/ 600], Loss: 0.0056\n",
      "Epoch: [ 2/ 5], Step: [ 4/ 600], Loss: 0.4968\n",
      "Epoch: [ 2/ 5], Step: [ 5/ 600], Loss: 0.0223\n",
      "Epoch: [ 2/ 5], Step: [ 6/ 600], Loss: 0.0425\n",
      "Epoch: [ 2/ 5], Step: [ 7/ 600], Loss: 0.0388\n",
      "Epoch: [ 2/ 5], Step: [ 8/ 600], Loss: 0.3980\n",
      "Epoch: [ 2/ 5], Step: [ 9/ 600], Loss: 2.1736\n",
      "Epoch: [ 2/ 5], Step: [ 10/ 600], Loss: 0.7719\n",
      "Epoch: [ 2/ 5], Step: [ 11/ 600], Loss: 0.2287\n",
      "Epoch: [ 2/ 5], Step: [ 12/ 600], Loss: 0.3653\n",
      "Epoch: [ 2/ 5], Step: [ 13/ 600], Loss: 0.1909\n",
      "Epoch: [ 2/ 5], Step: [ 14/ 600], Loss: 0.0681\n",
      "Epoch: [ 2/ 5], Step: [ 15/ 600], Loss: 0.8321\n",
      "Epoch: [ 2/ 5], Step: [ 16/ 600], Loss: 0.0253\n",
      "Epoch: [ 2/ 5], Step: [ 17/ 600], Loss: 0.0073\n",
      "Epoch: [ 2/ 5], Step: [ 18/ 600], Loss: 1.0912\n",
      "Epoch: [ 2/ 5], Step: [ 19/ 600], Loss: 0.0391\n",
      "Epoch: [ 2/ 5], Step: [ 20/ 600], Loss: 3.2082\n",
      "Epoch: [ 2/ 5], Step: [ 21/ 600], Loss: 0.8626\n",
      "Epoch: [ 2/ 5], Step: [ 22/ 600], Loss: 0.2697\n",
      "Epoch: [ 2/ 5], Step: [ 23/ 600], Loss: 0.0445\n",
      "Epoch: [ 2/ 5], Step: [ 24/ 600], Loss: 1.0303\n",
      "Epoch: [ 2/ 5], Step: [ 25/ 600], Loss: 0.0738\n",
      "Epoch: [ 2/ 5], Step: [ 26/ 600], Loss: 0.0170\n",
      "Epoch: [ 2/ 5], Step: [ 27/ 600], Loss: 1.2171\n",
      "Epoch: [ 2/ 5], Step: [ 28/ 600], Loss: 0.0187\n",
      "Epoch: [ 2/ 5], Step: [ 29/ 600], Loss: 0.0456\n",
      "Epoch: [ 2/ 5], Step: [ 30/ 600], Loss: 0.0682\n",
      "Epoch: [ 2/ 5], Step: [ 31/ 600], Loss: 0.0429\n",
      "Epoch: [ 2/ 5], Step: [ 32/ 600], Loss: 0.0181\n",
      "Epoch: [ 2/ 5], Step: [ 33/ 600], Loss: 1.5474\n",
      "Epoch: [ 2/ 5], Step: [ 34/ 600], Loss: 0.0978\n",
      "Epoch: [ 2/ 5], Step: [ 35/ 600], Loss: 1.0173\n",
      "Epoch: [ 2/ 5], Step: [ 36/ 600], Loss: 0.0833\n",
      "Epoch: [ 2/ 5], Step: [ 37/ 600], Loss: 0.0517\n",
      "Epoch: [ 2/ 5], Step: [ 38/ 600], Loss: 0.0004\n",
      "Epoch: [ 2/ 5], Step: [ 39/ 600], Loss: 0.2916\n",
      "Epoch: [ 2/ 5], Step: [ 40/ 600], Loss: 0.1127\n",
      "Epoch: [ 2/ 5], Step: [ 41/ 600], Loss: 0.0335\n",
      "Epoch: [ 2/ 5], Step: [ 42/ 600], Loss: 0.2202\n",
      "Epoch: [ 2/ 5], Step: [ 43/ 600], Loss: 0.0384\n",
      "Epoch: [ 2/ 5], Step: [ 44/ 600], Loss: 0.0100\n",
      "Epoch: [ 2/ 5], Step: [ 45/ 600], Loss: 0.0369\n",
      "Epoch: [ 2/ 5], Step: [ 46/ 600], Loss: 0.2322\n",
      "Epoch: [ 2/ 5], Step: [ 47/ 600], Loss: 0.1508\n",
      "Epoch: [ 2/ 5], Step: [ 48/ 600], Loss: 0.0555\n",
      "Epoch: [ 2/ 5], Step: [ 49/ 600], Loss: 0.0397\n",
      "Epoch: [ 2/ 5], Step: [ 50/ 600], Loss: 1.6498\n",
      "Epoch: [ 2/ 5], Step: [ 51/ 600], Loss: 0.0602\n",
      "Epoch: [ 2/ 5], Step: [ 52/ 600], Loss: 0.2061\n",
      "Epoch: [ 2/ 5], Step: [ 53/ 600], Loss: 0.5952\n",
      "Epoch: [ 2/ 5], Step: [ 54/ 600], Loss: 0.0209\n",
      "Epoch: [ 2/ 5], Step: [ 55/ 600], Loss: 0.0864\n",
      "Epoch: [ 2/ 5], Step: [ 56/ 600], Loss: 3.4996\n",
      "Epoch: [ 2/ 5], Step: [ 57/ 600], Loss: 0.2656\n",
      "Epoch: [ 2/ 5], Step: [ 58/ 600], Loss: 0.0433\n",
      "Epoch: [ 2/ 5], Step: [ 59/ 600], Loss: 0.0486\n",
      "Epoch: [ 2/ 5], Step: [ 60/ 600], Loss: 0.0092\n",
      "Epoch: [ 2/ 5], Step: [ 61/ 600], Loss: 0.1210\n",
      "Epoch: [ 2/ 5], Step: [ 62/ 600], Loss: 0.0749\n",
      "Epoch: [ 2/ 5], Step: [ 63/ 600], Loss: 0.2810\n",
      "Epoch: [ 2/ 5], Step: [ 64/ 600], Loss: 0.7403\n",
      "Epoch: [ 2/ 5], Step: [ 65/ 600], Loss: 0.5435\n",
      "Epoch: [ 2/ 5], Step: [ 66/ 600], Loss: 0.0629\n",
      "Epoch: [ 2/ 5], Step: [ 67/ 600], Loss: 0.2395\n",
      "Epoch: [ 2/ 5], Step: [ 68/ 600], Loss: 0.0668\n",
      "Epoch: [ 2/ 5], Step: [ 69/ 600], Loss: 0.0404\n",
      "Epoch: [ 2/ 5], Step: [ 70/ 600], Loss: 0.0410\n",
      "Epoch: [ 2/ 5], Step: [ 71/ 600], Loss: 0.5821\n",
      "Epoch: [ 2/ 5], Step: [ 72/ 600], Loss: 0.1486\n",
      "Epoch: [ 2/ 5], Step: [ 73/ 600], Loss: 0.6638\n",
      "Epoch: [ 2/ 5], Step: [ 74/ 600], Loss: 0.6347\n",
      "Epoch: [ 2/ 5], Step: [ 75/ 600], Loss: 0.0793\n",
      "Epoch: [ 2/ 5], Step: [ 76/ 600], Loss: 0.8665\n",
      "Epoch: [ 2/ 5], Step: [ 77/ 600], Loss: 0.4332\n",
      "Epoch: [ 2/ 5], Step: [ 78/ 600], Loss: 2.6679\n",
      "Epoch: [ 2/ 5], Step: [ 79/ 600], Loss: 0.0029\n",
      "Epoch: [ 2/ 5], Step: [ 80/ 600], Loss: 0.0075\n",
      "Epoch: [ 2/ 5], Step: [ 81/ 600], Loss: 0.2066\n",
      "Epoch: [ 2/ 5], Step: [ 82/ 600], Loss: 0.0829\n",
      "Epoch: [ 2/ 5], Step: [ 83/ 600], Loss: 0.3861\n",
      "Epoch: [ 2/ 5], Step: [ 84/ 600], Loss: 0.1859\n",
      "Epoch: [ 2/ 5], Step: [ 85/ 600], Loss: 0.2266\n",
      "Epoch: [ 2/ 5], Step: [ 86/ 600], Loss: 0.0051\n",
      "Epoch: [ 2/ 5], Step: [ 87/ 600], Loss: 0.2905\n",
      "Epoch: [ 2/ 5], Step: [ 88/ 600], Loss: 0.0627\n",
      "Epoch: [ 2/ 5], Step: [ 89/ 600], Loss: 0.1297\n",
      "Epoch: [ 2/ 5], Step: [ 90/ 600], Loss: 0.0757\n",
      "Epoch: [ 2/ 5], Step: [ 91/ 600], Loss: 0.0788\n",
      "Epoch: [ 2/ 5], Step: [ 92/ 600], Loss: 0.4186\n",
      "Epoch: [ 2/ 5], Step: [ 93/ 600], Loss: 0.0079\n",
      "Epoch: [ 2/ 5], Step: [ 94/ 600], Loss: 0.1394\n",
      "Epoch: [ 2/ 5], Step: [ 95/ 600], Loss: 0.3416\n",
      "Epoch: [ 2/ 5], Step: [ 96/ 600], Loss: 0.0419\n",
      "Epoch: [ 2/ 5], Step: [ 97/ 600], Loss: 0.0006\n",
      "Epoch: [ 2/ 5], Step: [ 98/ 600], Loss: 0.2006\n",
      "Epoch: [ 2/ 5], Step: [ 99/ 600], Loss: 0.3719\n",
      "Epoch: [ 2/ 5], Step: [ 100/ 600], Loss: 1.9031\n",
      "Epoch: [ 2/ 5], Step: [ 101/ 600], Loss: 0.0132\n",
      "Epoch: [ 2/ 5], Step: [ 102/ 600], Loss: 0.5308\n",
      "Epoch: [ 2/ 5], Step: [ 103/ 600], Loss: 3.6753\n",
      "Epoch: [ 2/ 5], Step: [ 104/ 600], Loss: 0.0246\n",
      "Epoch: [ 2/ 5], Step: [ 105/ 600], Loss: 0.0144\n",
      "Epoch: [ 2/ 5], Step: [ 106/ 600], Loss: 0.2006\n",
      "Epoch: [ 2/ 5], Step: [ 107/ 600], Loss: 0.7657\n",
      "Epoch: [ 2/ 5], Step: [ 108/ 600], Loss: 0.2232\n",
      "Epoch: [ 2/ 5], Step: [ 109/ 600], Loss: 0.1266\n",
      "Epoch: [ 2/ 5], Step: [ 110/ 600], Loss: 0.0841\n",
      "Epoch: [ 2/ 5], Step: [ 111/ 600], Loss: 0.2439\n",
      "Epoch: [ 2/ 5], Step: [ 112/ 600], Loss: 0.0797\n",
      "Epoch: [ 2/ 5], Step: [ 113/ 600], Loss: 0.2844\n",
      "Epoch: [ 2/ 5], Step: [ 114/ 600], Loss: 0.0018\n",
      "Epoch: [ 2/ 5], Step: [ 115/ 600], Loss: 0.2153\n",
      "Epoch: [ 2/ 5], Step: [ 116/ 600], Loss: 0.1165\n",
      "Epoch: [ 2/ 5], Step: [ 117/ 600], Loss: 0.1189\n",
      "Epoch: [ 2/ 5], Step: [ 118/ 600], Loss: 0.0012\n",
      "Epoch: [ 2/ 5], Step: [ 119/ 600], Loss: 0.0053\n",
      "Epoch: [ 2/ 5], Step: [ 120/ 600], Loss: 0.0520\n",
      "Epoch: [ 2/ 5], Step: [ 121/ 600], Loss: 0.0151\n",
      "Epoch: [ 2/ 5], Step: [ 122/ 600], Loss: 0.1524\n",
      "Epoch: [ 2/ 5], Step: [ 123/ 600], Loss: 0.6430\n",
      "Epoch: [ 2/ 5], Step: [ 124/ 600], Loss: 0.3172\n",
      "Epoch: [ 2/ 5], Step: [ 125/ 600], Loss: 0.2032\n",
      "Epoch: [ 2/ 5], Step: [ 126/ 600], Loss: 0.0030\n",
      "Epoch: [ 2/ 5], Step: [ 127/ 600], Loss: 0.1409\n",
      "Epoch: [ 2/ 5], Step: [ 128/ 600], Loss: 0.0048\n",
      "Epoch: [ 2/ 5], Step: [ 129/ 600], Loss: 0.0186\n",
      "Epoch: [ 2/ 5], Step: [ 130/ 600], Loss: 0.0237\n",
      "Epoch: [ 2/ 5], Step: [ 131/ 600], Loss: 2.1620\n",
      "Epoch: [ 2/ 5], Step: [ 132/ 600], Loss: 0.0104\n",
      "Epoch: [ 2/ 5], Step: [ 133/ 600], Loss: 0.0053\n",
      "Epoch: [ 2/ 5], Step: [ 134/ 600], Loss: 0.3808\n",
      "Epoch: [ 2/ 5], Step: [ 135/ 600], Loss: 0.0118\n",
      "Epoch: [ 2/ 5], Step: [ 136/ 600], Loss: 0.0446\n",
      "Epoch: [ 2/ 5], Step: [ 137/ 600], Loss: 0.0186\n",
      "Epoch: [ 2/ 5], Step: [ 138/ 600], Loss: 0.0514\n",
      "Epoch: [ 2/ 5], Step: [ 139/ 600], Loss: 1.0438\n",
      "Epoch: [ 2/ 5], Step: [ 140/ 600], Loss: 0.0176\n",
      "Epoch: [ 2/ 5], Step: [ 141/ 600], Loss: 0.0172\n",
      "Epoch: [ 2/ 5], Step: [ 142/ 600], Loss: 0.3163\n",
      "Epoch: [ 2/ 5], Step: [ 143/ 600], Loss: 3.3164\n",
      "Epoch: [ 2/ 5], Step: [ 144/ 600], Loss: 0.0376\n",
      "Epoch: [ 2/ 5], Step: [ 145/ 600], Loss: 2.0512\n",
      "Epoch: [ 2/ 5], Step: [ 146/ 600], Loss: 0.2009\n",
      "Epoch: [ 2/ 5], Step: [ 147/ 600], Loss: 1.1381\n",
      "Epoch: [ 2/ 5], Step: [ 148/ 600], Loss: 0.8767\n",
      "Epoch: [ 2/ 5], Step: [ 149/ 600], Loss: 0.0631\n",
      "Epoch: [ 2/ 5], Step: [ 150/ 600], Loss: 0.0708\n",
      "Epoch: [ 2/ 5], Step: [ 151/ 600], Loss: 1.1205\n",
      "Epoch: [ 2/ 5], Step: [ 152/ 600], Loss: 0.0374\n",
      "Epoch: [ 2/ 5], Step: [ 153/ 600], Loss: 0.0048\n",
      "Epoch: [ 2/ 5], Step: [ 154/ 600], Loss: 0.0012\n",
      "Epoch: [ 2/ 5], Step: [ 155/ 600], Loss: 0.4342\n",
      "Epoch: [ 2/ 5], Step: [ 156/ 600], Loss: 0.0128\n",
      "Epoch: [ 2/ 5], Step: [ 157/ 600], Loss: 0.3009\n",
      "Epoch: [ 2/ 5], Step: [ 158/ 600], Loss: 0.0228\n",
      "Epoch: [ 2/ 5], Step: [ 159/ 600], Loss: 0.0073\n",
      "Epoch: [ 2/ 5], Step: [ 160/ 600], Loss: 0.1721\n",
      "Epoch: [ 2/ 5], Step: [ 161/ 600], Loss: 1.8029\n",
      "Epoch: [ 2/ 5], Step: [ 162/ 600], Loss: 0.0141\n",
      "Epoch: [ 2/ 5], Step: [ 163/ 600], Loss: 1.1004\n",
      "Epoch: [ 2/ 5], Step: [ 164/ 600], Loss: 0.0121\n",
      "Epoch: [ 2/ 5], Step: [ 165/ 600], Loss: 0.0049\n",
      "Epoch: [ 2/ 5], Step: [ 166/ 600], Loss: 0.0175\n",
      "Epoch: [ 2/ 5], Step: [ 167/ 600], Loss: 0.0053\n",
      "Epoch: [ 2/ 5], Step: [ 168/ 600], Loss: 0.0804\n",
      "Epoch: [ 2/ 5], Step: [ 169/ 600], Loss: 1.2547\n",
      "Epoch: [ 2/ 5], Step: [ 170/ 600], Loss: 0.1065\n",
      "Epoch: [ 2/ 5], Step: [ 171/ 600], Loss: 0.0102\n",
      "Epoch: [ 2/ 5], Step: [ 172/ 600], Loss: 0.0166\n",
      "Epoch: [ 2/ 5], Step: [ 173/ 600], Loss: 0.7560\n",
      "Epoch: [ 2/ 5], Step: [ 174/ 600], Loss: 0.2521\n",
      "Epoch: [ 2/ 5], Step: [ 175/ 600], Loss: 2.5667\n",
      "Epoch: [ 2/ 5], Step: [ 176/ 600], Loss: 0.5302\n",
      "Epoch: [ 2/ 5], Step: [ 177/ 600], Loss: 0.0088\n",
      "Epoch: [ 2/ 5], Step: [ 178/ 600], Loss: 0.0305\n",
      "Epoch: [ 2/ 5], Step: [ 179/ 600], Loss: 0.3954\n",
      "Epoch: [ 2/ 5], Step: [ 180/ 600], Loss: 0.0028\n",
      "Epoch: [ 2/ 5], Step: [ 181/ 600], Loss: 1.5953\n",
      "Epoch: [ 2/ 5], Step: [ 182/ 600], Loss: 0.0275\n",
      "Epoch: [ 2/ 5], Step: [ 183/ 600], Loss: 0.0293\n",
      "Epoch: [ 2/ 5], Step: [ 184/ 600], Loss: 0.0883\n",
      "Epoch: [ 2/ 5], Step: [ 185/ 600], Loss: 0.0262\n",
      "Epoch: [ 2/ 5], Step: [ 186/ 600], Loss: 0.0223\n",
      "Epoch: [ 2/ 5], Step: [ 187/ 600], Loss: 3.6558\n",
      "Epoch: [ 2/ 5], Step: [ 188/ 600], Loss: 1.1622\n",
      "Epoch: [ 2/ 5], Step: [ 189/ 600], Loss: 0.6364\n",
      "Epoch: [ 2/ 5], Step: [ 190/ 600], Loss: 0.0063\n",
      "Epoch: [ 2/ 5], Step: [ 191/ 600], Loss: 0.2166\n",
      "Epoch: [ 2/ 5], Step: [ 192/ 600], Loss: 0.0835\n",
      "Epoch: [ 2/ 5], Step: [ 193/ 600], Loss: 0.0036\n",
      "Epoch: [ 2/ 5], Step: [ 194/ 600], Loss: 0.2764\n",
      "Epoch: [ 2/ 5], Step: [ 195/ 600], Loss: 0.0118\n",
      "Epoch: [ 2/ 5], Step: [ 196/ 600], Loss: 0.1306\n",
      "Epoch: [ 2/ 5], Step: [ 197/ 600], Loss: 0.0087\n",
      "Epoch: [ 2/ 5], Step: [ 198/ 600], Loss: 0.0682\n",
      "Epoch: [ 2/ 5], Step: [ 199/ 600], Loss: 0.0454\n",
      "Epoch: [ 2/ 5], Step: [ 200/ 600], Loss: 0.0256\n",
      "Epoch: [ 2/ 5], Step: [ 201/ 600], Loss: 0.0328\n",
      "Epoch: [ 2/ 5], Step: [ 202/ 600], Loss: 0.0445\n",
      "Epoch: [ 2/ 5], Step: [ 203/ 600], Loss: 0.2872\n",
      "Epoch: [ 2/ 5], Step: [ 204/ 600], Loss: 0.3657\n",
      "Epoch: [ 2/ 5], Step: [ 205/ 600], Loss: 0.0443\n",
      "Epoch: [ 2/ 5], Step: [ 206/ 600], Loss: 0.0005\n",
      "Epoch: [ 2/ 5], Step: [ 207/ 600], Loss: 0.0104\n",
      "Epoch: [ 2/ 5], Step: [ 208/ 600], Loss: 0.0734\n",
      "Epoch: [ 2/ 5], Step: [ 209/ 600], Loss: 0.0149\n",
      "Epoch: [ 2/ 5], Step: [ 210/ 600], Loss: 0.0406\n",
      "Epoch: [ 2/ 5], Step: [ 211/ 600], Loss: 0.0359\n",
      "Epoch: [ 2/ 5], Step: [ 212/ 600], Loss: 0.0772\n",
      "Epoch: [ 2/ 5], Step: [ 213/ 600], Loss: 0.0058\n",
      "Epoch: [ 2/ 5], Step: [ 214/ 600], Loss: 0.7757\n",
      "Epoch: [ 2/ 5], Step: [ 215/ 600], Loss: 0.5752\n",
      "Epoch: [ 2/ 5], Step: [ 216/ 600], Loss: 0.1432\n",
      "Epoch: [ 2/ 5], Step: [ 217/ 600], Loss: 0.0349\n",
      "Epoch: [ 2/ 5], Step: [ 218/ 600], Loss: 0.0268\n",
      "Epoch: [ 2/ 5], Step: [ 219/ 600], Loss: 0.0071\n",
      "Epoch: [ 2/ 5], Step: [ 220/ 600], Loss: 0.0611\n",
      "Epoch: [ 2/ 5], Step: [ 221/ 600], Loss: 0.0081\n",
      "Epoch: [ 2/ 5], Step: [ 222/ 600], Loss: 0.4915\n",
      "Epoch: [ 2/ 5], Step: [ 223/ 600], Loss: 0.0303\n",
      "Epoch: [ 2/ 5], Step: [ 224/ 600], Loss: 0.0491\n",
      "Epoch: [ 2/ 5], Step: [ 225/ 600], Loss: 0.0022\n",
      "Epoch: [ 2/ 5], Step: [ 226/ 600], Loss: 0.0200\n",
      "Epoch: [ 2/ 5], Step: [ 227/ 600], Loss: 0.7029\n",
      "Epoch: [ 2/ 5], Step: [ 228/ 600], Loss: 0.2824\n",
      "Epoch: [ 2/ 5], Step: [ 229/ 600], Loss: 0.0362\n",
      "Epoch: [ 2/ 5], Step: [ 230/ 600], Loss: 1.0838\n",
      "Epoch: [ 2/ 5], Step: [ 231/ 600], Loss: 1.4823\n",
      "Epoch: [ 2/ 5], Step: [ 232/ 600], Loss: 0.1244\n",
      "Epoch: [ 2/ 5], Step: [ 233/ 600], Loss: 0.0207\n",
      "Epoch: [ 2/ 5], Step: [ 234/ 600], Loss: 0.7160\n",
      "Epoch: [ 2/ 5], Step: [ 235/ 600], Loss: 0.0339\n",
      "Epoch: [ 2/ 5], Step: [ 236/ 600], Loss: 0.0974\n",
      "Epoch: [ 2/ 5], Step: [ 237/ 600], Loss: 0.0120\n",
      "Epoch: [ 2/ 5], Step: [ 238/ 600], Loss: 0.1584\n",
      "Epoch: [ 2/ 5], Step: [ 239/ 600], Loss: 1.7947\n",
      "Epoch: [ 2/ 5], Step: [ 240/ 600], Loss: 0.0209\n",
      "Epoch: [ 2/ 5], Step: [ 241/ 600], Loss: 0.0884\n",
      "Epoch: [ 2/ 5], Step: [ 242/ 600], Loss: 0.0745\n",
      "Epoch: [ 2/ 5], Step: [ 243/ 600], Loss: 0.0374\n",
      "Epoch: [ 2/ 5], Step: [ 244/ 600], Loss: 1.2384\n",
      "Epoch: [ 2/ 5], Step: [ 245/ 600], Loss: 0.2378\n",
      "Epoch: [ 2/ 5], Step: [ 246/ 600], Loss: 0.3500\n",
      "Epoch: [ 2/ 5], Step: [ 247/ 600], Loss: 0.6035\n",
      "Epoch: [ 2/ 5], Step: [ 248/ 600], Loss: 0.5034\n",
      "Epoch: [ 2/ 5], Step: [ 249/ 600], Loss: 0.7118\n",
      "Epoch: [ 2/ 5], Step: [ 250/ 600], Loss: 0.0092\n",
      "Epoch: [ 2/ 5], Step: [ 251/ 600], Loss: 0.1197\n",
      "Epoch: [ 2/ 5], Step: [ 252/ 600], Loss: 0.4451\n",
      "Epoch: [ 2/ 5], Step: [ 253/ 600], Loss: 0.2631\n",
      "Epoch: [ 2/ 5], Step: [ 254/ 600], Loss: 0.0056\n",
      "Epoch: [ 2/ 5], Step: [ 255/ 600], Loss: 0.3046\n",
      "Epoch: [ 2/ 5], Step: [ 256/ 600], Loss: 0.0503\n",
      "Epoch: [ 2/ 5], Step: [ 257/ 600], Loss: 0.6026\n",
      "Epoch: [ 2/ 5], Step: [ 258/ 600], Loss: 0.0098\n",
      "Epoch: [ 2/ 5], Step: [ 259/ 600], Loss: 0.0483\n",
      "Epoch: [ 2/ 5], Step: [ 260/ 600], Loss: 0.2939\n",
      "Epoch: [ 2/ 5], Step: [ 261/ 600], Loss: 0.3988\n",
      "Epoch: [ 2/ 5], Step: [ 262/ 600], Loss: 0.0491\n",
      "Epoch: [ 2/ 5], Step: [ 263/ 600], Loss: 0.1695\n",
      "Epoch: [ 2/ 5], Step: [ 264/ 600], Loss: 0.0124\n",
      "Epoch: [ 2/ 5], Step: [ 265/ 600], Loss: 0.1222\n",
      "Epoch: [ 2/ 5], Step: [ 266/ 600], Loss: 1.0900\n",
      "Epoch: [ 2/ 5], Step: [ 267/ 600], Loss: 0.3349\n",
      "Epoch: [ 2/ 5], Step: [ 268/ 600], Loss: 6.1798\n",
      "Epoch: [ 2/ 5], Step: [ 269/ 600], Loss: 0.2462\n",
      "Epoch: [ 2/ 5], Step: [ 270/ 600], Loss: 0.2949\n",
      "Epoch: [ 2/ 5], Step: [ 271/ 600], Loss: 0.1045\n",
      "Epoch: [ 2/ 5], Step: [ 272/ 600], Loss: 0.0101\n",
      "Epoch: [ 2/ 5], Step: [ 273/ 600], Loss: 0.0730\n",
      "Epoch: [ 2/ 5], Step: [ 274/ 600], Loss: 0.0767\n",
      "Epoch: [ 2/ 5], Step: [ 275/ 600], Loss: 0.3824\n",
      "Epoch: [ 2/ 5], Step: [ 276/ 600], Loss: 0.0332\n",
      "Epoch: [ 2/ 5], Step: [ 277/ 600], Loss: 0.0766\n",
      "Epoch: [ 2/ 5], Step: [ 278/ 600], Loss: 0.3159\n",
      "Epoch: [ 2/ 5], Step: [ 279/ 600], Loss: 0.0091\n",
      "Epoch: [ 2/ 5], Step: [ 280/ 600], Loss: 0.1093\n",
      "Epoch: [ 2/ 5], Step: [ 281/ 600], Loss: 0.5603\n",
      "Epoch: [ 2/ 5], Step: [ 282/ 600], Loss: 0.0223\n",
      "Epoch: [ 2/ 5], Step: [ 283/ 600], Loss: 0.0624\n",
      "Epoch: [ 2/ 5], Step: [ 284/ 600], Loss: 0.1595\n",
      "Epoch: [ 2/ 5], Step: [ 285/ 600], Loss: 0.2529\n",
      "Epoch: [ 2/ 5], Step: [ 286/ 600], Loss: 0.0817\n",
      "Epoch: [ 2/ 5], Step: [ 287/ 600], Loss: 0.0007\n",
      "Epoch: [ 2/ 5], Step: [ 288/ 600], Loss: 0.1153\n",
      "Epoch: [ 2/ 5], Step: [ 289/ 600], Loss: 0.0096\n",
      "Epoch: [ 2/ 5], Step: [ 290/ 600], Loss: 0.0005\n",
      "Epoch: [ 2/ 5], Step: [ 291/ 600], Loss: 1.3157\n",
      "Epoch: [ 2/ 5], Step: [ 292/ 600], Loss: 0.3734\n",
      "Epoch: [ 2/ 5], Step: [ 293/ 600], Loss: 0.5785\n",
      "Epoch: [ 2/ 5], Step: [ 294/ 600], Loss: 0.1928\n",
      "Epoch: [ 2/ 5], Step: [ 295/ 600], Loss: 0.0832\n",
      "Epoch: [ 2/ 5], Step: [ 296/ 600], Loss: 0.1844\n",
      "Epoch: [ 2/ 5], Step: [ 297/ 600], Loss: 0.0151\n",
      "Epoch: [ 2/ 5], Step: [ 298/ 600], Loss: 0.0058\n",
      "Epoch: [ 2/ 5], Step: [ 299/ 600], Loss: 0.0245\n",
      "Epoch: [ 2/ 5], Step: [ 300/ 600], Loss: 0.0047\n",
      "Epoch: [ 2/ 5], Step: [ 301/ 600], Loss: 0.1064\n",
      "Epoch: [ 2/ 5], Step: [ 302/ 600], Loss: 0.0446\n",
      "Epoch: [ 2/ 5], Step: [ 303/ 600], Loss: 0.0312\n",
      "Epoch: [ 2/ 5], Step: [ 304/ 600], Loss: 0.0155\n",
      "Epoch: [ 2/ 5], Step: [ 305/ 600], Loss: 0.0648\n",
      "Epoch: [ 2/ 5], Step: [ 306/ 600], Loss: 0.1438\n",
      "Epoch: [ 2/ 5], Step: [ 307/ 600], Loss: 0.1261\n",
      "Epoch: [ 2/ 5], Step: [ 308/ 600], Loss: 0.0543\n",
      "Epoch: [ 2/ 5], Step: [ 309/ 600], Loss: 0.2404\n",
      "Epoch: [ 2/ 5], Step: [ 310/ 600], Loss: 0.0180\n",
      "Epoch: [ 2/ 5], Step: [ 311/ 600], Loss: 0.0181\n",
      "Epoch: [ 2/ 5], Step: [ 312/ 600], Loss: 0.0243\n",
      "Epoch: [ 2/ 5], Step: [ 313/ 600], Loss: 0.0006\n",
      "Epoch: [ 2/ 5], Step: [ 314/ 600], Loss: 1.2559\n",
      "Epoch: [ 2/ 5], Step: [ 315/ 600], Loss: 0.0287\n",
      "Epoch: [ 2/ 5], Step: [ 316/ 600], Loss: 0.1318\n",
      "Epoch: [ 2/ 5], Step: [ 317/ 600], Loss: 0.0419\n",
      "Epoch: [ 2/ 5], Step: [ 318/ 600], Loss: 1.4591\n",
      "Epoch: [ 2/ 5], Step: [ 319/ 600], Loss: 0.0216\n",
      "Epoch: [ 2/ 5], Step: [ 320/ 600], Loss: 0.2294\n",
      "Epoch: [ 2/ 5], Step: [ 321/ 600], Loss: 0.1104\n",
      "Epoch: [ 2/ 5], Step: [ 322/ 600], Loss: 0.0102\n",
      "Epoch: [ 2/ 5], Step: [ 323/ 600], Loss: 0.2365\n",
      "Epoch: [ 2/ 5], Step: [ 324/ 600], Loss: 0.3775\n",
      "Epoch: [ 2/ 5], Step: [ 325/ 600], Loss: 0.1654\n",
      "Epoch: [ 2/ 5], Step: [ 326/ 600], Loss: 1.1129\n",
      "Epoch: [ 2/ 5], Step: [ 327/ 600], Loss: 0.2772\n",
      "Epoch: [ 2/ 5], Step: [ 328/ 600], Loss: 3.8588\n",
      "Epoch: [ 2/ 5], Step: [ 329/ 600], Loss: 0.1372\n",
      "Epoch: [ 2/ 5], Step: [ 330/ 600], Loss: 0.0279\n",
      "Epoch: [ 2/ 5], Step: [ 331/ 600], Loss: 0.0269\n",
      "Epoch: [ 2/ 5], Step: [ 332/ 600], Loss: 0.8903\n",
      "Epoch: [ 2/ 5], Step: [ 333/ 600], Loss: 0.0134\n",
      "Epoch: [ 2/ 5], Step: [ 334/ 600], Loss: 0.0428\n",
      "Epoch: [ 2/ 5], Step: [ 335/ 600], Loss: 0.0197\n",
      "Epoch: [ 2/ 5], Step: [ 336/ 600], Loss: 0.0009\n",
      "Epoch: [ 2/ 5], Step: [ 337/ 600], Loss: 0.1800\n",
      "Epoch: [ 2/ 5], Step: [ 338/ 600], Loss: 0.0003\n",
      "Epoch: [ 2/ 5], Step: [ 339/ 600], Loss: 0.0451\n",
      "Epoch: [ 2/ 5], Step: [ 340/ 600], Loss: 0.0805\n",
      "Epoch: [ 2/ 5], Step: [ 341/ 600], Loss: 0.6038\n",
      "Epoch: [ 2/ 5], Step: [ 342/ 600], Loss: 0.2704\n",
      "Epoch: [ 2/ 5], Step: [ 343/ 600], Loss: 1.1417\n",
      "Epoch: [ 2/ 5], Step: [ 344/ 600], Loss: 0.1576\n",
      "Epoch: [ 2/ 5], Step: [ 345/ 600], Loss: 0.2563\n",
      "Epoch: [ 2/ 5], Step: [ 346/ 600], Loss: 0.0320\n",
      "Epoch: [ 2/ 5], Step: [ 347/ 600], Loss: 0.7897\n",
      "Epoch: [ 2/ 5], Step: [ 348/ 600], Loss: 0.0002\n",
      "Epoch: [ 2/ 5], Step: [ 349/ 600], Loss: 0.0015\n",
      "Epoch: [ 2/ 5], Step: [ 350/ 600], Loss: 0.2923\n",
      "Epoch: [ 2/ 5], Step: [ 351/ 600], Loss: 0.4106\n",
      "Epoch: [ 2/ 5], Step: [ 352/ 600], Loss: 1.3997\n",
      "Epoch: [ 2/ 5], Step: [ 353/ 600], Loss: 0.0634\n",
      "Epoch: [ 2/ 5], Step: [ 354/ 600], Loss: 0.1930\n",
      "Epoch: [ 2/ 5], Step: [ 355/ 600], Loss: 0.7693\n",
      "Epoch: [ 2/ 5], Step: [ 356/ 600], Loss: 0.0307\n",
      "Epoch: [ 2/ 5], Step: [ 357/ 600], Loss: 0.0031\n",
      "Epoch: [ 2/ 5], Step: [ 358/ 600], Loss: 0.0059\n",
      "Epoch: [ 2/ 5], Step: [ 359/ 600], Loss: 0.1126\n",
      "Epoch: [ 2/ 5], Step: [ 360/ 600], Loss: 0.0625\n",
      "Epoch: [ 2/ 5], Step: [ 361/ 600], Loss: 0.8873\n",
      "Epoch: [ 2/ 5], Step: [ 362/ 600], Loss: 0.0178\n",
      "Epoch: [ 2/ 5], Step: [ 363/ 600], Loss: 0.0021\n",
      "Epoch: [ 2/ 5], Step: [ 364/ 600], Loss: 0.0760\n",
      "Epoch: [ 2/ 5], Step: [ 365/ 600], Loss: 4.8160\n",
      "Epoch: [ 2/ 5], Step: [ 366/ 600], Loss: 0.0035\n",
      "Epoch: [ 2/ 5], Step: [ 367/ 600], Loss: 2.9719\n",
      "Epoch: [ 2/ 5], Step: [ 368/ 600], Loss: 0.0003\n",
      "Epoch: [ 2/ 5], Step: [ 369/ 600], Loss: 0.0367\n",
      "Epoch: [ 2/ 5], Step: [ 370/ 600], Loss: 1.9715\n",
      "Epoch: [ 2/ 5], Step: [ 371/ 600], Loss: 2.3567\n",
      "Epoch: [ 2/ 5], Step: [ 372/ 600], Loss: 0.0481\n",
      "Epoch: [ 2/ 5], Step: [ 373/ 600], Loss: 0.7205\n",
      "Epoch: [ 2/ 5], Step: [ 374/ 600], Loss: 0.0533\n",
      "Epoch: [ 2/ 5], Step: [ 375/ 600], Loss: 0.1291\n",
      "Epoch: [ 2/ 5], Step: [ 376/ 600], Loss: 0.1469\n",
      "Epoch: [ 2/ 5], Step: [ 377/ 600], Loss: 0.0105\n",
      "Epoch: [ 2/ 5], Step: [ 378/ 600], Loss: 0.0020\n",
      "Epoch: [ 2/ 5], Step: [ 379/ 600], Loss: 0.1544\n",
      "Epoch: [ 2/ 5], Step: [ 380/ 600], Loss: 0.1703\n",
      "Epoch: [ 2/ 5], Step: [ 381/ 600], Loss: 0.8279\n",
      "Epoch: [ 2/ 5], Step: [ 382/ 600], Loss: 0.0142\n",
      "Epoch: [ 2/ 5], Step: [ 383/ 600], Loss: 0.1035\n",
      "Epoch: [ 2/ 5], Step: [ 384/ 600], Loss: 0.0332\n",
      "Epoch: [ 2/ 5], Step: [ 385/ 600], Loss: 0.6460\n",
      "Epoch: [ 2/ 5], Step: [ 386/ 600], Loss: 0.2239\n",
      "Epoch: [ 2/ 5], Step: [ 387/ 600], Loss: 0.0330\n",
      "Epoch: [ 2/ 5], Step: [ 388/ 600], Loss: 0.0029\n",
      "Epoch: [ 2/ 5], Step: [ 389/ 600], Loss: 0.0976\n",
      "Epoch: [ 2/ 5], Step: [ 390/ 600], Loss: 0.1286\n",
      "Epoch: [ 2/ 5], Step: [ 391/ 600], Loss: 0.0709\n",
      "Epoch: [ 2/ 5], Step: [ 392/ 600], Loss: 0.0789\n",
      "Epoch: [ 2/ 5], Step: [ 393/ 600], Loss: 0.0699\n",
      "Epoch: [ 2/ 5], Step: [ 394/ 600], Loss: 0.0349\n",
      "Epoch: [ 2/ 5], Step: [ 395/ 600], Loss: 0.0072\n",
      "Epoch: [ 2/ 5], Step: [ 396/ 600], Loss: 0.0154\n",
      "Epoch: [ 2/ 5], Step: [ 397/ 600], Loss: 0.3838\n",
      "Epoch: [ 2/ 5], Step: [ 398/ 600], Loss: 0.0302\n",
      "Epoch: [ 2/ 5], Step: [ 399/ 600], Loss: 0.4274\n",
      "Epoch: [ 2/ 5], Step: [ 400/ 600], Loss: 0.2402\n",
      "Epoch: [ 2/ 5], Step: [ 401/ 600], Loss: 0.6771\n",
      "Epoch: [ 2/ 5], Step: [ 402/ 600], Loss: 0.1349\n",
      "Epoch: [ 2/ 5], Step: [ 403/ 600], Loss: 0.0023\n",
      "Epoch: [ 2/ 5], Step: [ 404/ 600], Loss: 0.0644\n",
      "Epoch: [ 2/ 5], Step: [ 405/ 600], Loss: 0.1215\n",
      "Epoch: [ 2/ 5], Step: [ 406/ 600], Loss: 0.0155\n",
      "Epoch: [ 2/ 5], Step: [ 407/ 600], Loss: 0.0005\n",
      "Epoch: [ 2/ 5], Step: [ 408/ 600], Loss: 0.0089\n",
      "Epoch: [ 2/ 5], Step: [ 409/ 600], Loss: 0.0122\n",
      "Epoch: [ 2/ 5], Step: [ 410/ 600], Loss: 0.1716\n",
      "Epoch: [ 2/ 5], Step: [ 411/ 600], Loss: 0.0499\n",
      "Epoch: [ 2/ 5], Step: [ 412/ 600], Loss: 0.1207\n",
      "Epoch: [ 2/ 5], Step: [ 413/ 600], Loss: 1.3606\n",
      "Epoch: [ 2/ 5], Step: [ 414/ 600], Loss: 0.0465\n",
      "Epoch: [ 2/ 5], Step: [ 415/ 600], Loss: 0.0500\n",
      "Epoch: [ 2/ 5], Step: [ 416/ 600], Loss: 0.0087\n",
      "Epoch: [ 2/ 5], Step: [ 417/ 600], Loss: 0.0000\n",
      "Epoch: [ 2/ 5], Step: [ 418/ 600], Loss: 0.4477\n",
      "Epoch: [ 2/ 5], Step: [ 419/ 600], Loss: 0.1693\n",
      "Epoch: [ 2/ 5], Step: [ 420/ 600], Loss: 0.0182\n",
      "Epoch: [ 2/ 5], Step: [ 421/ 600], Loss: 0.0617\n",
      "Epoch: [ 2/ 5], Step: [ 422/ 600], Loss: 1.0815\n",
      "Epoch: [ 2/ 5], Step: [ 423/ 600], Loss: 0.6477\n",
      "Epoch: [ 2/ 5], Step: [ 424/ 600], Loss: 0.0643\n",
      "Epoch: [ 2/ 5], Step: [ 425/ 600], Loss: 0.2013\n",
      "Epoch: [ 2/ 5], Step: [ 426/ 600], Loss: 0.0270\n",
      "Epoch: [ 2/ 5], Step: [ 427/ 600], Loss: 0.4741\n",
      "Epoch: [ 2/ 5], Step: [ 428/ 600], Loss: 0.1038\n",
      "Epoch: [ 2/ 5], Step: [ 429/ 600], Loss: 0.5190\n",
      "Epoch: [ 2/ 5], Step: [ 430/ 600], Loss: 0.0013\n",
      "Epoch: [ 2/ 5], Step: [ 431/ 600], Loss: 0.1198\n",
      "Epoch: [ 2/ 5], Step: [ 432/ 600], Loss: 0.1873\n",
      "Epoch: [ 2/ 5], Step: [ 433/ 600], Loss: 0.0436\n",
      "Epoch: [ 2/ 5], Step: [ 434/ 600], Loss: 0.1457\n",
      "Epoch: [ 2/ 5], Step: [ 435/ 600], Loss: 0.1426\n",
      "Epoch: [ 2/ 5], Step: [ 436/ 600], Loss: 1.7682\n",
      "Epoch: [ 2/ 5], Step: [ 437/ 600], Loss: 0.0110\n",
      "Epoch: [ 2/ 5], Step: [ 438/ 600], Loss: 0.0590\n",
      "Epoch: [ 2/ 5], Step: [ 439/ 600], Loss: 0.0142\n",
      "Epoch: [ 2/ 5], Step: [ 440/ 600], Loss: 0.0160\n",
      "Epoch: [ 2/ 5], Step: [ 441/ 600], Loss: 0.0255\n",
      "Epoch: [ 2/ 5], Step: [ 442/ 600], Loss: 0.1193\n",
      "Epoch: [ 2/ 5], Step: [ 443/ 600], Loss: 0.0286\n",
      "Epoch: [ 2/ 5], Step: [ 444/ 600], Loss: 0.1191\n",
      "Epoch: [ 2/ 5], Step: [ 445/ 600], Loss: 0.3969\n",
      "Epoch: [ 2/ 5], Step: [ 446/ 600], Loss: 0.0332\n",
      "Epoch: [ 2/ 5], Step: [ 447/ 600], Loss: 0.1619\n",
      "Epoch: [ 2/ 5], Step: [ 448/ 600], Loss: 0.0227\n",
      "Epoch: [ 2/ 5], Step: [ 449/ 600], Loss: 0.0804\n",
      "Epoch: [ 2/ 5], Step: [ 450/ 600], Loss: 2.5396\n",
      "Epoch: [ 2/ 5], Step: [ 451/ 600], Loss: 0.0955\n",
      "Epoch: [ 2/ 5], Step: [ 452/ 600], Loss: 0.1299\n",
      "Epoch: [ 2/ 5], Step: [ 453/ 600], Loss: 0.0001\n",
      "Epoch: [ 2/ 5], Step: [ 454/ 600], Loss: 0.0056\n",
      "Epoch: [ 2/ 5], Step: [ 455/ 600], Loss: 0.0499\n",
      "Epoch: [ 2/ 5], Step: [ 456/ 600], Loss: 0.2571\n",
      "Epoch: [ 2/ 5], Step: [ 457/ 600], Loss: 0.0570\n",
      "Epoch: [ 2/ 5], Step: [ 458/ 600], Loss: 0.0633\n",
      "Epoch: [ 2/ 5], Step: [ 459/ 600], Loss: 2.0190\n",
      "Epoch: [ 2/ 5], Step: [ 460/ 600], Loss: 0.0020\n",
      "Epoch: [ 2/ 5], Step: [ 461/ 600], Loss: 0.2111\n",
      "Epoch: [ 2/ 5], Step: [ 462/ 600], Loss: 0.3648\n",
      "Epoch: [ 2/ 5], Step: [ 463/ 600], Loss: 0.0583\n",
      "Epoch: [ 2/ 5], Step: [ 464/ 600], Loss: 0.2385\n",
      "Epoch: [ 2/ 5], Step: [ 465/ 600], Loss: 0.7315\n",
      "Epoch: [ 2/ 5], Step: [ 466/ 600], Loss: 0.6567\n",
      "Epoch: [ 2/ 5], Step: [ 467/ 600], Loss: 0.2112\n",
      "Epoch: [ 2/ 5], Step: [ 468/ 600], Loss: 0.0082\n",
      "Epoch: [ 2/ 5], Step: [ 469/ 600], Loss: 0.2410\n",
      "Epoch: [ 2/ 5], Step: [ 470/ 600], Loss: 0.1922\n",
      "Epoch: [ 2/ 5], Step: [ 471/ 600], Loss: 0.0072\n",
      "Epoch: [ 2/ 5], Step: [ 472/ 600], Loss: 0.0051\n",
      "Epoch: [ 2/ 5], Step: [ 473/ 600], Loss: 0.4359\n",
      "Epoch: [ 2/ 5], Step: [ 474/ 600], Loss: 0.2923\n",
      "Epoch: [ 2/ 5], Step: [ 475/ 600], Loss: 0.0297\n",
      "Epoch: [ 2/ 5], Step: [ 476/ 600], Loss: 0.3590\n",
      "Epoch: [ 2/ 5], Step: [ 477/ 600], Loss: 0.0257\n",
      "Epoch: [ 2/ 5], Step: [ 478/ 600], Loss: 0.0410\n",
      "Epoch: [ 2/ 5], Step: [ 479/ 600], Loss: 0.0415\n",
      "Epoch: [ 2/ 5], Step: [ 480/ 600], Loss: 1.0193\n",
      "Epoch: [ 2/ 5], Step: [ 481/ 600], Loss: 0.0116\n",
      "Epoch: [ 2/ 5], Step: [ 482/ 600], Loss: 1.7058\n",
      "Epoch: [ 2/ 5], Step: [ 483/ 600], Loss: 2.0283\n",
      "Epoch: [ 2/ 5], Step: [ 484/ 600], Loss: 0.0816\n",
      "Epoch: [ 2/ 5], Step: [ 485/ 600], Loss: 0.4382\n",
      "Epoch: [ 2/ 5], Step: [ 486/ 600], Loss: 0.0062\n",
      "Epoch: [ 2/ 5], Step: [ 487/ 600], Loss: 0.0385\n",
      "Epoch: [ 2/ 5], Step: [ 488/ 600], Loss: 3.9895\n",
      "Epoch: [ 2/ 5], Step: [ 489/ 600], Loss: 0.0408\n",
      "Epoch: [ 2/ 5], Step: [ 490/ 600], Loss: 2.1798\n",
      "Epoch: [ 2/ 5], Step: [ 491/ 600], Loss: 0.0615\n",
      "Epoch: [ 2/ 5], Step: [ 492/ 600], Loss: 0.1100\n",
      "Epoch: [ 2/ 5], Step: [ 493/ 600], Loss: 0.0103\n",
      "Epoch: [ 2/ 5], Step: [ 494/ 600], Loss: 0.8572\n",
      "Epoch: [ 2/ 5], Step: [ 495/ 600], Loss: 0.0018\n",
      "Epoch: [ 2/ 5], Step: [ 496/ 600], Loss: 0.1118\n",
      "Epoch: [ 2/ 5], Step: [ 497/ 600], Loss: 0.0161\n",
      "Epoch: [ 2/ 5], Step: [ 498/ 600], Loss: 0.0463\n",
      "Epoch: [ 2/ 5], Step: [ 499/ 600], Loss: 0.4239\n",
      "Epoch: [ 2/ 5], Step: [ 500/ 600], Loss: 0.0140\n",
      "Epoch: [ 2/ 5], Step: [ 501/ 600], Loss: 0.0175\n",
      "Epoch: [ 2/ 5], Step: [ 502/ 600], Loss: 0.0420\n",
      "Epoch: [ 2/ 5], Step: [ 503/ 600], Loss: 0.0246\n",
      "Epoch: [ 2/ 5], Step: [ 504/ 600], Loss: 0.0387\n",
      "Epoch: [ 2/ 5], Step: [ 505/ 600], Loss: 0.1644\n",
      "Epoch: [ 2/ 5], Step: [ 506/ 600], Loss: 0.0116\n",
      "Epoch: [ 2/ 5], Step: [ 507/ 600], Loss: 0.3157\n",
      "Epoch: [ 2/ 5], Step: [ 508/ 600], Loss: 0.8714\n",
      "Epoch: [ 2/ 5], Step: [ 509/ 600], Loss: 0.0155\n",
      "Epoch: [ 2/ 5], Step: [ 510/ 600], Loss: 0.3056\n",
      "Epoch: [ 2/ 5], Step: [ 511/ 600], Loss: 0.0462\n",
      "Epoch: [ 2/ 5], Step: [ 512/ 600], Loss: 0.0219\n",
      "Epoch: [ 2/ 5], Step: [ 513/ 600], Loss: 0.8161\n",
      "Epoch: [ 2/ 5], Step: [ 514/ 600], Loss: 0.0973\n",
      "Epoch: [ 2/ 5], Step: [ 515/ 600], Loss: 4.9473\n",
      "Epoch: [ 2/ 5], Step: [ 516/ 600], Loss: 0.0030\n",
      "Epoch: [ 2/ 5], Step: [ 517/ 600], Loss: 0.0974\n",
      "Epoch: [ 2/ 5], Step: [ 518/ 600], Loss: 1.1147\n",
      "Epoch: [ 2/ 5], Step: [ 519/ 600], Loss: 0.0058\n",
      "Epoch: [ 2/ 5], Step: [ 520/ 600], Loss: 1.0239\n",
      "Epoch: [ 2/ 5], Step: [ 521/ 600], Loss: 0.1070\n",
      "Epoch: [ 2/ 5], Step: [ 522/ 600], Loss: 0.0662\n",
      "Epoch: [ 2/ 5], Step: [ 523/ 600], Loss: 0.0006\n",
      "Epoch: [ 2/ 5], Step: [ 524/ 600], Loss: 0.1589\n",
      "Epoch: [ 2/ 5], Step: [ 525/ 600], Loss: 0.2031\n",
      "Epoch: [ 2/ 5], Step: [ 526/ 600], Loss: 0.0220\n",
      "Epoch: [ 2/ 5], Step: [ 527/ 600], Loss: 0.0366\n",
      "Epoch: [ 2/ 5], Step: [ 528/ 600], Loss: 0.0112\n",
      "Epoch: [ 2/ 5], Step: [ 529/ 600], Loss: 0.0035\n",
      "Epoch: [ 2/ 5], Step: [ 530/ 600], Loss: 3.3304\n",
      "Epoch: [ 2/ 5], Step: [ 531/ 600], Loss: 0.0061\n",
      "Epoch: [ 2/ 5], Step: [ 532/ 600], Loss: 0.0276\n",
      "Epoch: [ 2/ 5], Step: [ 533/ 600], Loss: 0.0142\n",
      "Epoch: [ 2/ 5], Step: [ 534/ 600], Loss: 0.1290\n",
      "Epoch: [ 2/ 5], Step: [ 535/ 600], Loss: 0.0822\n",
      "Epoch: [ 2/ 5], Step: [ 536/ 600], Loss: 0.8692\n",
      "Epoch: [ 2/ 5], Step: [ 537/ 600], Loss: 0.0517\n",
      "Epoch: [ 2/ 5], Step: [ 538/ 600], Loss: 0.0453\n",
      "Epoch: [ 2/ 5], Step: [ 539/ 600], Loss: 2.2440\n",
      "Epoch: [ 2/ 5], Step: [ 540/ 600], Loss: 0.0191\n",
      "Epoch: [ 2/ 5], Step: [ 541/ 600], Loss: 0.1130\n",
      "Epoch: [ 2/ 5], Step: [ 542/ 600], Loss: 0.0197\n",
      "Epoch: [ 2/ 5], Step: [ 543/ 600], Loss: 0.4043\n",
      "Epoch: [ 2/ 5], Step: [ 544/ 600], Loss: 0.1153\n",
      "Epoch: [ 2/ 5], Step: [ 545/ 600], Loss: 0.5114\n",
      "Epoch: [ 2/ 5], Step: [ 546/ 600], Loss: 0.3924\n",
      "Epoch: [ 2/ 5], Step: [ 547/ 600], Loss: 0.7499\n",
      "Epoch: [ 2/ 5], Step: [ 548/ 600], Loss: 0.0016\n",
      "Epoch: [ 2/ 5], Step: [ 549/ 600], Loss: 0.2952\n",
      "Epoch: [ 2/ 5], Step: [ 550/ 600], Loss: 0.0887\n",
      "Epoch: [ 2/ 5], Step: [ 551/ 600], Loss: 1.0774\n",
      "Epoch: [ 2/ 5], Step: [ 552/ 600], Loss: 0.6376\n",
      "Epoch: [ 2/ 5], Step: [ 553/ 600], Loss: 0.0078\n",
      "Epoch: [ 2/ 5], Step: [ 554/ 600], Loss: 0.2423\n",
      "Epoch: [ 2/ 5], Step: [ 555/ 600], Loss: 0.1338\n",
      "Epoch: [ 2/ 5], Step: [ 556/ 600], Loss: 0.2578\n",
      "Epoch: [ 2/ 5], Step: [ 557/ 600], Loss: 0.0282\n",
      "Epoch: [ 2/ 5], Step: [ 558/ 600], Loss: 0.0169\n",
      "Epoch: [ 2/ 5], Step: [ 559/ 600], Loss: 1.7893\n",
      "Epoch: [ 2/ 5], Step: [ 560/ 600], Loss: 0.0333\n",
      "Epoch: [ 2/ 5], Step: [ 561/ 600], Loss: 0.0546\n",
      "Epoch: [ 2/ 5], Step: [ 562/ 600], Loss: 5.4466\n",
      "Epoch: [ 2/ 5], Step: [ 563/ 600], Loss: 1.4992\n",
      "Epoch: [ 2/ 5], Step: [ 564/ 600], Loss: 0.0025\n",
      "Epoch: [ 2/ 5], Step: [ 565/ 600], Loss: 0.0001\n",
      "Epoch: [ 2/ 5], Step: [ 566/ 600], Loss: 0.0101\n",
      "Epoch: [ 2/ 5], Step: [ 567/ 600], Loss: 0.0070\n",
      "Epoch: [ 2/ 5], Step: [ 568/ 600], Loss: 0.0052\n",
      "Epoch: [ 2/ 5], Step: [ 569/ 600], Loss: 0.5105\n",
      "Epoch: [ 2/ 5], Step: [ 570/ 600], Loss: 0.2148\n",
      "Epoch: [ 2/ 5], Step: [ 571/ 600], Loss: 0.2646\n",
      "Epoch: [ 2/ 5], Step: [ 572/ 600], Loss: 0.0707\n",
      "Epoch: [ 2/ 5], Step: [ 573/ 600], Loss: 0.0551\n",
      "Epoch: [ 2/ 5], Step: [ 574/ 600], Loss: 0.1395\n",
      "Epoch: [ 2/ 5], Step: [ 575/ 600], Loss: 0.0132\n",
      "Epoch: [ 2/ 5], Step: [ 576/ 600], Loss: 0.0581\n",
      "Epoch: [ 2/ 5], Step: [ 577/ 600], Loss: 0.0733\n",
      "Epoch: [ 2/ 5], Step: [ 578/ 600], Loss: 0.0387\n",
      "Epoch: [ 2/ 5], Step: [ 579/ 600], Loss: 0.0561\n",
      "Epoch: [ 2/ 5], Step: [ 580/ 600], Loss: 2.0961\n",
      "Epoch: [ 2/ 5], Step: [ 581/ 600], Loss: 0.6121\n",
      "Epoch: [ 2/ 5], Step: [ 582/ 600], Loss: 0.0722\n",
      "Epoch: [ 2/ 5], Step: [ 583/ 600], Loss: 0.0066\n",
      "Epoch: [ 2/ 5], Step: [ 584/ 600], Loss: 0.1106\n",
      "Epoch: [ 2/ 5], Step: [ 585/ 600], Loss: 0.0320\n",
      "Epoch: [ 2/ 5], Step: [ 586/ 600], Loss: 0.6635\n",
      "Epoch: [ 2/ 5], Step: [ 587/ 600], Loss: 0.0740\n",
      "Epoch: [ 2/ 5], Step: [ 588/ 600], Loss: 0.0162\n",
      "Epoch: [ 2/ 5], Step: [ 589/ 600], Loss: 0.0057\n",
      "Epoch: [ 2/ 5], Step: [ 590/ 600], Loss: 0.4058\n",
      "Epoch: [ 2/ 5], Step: [ 591/ 600], Loss: 0.6799\n",
      "Epoch: [ 2/ 5], Step: [ 592/ 600], Loss: 0.0380\n",
      "Epoch: [ 2/ 5], Step: [ 593/ 600], Loss: 0.0122\n",
      "Epoch: [ 2/ 5], Step: [ 594/ 600], Loss: 0.0014\n",
      "Epoch: [ 2/ 5], Step: [ 595/ 600], Loss: 0.0128\n",
      "Epoch: [ 2/ 5], Step: [ 596/ 600], Loss: 0.1459\n",
      "Epoch: [ 2/ 5], Step: [ 597/ 600], Loss: 0.0001\n",
      "Epoch: [ 2/ 5], Step: [ 598/ 600], Loss: 0.5545\n",
      "Epoch: [ 2/ 5], Step: [ 599/ 600], Loss: 0.1021\n",
      "Epoch: [ 2/ 5], Step: [ 600/ 600], Loss: 0.0596\n",
      "Epoch: [ 3/ 5], Step: [ 1/ 600], Loss: 0.0221\n",
      "Epoch: [ 3/ 5], Step: [ 2/ 600], Loss: 0.1688\n",
      "Epoch: [ 3/ 5], Step: [ 3/ 600], Loss: 0.0097\n",
      "Epoch: [ 3/ 5], Step: [ 4/ 600], Loss: 0.3459\n",
      "Epoch: [ 3/ 5], Step: [ 5/ 600], Loss: 0.2183\n",
      "Epoch: [ 3/ 5], Step: [ 6/ 600], Loss: 0.1999\n",
      "Epoch: [ 3/ 5], Step: [ 7/ 600], Loss: 0.0174\n",
      "Epoch: [ 3/ 5], Step: [ 8/ 600], Loss: 0.1434\n",
      "Epoch: [ 3/ 5], Step: [ 9/ 600], Loss: 0.0166\n",
      "Epoch: [ 3/ 5], Step: [ 10/ 600], Loss: 2.0640\n",
      "Epoch: [ 3/ 5], Step: [ 11/ 600], Loss: 0.0032\n",
      "Epoch: [ 3/ 5], Step: [ 12/ 600], Loss: 0.0048\n",
      "Epoch: [ 3/ 5], Step: [ 13/ 600], Loss: 0.0641\n",
      "Epoch: [ 3/ 5], Step: [ 14/ 600], Loss: 0.1985\n",
      "Epoch: [ 3/ 5], Step: [ 15/ 600], Loss: 0.0709\n",
      "Epoch: [ 3/ 5], Step: [ 16/ 600], Loss: 0.0405\n",
      "Epoch: [ 3/ 5], Step: [ 17/ 600], Loss: 0.0039\n",
      "Epoch: [ 3/ 5], Step: [ 18/ 600], Loss: 0.0307\n",
      "Epoch: [ 3/ 5], Step: [ 19/ 600], Loss: 0.0445\n",
      "Epoch: [ 3/ 5], Step: [ 20/ 600], Loss: 0.0129\n",
      "Epoch: [ 3/ 5], Step: [ 21/ 600], Loss: 0.0396\n",
      "Epoch: [ 3/ 5], Step: [ 22/ 600], Loss: 5.5266\n",
      "Epoch: [ 3/ 5], Step: [ 23/ 600], Loss: 1.6107\n",
      "Epoch: [ 3/ 5], Step: [ 24/ 600], Loss: 0.1469\n",
      "Epoch: [ 3/ 5], Step: [ 25/ 600], Loss: 0.0490\n",
      "Epoch: [ 3/ 5], Step: [ 26/ 600], Loss: 0.0154\n",
      "Epoch: [ 3/ 5], Step: [ 27/ 600], Loss: 0.0113\n",
      "Epoch: [ 3/ 5], Step: [ 28/ 600], Loss: 0.0227\n",
      "Epoch: [ 3/ 5], Step: [ 29/ 600], Loss: 0.0002\n",
      "Epoch: [ 3/ 5], Step: [ 30/ 600], Loss: 0.1126\n",
      "Epoch: [ 3/ 5], Step: [ 31/ 600], Loss: 0.1219\n",
      "Epoch: [ 3/ 5], Step: [ 32/ 600], Loss: 0.4351\n",
      "Epoch: [ 3/ 5], Step: [ 33/ 600], Loss: 2.7597\n",
      "Epoch: [ 3/ 5], Step: [ 34/ 600], Loss: 2.0450\n",
      "Epoch: [ 3/ 5], Step: [ 35/ 600], Loss: 0.2427\n",
      "Epoch: [ 3/ 5], Step: [ 36/ 600], Loss: 0.0137\n",
      "Epoch: [ 3/ 5], Step: [ 37/ 600], Loss: 0.0142\n",
      "Epoch: [ 3/ 5], Step: [ 38/ 600], Loss: 0.0003\n",
      "Epoch: [ 3/ 5], Step: [ 39/ 600], Loss: 0.0010\n",
      "Epoch: [ 3/ 5], Step: [ 40/ 600], Loss: 0.0018\n",
      "Epoch: [ 3/ 5], Step: [ 41/ 600], Loss: 0.0047\n",
      "Epoch: [ 3/ 5], Step: [ 42/ 600], Loss: 0.0285\n",
      "Epoch: [ 3/ 5], Step: [ 43/ 600], Loss: 0.2707\n",
      "Epoch: [ 3/ 5], Step: [ 44/ 600], Loss: 0.0469\n",
      "Epoch: [ 3/ 5], Step: [ 45/ 600], Loss: 0.5768\n",
      "Epoch: [ 3/ 5], Step: [ 46/ 600], Loss: 0.0204\n",
      "Epoch: [ 3/ 5], Step: [ 47/ 600], Loss: 1.4498\n",
      "Epoch: [ 3/ 5], Step: [ 48/ 600], Loss: 0.1744\n",
      "Epoch: [ 3/ 5], Step: [ 49/ 600], Loss: 0.0160\n",
      "Epoch: [ 3/ 5], Step: [ 50/ 600], Loss: 0.2204\n",
      "Epoch: [ 3/ 5], Step: [ 51/ 600], Loss: 0.0957\n",
      "Epoch: [ 3/ 5], Step: [ 52/ 600], Loss: 0.2130\n",
      "Epoch: [ 3/ 5], Step: [ 53/ 600], Loss: 0.0216\n",
      "Epoch: [ 3/ 5], Step: [ 54/ 600], Loss: 0.0029\n",
      "Epoch: [ 3/ 5], Step: [ 55/ 600], Loss: 0.6059\n",
      "Epoch: [ 3/ 5], Step: [ 56/ 600], Loss: 0.0237\n",
      "Epoch: [ 3/ 5], Step: [ 57/ 600], Loss: 0.1717\n",
      "Epoch: [ 3/ 5], Step: [ 58/ 600], Loss: 1.1883\n",
      "Epoch: [ 3/ 5], Step: [ 59/ 600], Loss: 0.2380\n",
      "Epoch: [ 3/ 5], Step: [ 60/ 600], Loss: 0.0260\n",
      "Epoch: [ 3/ 5], Step: [ 61/ 600], Loss: 0.1831\n",
      "Epoch: [ 3/ 5], Step: [ 62/ 600], Loss: 0.2297\n",
      "Epoch: [ 3/ 5], Step: [ 63/ 600], Loss: 1.7131\n",
      "Epoch: [ 3/ 5], Step: [ 64/ 600], Loss: 2.9057\n",
      "Epoch: [ 3/ 5], Step: [ 65/ 600], Loss: 0.0797\n",
      "Epoch: [ 3/ 5], Step: [ 66/ 600], Loss: 0.0439\n",
      "Epoch: [ 3/ 5], Step: [ 67/ 600], Loss: 3.4838\n",
      "Epoch: [ 3/ 5], Step: [ 68/ 600], Loss: 0.3210\n",
      "Epoch: [ 3/ 5], Step: [ 69/ 600], Loss: 0.0781\n",
      "Epoch: [ 3/ 5], Step: [ 70/ 600], Loss: 0.0243\n",
      "Epoch: [ 3/ 5], Step: [ 71/ 600], Loss: 0.0201\n",
      "Epoch: [ 3/ 5], Step: [ 72/ 600], Loss: 0.0829\n",
      "Epoch: [ 3/ 5], Step: [ 73/ 600], Loss: 0.0860\n",
      "Epoch: [ 3/ 5], Step: [ 74/ 600], Loss: 0.0558\n",
      "Epoch: [ 3/ 5], Step: [ 75/ 600], Loss: 1.0448\n",
      "Epoch: [ 3/ 5], Step: [ 76/ 600], Loss: 0.0288\n",
      "Epoch: [ 3/ 5], Step: [ 77/ 600], Loss: 0.0337\n",
      "Epoch: [ 3/ 5], Step: [ 78/ 600], Loss: 0.0053\n",
      "Epoch: [ 3/ 5], Step: [ 79/ 600], Loss: 0.8688\n",
      "Epoch: [ 3/ 5], Step: [ 80/ 600], Loss: 0.2998\n",
      "Epoch: [ 3/ 5], Step: [ 81/ 600], Loss: 0.1577\n",
      "Epoch: [ 3/ 5], Step: [ 82/ 600], Loss: 0.0770\n",
      "Epoch: [ 3/ 5], Step: [ 83/ 600], Loss: 0.1604\n",
      "Epoch: [ 3/ 5], Step: [ 84/ 600], Loss: 1.0417\n",
      "Epoch: [ 3/ 5], Step: [ 85/ 600], Loss: 0.0531\n",
      "Epoch: [ 3/ 5], Step: [ 86/ 600], Loss: 0.0012\n",
      "Epoch: [ 3/ 5], Step: [ 87/ 600], Loss: 0.1053\n",
      "Epoch: [ 3/ 5], Step: [ 88/ 600], Loss: 0.2529\n",
      "Epoch: [ 3/ 5], Step: [ 89/ 600], Loss: 0.0715\n",
      "Epoch: [ 3/ 5], Step: [ 90/ 600], Loss: 0.7253\n",
      "Epoch: [ 3/ 5], Step: [ 91/ 600], Loss: 0.0401\n",
      "Epoch: [ 3/ 5], Step: [ 92/ 600], Loss: 0.3001\n",
      "Epoch: [ 3/ 5], Step: [ 93/ 600], Loss: 0.0356\n",
      "Epoch: [ 3/ 5], Step: [ 94/ 600], Loss: 0.1772\n",
      "Epoch: [ 3/ 5], Step: [ 95/ 600], Loss: 0.0001\n",
      "Epoch: [ 3/ 5], Step: [ 96/ 600], Loss: 0.0007\n",
      "Epoch: [ 3/ 5], Step: [ 97/ 600], Loss: 0.0166\n",
      "Epoch: [ 3/ 5], Step: [ 98/ 600], Loss: 0.0398\n",
      "Epoch: [ 3/ 5], Step: [ 99/ 600], Loss: 0.0267\n",
      "Epoch: [ 3/ 5], Step: [ 100/ 600], Loss: 0.3590\n",
      "Epoch: [ 3/ 5], Step: [ 101/ 600], Loss: 0.0375\n",
      "Epoch: [ 3/ 5], Step: [ 102/ 600], Loss: 0.0040\n",
      "Epoch: [ 3/ 5], Step: [ 103/ 600], Loss: 2.2640\n",
      "Epoch: [ 3/ 5], Step: [ 104/ 600], Loss: 0.2769\n",
      "Epoch: [ 3/ 5], Step: [ 105/ 600], Loss: 0.0145\n",
      "Epoch: [ 3/ 5], Step: [ 106/ 600], Loss: 0.0626\n",
      "Epoch: [ 3/ 5], Step: [ 107/ 600], Loss: 0.0386\n",
      "Epoch: [ 3/ 5], Step: [ 108/ 600], Loss: 3.4017\n",
      "Epoch: [ 3/ 5], Step: [ 109/ 600], Loss: 0.1100\n",
      "Epoch: [ 3/ 5], Step: [ 110/ 600], Loss: 4.2984\n",
      "Epoch: [ 3/ 5], Step: [ 111/ 600], Loss: 0.1476\n",
      "Epoch: [ 3/ 5], Step: [ 112/ 600], Loss: 0.0377\n",
      "Epoch: [ 3/ 5], Step: [ 113/ 600], Loss: 0.0146\n",
      "Epoch: [ 3/ 5], Step: [ 114/ 600], Loss: 0.0510\n",
      "Epoch: [ 3/ 5], Step: [ 115/ 600], Loss: 0.0447\n",
      "Epoch: [ 3/ 5], Step: [ 116/ 600], Loss: 1.5691\n",
      "Epoch: [ 3/ 5], Step: [ 117/ 600], Loss: 0.0519\n",
      "Epoch: [ 3/ 5], Step: [ 118/ 600], Loss: 0.0404\n",
      "Epoch: [ 3/ 5], Step: [ 119/ 600], Loss: 0.0055\n",
      "Epoch: [ 3/ 5], Step: [ 120/ 600], Loss: 0.0306\n",
      "Epoch: [ 3/ 5], Step: [ 121/ 600], Loss: 0.0030\n",
      "Epoch: [ 3/ 5], Step: [ 122/ 600], Loss: 0.0957\n",
      "Epoch: [ 3/ 5], Step: [ 123/ 600], Loss: 0.2574\n",
      "Epoch: [ 3/ 5], Step: [ 124/ 600], Loss: 0.0443\n",
      "Epoch: [ 3/ 5], Step: [ 125/ 600], Loss: 0.0019\n",
      "Epoch: [ 3/ 5], Step: [ 126/ 600], Loss: 0.1187\n",
      "Epoch: [ 3/ 5], Step: [ 127/ 600], Loss: 0.1447\n",
      "Epoch: [ 3/ 5], Step: [ 128/ 600], Loss: 0.0046\n",
      "Epoch: [ 3/ 5], Step: [ 129/ 600], Loss: 0.0096\n",
      "Epoch: [ 3/ 5], Step: [ 130/ 600], Loss: 0.5281\n",
      "Epoch: [ 3/ 5], Step: [ 131/ 600], Loss: 0.0389\n",
      "Epoch: [ 3/ 5], Step: [ 132/ 600], Loss: 0.0585\n",
      "Epoch: [ 3/ 5], Step: [ 133/ 600], Loss: 1.2297\n",
      "Epoch: [ 3/ 5], Step: [ 134/ 600], Loss: 0.1762\n",
      "Epoch: [ 3/ 5], Step: [ 135/ 600], Loss: 0.3163\n",
      "Epoch: [ 3/ 5], Step: [ 136/ 600], Loss: 0.0906\n",
      "Epoch: [ 3/ 5], Step: [ 137/ 600], Loss: 0.0242\n",
      "Epoch: [ 3/ 5], Step: [ 138/ 600], Loss: 0.0369\n",
      "Epoch: [ 3/ 5], Step: [ 139/ 600], Loss: 0.0322\n",
      "Epoch: [ 3/ 5], Step: [ 140/ 600], Loss: 0.0989\n",
      "Epoch: [ 3/ 5], Step: [ 141/ 600], Loss: 0.0000\n",
      "Epoch: [ 3/ 5], Step: [ 142/ 600], Loss: 0.0102\n",
      "Epoch: [ 3/ 5], Step: [ 143/ 600], Loss: 0.4601\n",
      "Epoch: [ 3/ 5], Step: [ 144/ 600], Loss: 0.8324\n",
      "Epoch: [ 3/ 5], Step: [ 145/ 600], Loss: 0.6891\n",
      "Epoch: [ 3/ 5], Step: [ 146/ 600], Loss: 0.1984\n",
      "Epoch: [ 3/ 5], Step: [ 147/ 600], Loss: 2.6951\n",
      "Epoch: [ 3/ 5], Step: [ 148/ 600], Loss: 1.1948\n",
      "Epoch: [ 3/ 5], Step: [ 149/ 600], Loss: 0.0011\n",
      "Epoch: [ 3/ 5], Step: [ 150/ 600], Loss: 0.0058\n",
      "Epoch: [ 3/ 5], Step: [ 151/ 600], Loss: 0.0390\n",
      "Epoch: [ 3/ 5], Step: [ 152/ 600], Loss: 0.0812\n",
      "Epoch: [ 3/ 5], Step: [ 153/ 600], Loss: 6.8329\n",
      "Epoch: [ 3/ 5], Step: [ 154/ 600], Loss: 0.0265\n",
      "Epoch: [ 3/ 5], Step: [ 155/ 600], Loss: 0.2936\n",
      "Epoch: [ 3/ 5], Step: [ 156/ 600], Loss: 0.1465\n",
      "Epoch: [ 3/ 5], Step: [ 157/ 600], Loss: 0.3864\n",
      "Epoch: [ 3/ 5], Step: [ 158/ 600], Loss: 0.0142\n",
      "Epoch: [ 3/ 5], Step: [ 159/ 600], Loss: 0.0285\n",
      "Epoch: [ 3/ 5], Step: [ 160/ 600], Loss: 0.1374\n",
      "Epoch: [ 3/ 5], Step: [ 161/ 600], Loss: 1.7635\n",
      "Epoch: [ 3/ 5], Step: [ 162/ 600], Loss: 0.0258\n",
      "Epoch: [ 3/ 5], Step: [ 163/ 600], Loss: 0.0768\n",
      "Epoch: [ 3/ 5], Step: [ 164/ 600], Loss: 0.6211\n",
      "Epoch: [ 3/ 5], Step: [ 165/ 600], Loss: 0.0805\n",
      "Epoch: [ 3/ 5], Step: [ 166/ 600], Loss: 0.0132\n",
      "Epoch: [ 3/ 5], Step: [ 167/ 600], Loss: 0.0004\n",
      "Epoch: [ 3/ 5], Step: [ 168/ 600], Loss: 0.0131\n",
      "Epoch: [ 3/ 5], Step: [ 169/ 600], Loss: 0.0108\n",
      "Epoch: [ 3/ 5], Step: [ 170/ 600], Loss: 0.0116\n",
      "Epoch: [ 3/ 5], Step: [ 171/ 600], Loss: 0.1059\n",
      "Epoch: [ 3/ 5], Step: [ 172/ 600], Loss: 0.8562\n",
      "Epoch: [ 3/ 5], Step: [ 173/ 600], Loss: 0.3886\n",
      "Epoch: [ 3/ 5], Step: [ 174/ 600], Loss: 0.0371\n",
      "Epoch: [ 3/ 5], Step: [ 175/ 600], Loss: 0.1953\n",
      "Epoch: [ 3/ 5], Step: [ 176/ 600], Loss: 0.0244\n",
      "Epoch: [ 3/ 5], Step: [ 177/ 600], Loss: 0.0035\n",
      "Epoch: [ 3/ 5], Step: [ 178/ 600], Loss: 0.0326\n",
      "Epoch: [ 3/ 5], Step: [ 179/ 600], Loss: 0.0176\n",
      "Epoch: [ 3/ 5], Step: [ 180/ 600], Loss: 0.5236\n",
      "Epoch: [ 3/ 5], Step: [ 181/ 600], Loss: 0.0854\n",
      "Epoch: [ 3/ 5], Step: [ 182/ 600], Loss: 0.2618\n",
      "Epoch: [ 3/ 5], Step: [ 183/ 600], Loss: 0.1652\n",
      "Epoch: [ 3/ 5], Step: [ 184/ 600], Loss: 2.8886\n",
      "Epoch: [ 3/ 5], Step: [ 185/ 600], Loss: 0.1906\n",
      "Epoch: [ 3/ 5], Step: [ 186/ 600], Loss: 0.0084\n",
      "Epoch: [ 3/ 5], Step: [ 187/ 600], Loss: 0.4186\n",
      "Epoch: [ 3/ 5], Step: [ 188/ 600], Loss: 0.1223\n",
      "Epoch: [ 3/ 5], Step: [ 189/ 600], Loss: 0.0386\n",
      "Epoch: [ 3/ 5], Step: [ 190/ 600], Loss: 0.0269\n",
      "Epoch: [ 3/ 5], Step: [ 191/ 600], Loss: 0.1208\n",
      "Epoch: [ 3/ 5], Step: [ 192/ 600], Loss: 0.0065\n",
      "Epoch: [ 3/ 5], Step: [ 193/ 600], Loss: 0.0010\n",
      "Epoch: [ 3/ 5], Step: [ 194/ 600], Loss: 0.3866\n",
      "Epoch: [ 3/ 5], Step: [ 195/ 600], Loss: 0.0107\n",
      "Epoch: [ 3/ 5], Step: [ 196/ 600], Loss: 1.8611\n",
      "Epoch: [ 3/ 5], Step: [ 197/ 600], Loss: 0.0391\n",
      "Epoch: [ 3/ 5], Step: [ 198/ 600], Loss: 0.0257\n",
      "Epoch: [ 3/ 5], Step: [ 199/ 600], Loss: 1.9264\n",
      "Epoch: [ 3/ 5], Step: [ 200/ 600], Loss: 0.0096\n",
      "Epoch: [ 3/ 5], Step: [ 201/ 600], Loss: 0.0164\n",
      "Epoch: [ 3/ 5], Step: [ 202/ 600], Loss: 0.0039\n",
      "Epoch: [ 3/ 5], Step: [ 203/ 600], Loss: 0.5760\n",
      "Epoch: [ 3/ 5], Step: [ 204/ 600], Loss: 0.0220\n",
      "Epoch: [ 3/ 5], Step: [ 205/ 600], Loss: 0.0102\n",
      "Epoch: [ 3/ 5], Step: [ 206/ 600], Loss: 1.3957\n",
      "Epoch: [ 3/ 5], Step: [ 207/ 600], Loss: 0.0003\n",
      "Epoch: [ 3/ 5], Step: [ 208/ 600], Loss: 0.0098\n",
      "Epoch: [ 3/ 5], Step: [ 209/ 600], Loss: 0.0181\n",
      "Epoch: [ 3/ 5], Step: [ 210/ 600], Loss: 0.3028\n",
      "Epoch: [ 3/ 5], Step: [ 211/ 600], Loss: 0.1661\n",
      "Epoch: [ 3/ 5], Step: [ 212/ 600], Loss: 0.0625\n",
      "Epoch: [ 3/ 5], Step: [ 213/ 600], Loss: 0.1652\n",
      "Epoch: [ 3/ 5], Step: [ 214/ 600], Loss: 0.0872\n",
      "Epoch: [ 3/ 5], Step: [ 215/ 600], Loss: 0.0205\n",
      "Epoch: [ 3/ 5], Step: [ 216/ 600], Loss: 0.0116\n",
      "Epoch: [ 3/ 5], Step: [ 217/ 600], Loss: 0.0238\n",
      "Epoch: [ 3/ 5], Step: [ 218/ 600], Loss: 0.0008\n",
      "Epoch: [ 3/ 5], Step: [ 219/ 600], Loss: 0.0226\n",
      "Epoch: [ 3/ 5], Step: [ 220/ 600], Loss: 0.1812\n",
      "Epoch: [ 3/ 5], Step: [ 221/ 600], Loss: 0.0360\n",
      "Epoch: [ 3/ 5], Step: [ 222/ 600], Loss: 0.1930\n",
      "Epoch: [ 3/ 5], Step: [ 223/ 600], Loss: 0.1414\n",
      "Epoch: [ 3/ 5], Step: [ 224/ 600], Loss: 0.0001\n",
      "Epoch: [ 3/ 5], Step: [ 225/ 600], Loss: 0.0166\n",
      "Epoch: [ 3/ 5], Step: [ 226/ 600], Loss: 0.0741\n",
      "Epoch: [ 3/ 5], Step: [ 227/ 600], Loss: 0.4454\n",
      "Epoch: [ 3/ 5], Step: [ 228/ 600], Loss: 0.0027\n",
      "Epoch: [ 3/ 5], Step: [ 229/ 600], Loss: 0.0892\n",
      "Epoch: [ 3/ 5], Step: [ 230/ 600], Loss: 0.1034\n",
      "Epoch: [ 3/ 5], Step: [ 231/ 600], Loss: 0.0013\n",
      "Epoch: [ 3/ 5], Step: [ 232/ 600], Loss: 0.1824\n",
      "Epoch: [ 3/ 5], Step: [ 233/ 600], Loss: 0.4557\n",
      "Epoch: [ 3/ 5], Step: [ 234/ 600], Loss: 0.6636\n",
      "Epoch: [ 3/ 5], Step: [ 235/ 600], Loss: 0.0416\n",
      "Epoch: [ 3/ 5], Step: [ 236/ 600], Loss: 0.0171\n",
      "Epoch: [ 3/ 5], Step: [ 237/ 600], Loss: 0.0164\n",
      "Epoch: [ 3/ 5], Step: [ 238/ 600], Loss: 0.0356\n",
      "Epoch: [ 3/ 5], Step: [ 239/ 600], Loss: 0.8114\n",
      "Epoch: [ 3/ 5], Step: [ 240/ 600], Loss: 0.0187\n",
      "Epoch: [ 3/ 5], Step: [ 241/ 600], Loss: 0.1348\n",
      "Epoch: [ 3/ 5], Step: [ 242/ 600], Loss: 0.4713\n",
      "Epoch: [ 3/ 5], Step: [ 243/ 600], Loss: 0.0422\n",
      "Epoch: [ 3/ 5], Step: [ 244/ 600], Loss: 0.0049\n",
      "Epoch: [ 3/ 5], Step: [ 245/ 600], Loss: 0.0349\n",
      "Epoch: [ 3/ 5], Step: [ 246/ 600], Loss: 0.0170\n",
      "Epoch: [ 3/ 5], Step: [ 247/ 600], Loss: 0.9160\n",
      "Epoch: [ 3/ 5], Step: [ 248/ 600], Loss: 0.0030\n",
      "Epoch: [ 3/ 5], Step: [ 249/ 600], Loss: 0.2455\n",
      "Epoch: [ 3/ 5], Step: [ 250/ 600], Loss: 0.0433\n",
      "Epoch: [ 3/ 5], Step: [ 251/ 600], Loss: 0.0144\n",
      "Epoch: [ 3/ 5], Step: [ 252/ 600], Loss: 0.0275\n",
      "Epoch: [ 3/ 5], Step: [ 253/ 600], Loss: 0.1540\n",
      "Epoch: [ 3/ 5], Step: [ 254/ 600], Loss: 0.3040\n",
      "Epoch: [ 3/ 5], Step: [ 255/ 600], Loss: 0.2459\n",
      "Epoch: [ 3/ 5], Step: [ 256/ 600], Loss: 0.4174\n",
      "Epoch: [ 3/ 5], Step: [ 257/ 600], Loss: 0.1584\n",
      "Epoch: [ 3/ 5], Step: [ 258/ 600], Loss: 0.0880\n",
      "Epoch: [ 3/ 5], Step: [ 259/ 600], Loss: 0.3278\n",
      "Epoch: [ 3/ 5], Step: [ 260/ 600], Loss: 1.5981\n",
      "Epoch: [ 3/ 5], Step: [ 261/ 600], Loss: 0.0515\n",
      "Epoch: [ 3/ 5], Step: [ 262/ 600], Loss: 0.0070\n",
      "Epoch: [ 3/ 5], Step: [ 263/ 600], Loss: 0.0427\n",
      "Epoch: [ 3/ 5], Step: [ 264/ 600], Loss: 0.0736\n",
      "Epoch: [ 3/ 5], Step: [ 265/ 600], Loss: 0.0042\n",
      "Epoch: [ 3/ 5], Step: [ 266/ 600], Loss: 0.0843\n",
      "Epoch: [ 3/ 5], Step: [ 267/ 600], Loss: 0.0498\n",
      "Epoch: [ 3/ 5], Step: [ 268/ 600], Loss: 3.6155\n",
      "Epoch: [ 3/ 5], Step: [ 269/ 600], Loss: 0.0212\n",
      "Epoch: [ 3/ 5], Step: [ 270/ 600], Loss: 0.0135\n",
      "Epoch: [ 3/ 5], Step: [ 271/ 600], Loss: 0.1007\n",
      "Epoch: [ 3/ 5], Step: [ 272/ 600], Loss: 1.1843\n",
      "Epoch: [ 3/ 5], Step: [ 273/ 600], Loss: 0.1094\n",
      "Epoch: [ 3/ 5], Step: [ 274/ 600], Loss: 0.4765\n",
      "Epoch: [ 3/ 5], Step: [ 275/ 600], Loss: 0.0283\n",
      "Epoch: [ 3/ 5], Step: [ 276/ 600], Loss: 0.0452\n",
      "Epoch: [ 3/ 5], Step: [ 277/ 600], Loss: 0.0194\n",
      "Epoch: [ 3/ 5], Step: [ 278/ 600], Loss: 0.0089\n",
      "Epoch: [ 3/ 5], Step: [ 279/ 600], Loss: 0.0043\n",
      "Epoch: [ 3/ 5], Step: [ 280/ 600], Loss: 0.0306\n",
      "Epoch: [ 3/ 5], Step: [ 281/ 600], Loss: 0.0026\n",
      "Epoch: [ 3/ 5], Step: [ 282/ 600], Loss: 0.0066\n",
      "Epoch: [ 3/ 5], Step: [ 283/ 600], Loss: 0.0134\n",
      "Epoch: [ 3/ 5], Step: [ 284/ 600], Loss: 0.0252\n",
      "Epoch: [ 3/ 5], Step: [ 285/ 600], Loss: 0.0531\n",
      "Epoch: [ 3/ 5], Step: [ 286/ 600], Loss: 0.0894\n",
      "Epoch: [ 3/ 5], Step: [ 287/ 600], Loss: 0.0135\n",
      "Epoch: [ 3/ 5], Step: [ 288/ 600], Loss: 0.2351\n",
      "Epoch: [ 3/ 5], Step: [ 289/ 600], Loss: 2.2479\n",
      "Epoch: [ 3/ 5], Step: [ 290/ 600], Loss: 0.2752\n",
      "Epoch: [ 3/ 5], Step: [ 291/ 600], Loss: 0.0024\n",
      "Epoch: [ 3/ 5], Step: [ 292/ 600], Loss: 0.1504\n",
      "Epoch: [ 3/ 5], Step: [ 293/ 600], Loss: 0.0810\n",
      "Epoch: [ 3/ 5], Step: [ 294/ 600], Loss: 0.0434\n",
      "Epoch: [ 3/ 5], Step: [ 295/ 600], Loss: 0.0962\n",
      "Epoch: [ 3/ 5], Step: [ 296/ 600], Loss: 0.0103\n",
      "Epoch: [ 3/ 5], Step: [ 297/ 600], Loss: 0.0069\n",
      "Epoch: [ 3/ 5], Step: [ 298/ 600], Loss: 1.1502\n",
      "Epoch: [ 3/ 5], Step: [ 299/ 600], Loss: 0.0059\n",
      "Epoch: [ 3/ 5], Step: [ 300/ 600], Loss: 0.0251\n",
      "Epoch: [ 3/ 5], Step: [ 301/ 600], Loss: 0.0058\n",
      "Epoch: [ 3/ 5], Step: [ 302/ 600], Loss: 0.0942\n",
      "Epoch: [ 3/ 5], Step: [ 303/ 600], Loss: 0.0123\n",
      "Epoch: [ 3/ 5], Step: [ 304/ 600], Loss: 0.6906\n",
      "Epoch: [ 3/ 5], Step: [ 305/ 600], Loss: 0.3595\n",
      "Epoch: [ 3/ 5], Step: [ 306/ 600], Loss: 0.1246\n",
      "Epoch: [ 3/ 5], Step: [ 307/ 600], Loss: 0.0357\n",
      "Epoch: [ 3/ 5], Step: [ 308/ 600], Loss: 0.0057\n",
      "Epoch: [ 3/ 5], Step: [ 309/ 600], Loss: 0.0256\n",
      "Epoch: [ 3/ 5], Step: [ 310/ 600], Loss: 0.0451\n",
      "Epoch: [ 3/ 5], Step: [ 311/ 600], Loss: 0.0147\n",
      "Epoch: [ 3/ 5], Step: [ 312/ 600], Loss: 0.0343\n",
      "Epoch: [ 3/ 5], Step: [ 313/ 600], Loss: 0.8022\n",
      "Epoch: [ 3/ 5], Step: [ 314/ 600], Loss: 0.0156\n",
      "Epoch: [ 3/ 5], Step: [ 315/ 600], Loss: 0.0205\n",
      "Epoch: [ 3/ 5], Step: [ 316/ 600], Loss: 0.0755\n",
      "Epoch: [ 3/ 5], Step: [ 317/ 600], Loss: 0.0125\n",
      "Epoch: [ 3/ 5], Step: [ 318/ 600], Loss: 0.0046\n",
      "Epoch: [ 3/ 5], Step: [ 319/ 600], Loss: 0.0005\n",
      "Epoch: [ 3/ 5], Step: [ 320/ 600], Loss: 0.1316\n",
      "Epoch: [ 3/ 5], Step: [ 321/ 600], Loss: 2.6532\n",
      "Epoch: [ 3/ 5], Step: [ 322/ 600], Loss: 1.9425\n",
      "Epoch: [ 3/ 5], Step: [ 323/ 600], Loss: 0.0186\n",
      "Epoch: [ 3/ 5], Step: [ 324/ 600], Loss: 0.2078\n",
      "Epoch: [ 3/ 5], Step: [ 325/ 600], Loss: 2.1240\n",
      "Epoch: [ 3/ 5], Step: [ 326/ 600], Loss: 0.0242\n",
      "Epoch: [ 3/ 5], Step: [ 327/ 600], Loss: 0.0077\n",
      "Epoch: [ 3/ 5], Step: [ 328/ 600], Loss: 0.1720\n",
      "Epoch: [ 3/ 5], Step: [ 329/ 600], Loss: 0.5831\n",
      "Epoch: [ 3/ 5], Step: [ 330/ 600], Loss: 0.0329\n",
      "Epoch: [ 3/ 5], Step: [ 331/ 600], Loss: 0.6367\n",
      "Epoch: [ 3/ 5], Step: [ 332/ 600], Loss: 0.0151\n",
      "Epoch: [ 3/ 5], Step: [ 333/ 600], Loss: 0.0759\n",
      "Epoch: [ 3/ 5], Step: [ 334/ 600], Loss: 0.3521\n",
      "Epoch: [ 3/ 5], Step: [ 335/ 600], Loss: 0.4416\n",
      "Epoch: [ 3/ 5], Step: [ 336/ 600], Loss: 0.9971\n",
      "Epoch: [ 3/ 5], Step: [ 337/ 600], Loss: 0.0780\n",
      "Epoch: [ 3/ 5], Step: [ 338/ 600], Loss: 0.0956\n",
      "Epoch: [ 3/ 5], Step: [ 339/ 600], Loss: 0.2792\n",
      "Epoch: [ 3/ 5], Step: [ 340/ 600], Loss: 0.0227\n",
      "Epoch: [ 3/ 5], Step: [ 341/ 600], Loss: 0.0547\n",
      "Epoch: [ 3/ 5], Step: [ 342/ 600], Loss: 0.0337\n",
      "Epoch: [ 3/ 5], Step: [ 343/ 600], Loss: 0.0715\n",
      "Epoch: [ 3/ 5], Step: [ 344/ 600], Loss: 0.0011\n",
      "Epoch: [ 3/ 5], Step: [ 345/ 600], Loss: 0.0121\n",
      "Epoch: [ 3/ 5], Step: [ 346/ 600], Loss: 0.0309\n",
      "Epoch: [ 3/ 5], Step: [ 347/ 600], Loss: 0.2655\n",
      "Epoch: [ 3/ 5], Step: [ 348/ 600], Loss: 0.0531\n",
      "Epoch: [ 3/ 5], Step: [ 349/ 600], Loss: 0.0136\n",
      "Epoch: [ 3/ 5], Step: [ 350/ 600], Loss: 0.1647\n",
      "Epoch: [ 3/ 5], Step: [ 351/ 600], Loss: 0.0073\n",
      "Epoch: [ 3/ 5], Step: [ 352/ 600], Loss: 0.0021\n",
      "Epoch: [ 3/ 5], Step: [ 353/ 600], Loss: 0.0010\n",
      "Epoch: [ 3/ 5], Step: [ 354/ 600], Loss: 1.5327\n",
      "Epoch: [ 3/ 5], Step: [ 355/ 600], Loss: 0.5577\n",
      "Epoch: [ 3/ 5], Step: [ 356/ 600], Loss: 0.0055\n",
      "Epoch: [ 3/ 5], Step: [ 357/ 600], Loss: 0.0813\n",
      "Epoch: [ 3/ 5], Step: [ 358/ 600], Loss: 0.0137\n",
      "Epoch: [ 3/ 5], Step: [ 359/ 600], Loss: 1.2159\n",
      "Epoch: [ 3/ 5], Step: [ 360/ 600], Loss: 0.0106\n",
      "Epoch: [ 3/ 5], Step: [ 361/ 600], Loss: 0.0010\n",
      "Epoch: [ 3/ 5], Step: [ 362/ 600], Loss: 0.0301\n",
      "Epoch: [ 3/ 5], Step: [ 363/ 600], Loss: 0.0309\n",
      "Epoch: [ 3/ 5], Step: [ 364/ 600], Loss: 0.0017\n",
      "Epoch: [ 3/ 5], Step: [ 365/ 600], Loss: 0.0015\n",
      "Epoch: [ 3/ 5], Step: [ 366/ 600], Loss: 0.0016\n",
      "Epoch: [ 3/ 5], Step: [ 367/ 600], Loss: 8.0118\n",
      "Epoch: [ 3/ 5], Step: [ 368/ 600], Loss: 0.0005\n",
      "Epoch: [ 3/ 5], Step: [ 369/ 600], Loss: 0.0002\n",
      "Epoch: [ 3/ 5], Step: [ 370/ 600], Loss: 0.1549\n",
      "Epoch: [ 3/ 5], Step: [ 371/ 600], Loss: 0.0106\n",
      "Epoch: [ 3/ 5], Step: [ 372/ 600], Loss: 0.1336\n",
      "Epoch: [ 3/ 5], Step: [ 373/ 600], Loss: 0.1802\n",
      "Epoch: [ 3/ 5], Step: [ 374/ 600], Loss: 0.0759\n",
      "Epoch: [ 3/ 5], Step: [ 375/ 600], Loss: 0.0378\n",
      "Epoch: [ 3/ 5], Step: [ 376/ 600], Loss: 1.0853\n",
      "Epoch: [ 3/ 5], Step: [ 377/ 600], Loss: 0.3010\n",
      "Epoch: [ 3/ 5], Step: [ 378/ 600], Loss: 0.0073\n",
      "Epoch: [ 3/ 5], Step: [ 379/ 600], Loss: 0.1494\n",
      "Epoch: [ 3/ 5], Step: [ 380/ 600], Loss: 0.0213\n",
      "Epoch: [ 3/ 5], Step: [ 381/ 600], Loss: 0.0033\n",
      "Epoch: [ 3/ 5], Step: [ 382/ 600], Loss: 0.0018\n",
      "Epoch: [ 3/ 5], Step: [ 383/ 600], Loss: 0.0022\n",
      "Epoch: [ 3/ 5], Step: [ 384/ 600], Loss: 0.0189\n",
      "Epoch: [ 3/ 5], Step: [ 385/ 600], Loss: 0.0303\n",
      "Epoch: [ 3/ 5], Step: [ 386/ 600], Loss: 0.0027\n",
      "Epoch: [ 3/ 5], Step: [ 387/ 600], Loss: 0.0185\n",
      "Epoch: [ 3/ 5], Step: [ 388/ 600], Loss: 0.0348\n",
      "Epoch: [ 3/ 5], Step: [ 389/ 600], Loss: 0.0027\n",
      "Epoch: [ 3/ 5], Step: [ 390/ 600], Loss: 3.8610\n",
      "Epoch: [ 3/ 5], Step: [ 391/ 600], Loss: 0.0090\n",
      "Epoch: [ 3/ 5], Step: [ 392/ 600], Loss: 1.7130\n",
      "Epoch: [ 3/ 5], Step: [ 393/ 600], Loss: 0.1235\n",
      "Epoch: [ 3/ 5], Step: [ 394/ 600], Loss: 0.7319\n",
      "Epoch: [ 3/ 5], Step: [ 395/ 600], Loss: 0.0681\n",
      "Epoch: [ 3/ 5], Step: [ 396/ 600], Loss: 0.0263\n",
      "Epoch: [ 3/ 5], Step: [ 397/ 600], Loss: 0.2385\n",
      "Epoch: [ 3/ 5], Step: [ 398/ 600], Loss: 0.0004\n",
      "Epoch: [ 3/ 5], Step: [ 399/ 600], Loss: 0.0245\n",
      "Epoch: [ 3/ 5], Step: [ 400/ 600], Loss: 0.8862\n",
      "Epoch: [ 3/ 5], Step: [ 401/ 600], Loss: 0.0436\n",
      "Epoch: [ 3/ 5], Step: [ 402/ 600], Loss: 0.0052\n",
      "Epoch: [ 3/ 5], Step: [ 403/ 600], Loss: 1.0113\n",
      "Epoch: [ 3/ 5], Step: [ 404/ 600], Loss: 0.0097\n",
      "Epoch: [ 3/ 5], Step: [ 405/ 600], Loss: 0.0017\n",
      "Epoch: [ 3/ 5], Step: [ 406/ 600], Loss: 0.0017\n",
      "Epoch: [ 3/ 5], Step: [ 407/ 600], Loss: 0.0014\n",
      "Epoch: [ 3/ 5], Step: [ 408/ 600], Loss: 0.0254\n",
      "Epoch: [ 3/ 5], Step: [ 409/ 600], Loss: 0.4130\n",
      "Epoch: [ 3/ 5], Step: [ 410/ 600], Loss: 0.3345\n",
      "Epoch: [ 3/ 5], Step: [ 411/ 600], Loss: 0.0130\n",
      "Epoch: [ 3/ 5], Step: [ 412/ 600], Loss: 0.0803\n",
      "Epoch: [ 3/ 5], Step: [ 413/ 600], Loss: 0.0521\n",
      "Epoch: [ 3/ 5], Step: [ 414/ 600], Loss: 0.0548\n",
      "Epoch: [ 3/ 5], Step: [ 415/ 600], Loss: 0.0117\n",
      "Epoch: [ 3/ 5], Step: [ 416/ 600], Loss: 0.0688\n",
      "Epoch: [ 3/ 5], Step: [ 417/ 600], Loss: 0.0333\n",
      "Epoch: [ 3/ 5], Step: [ 418/ 600], Loss: 0.0819\n",
      "Epoch: [ 3/ 5], Step: [ 419/ 600], Loss: 0.0388\n",
      "Epoch: [ 3/ 5], Step: [ 420/ 600], Loss: 0.0732\n",
      "Epoch: [ 3/ 5], Step: [ 421/ 600], Loss: 0.0719\n",
      "Epoch: [ 3/ 5], Step: [ 422/ 600], Loss: 0.0101\n",
      "Epoch: [ 3/ 5], Step: [ 423/ 600], Loss: 0.8811\n",
      "Epoch: [ 3/ 5], Step: [ 424/ 600], Loss: 0.0024\n",
      "Epoch: [ 3/ 5], Step: [ 425/ 600], Loss: 0.1532\n",
      "Epoch: [ 3/ 5], Step: [ 426/ 600], Loss: 0.0049\n",
      "Epoch: [ 3/ 5], Step: [ 427/ 600], Loss: 0.0225\n",
      "Epoch: [ 3/ 5], Step: [ 428/ 600], Loss: 0.0056\n",
      "Epoch: [ 3/ 5], Step: [ 429/ 600], Loss: 0.2600\n",
      "Epoch: [ 3/ 5], Step: [ 430/ 600], Loss: 0.4108\n",
      "Epoch: [ 3/ 5], Step: [ 431/ 600], Loss: 2.0307\n",
      "Epoch: [ 3/ 5], Step: [ 432/ 600], Loss: 0.0025\n",
      "Epoch: [ 3/ 5], Step: [ 433/ 600], Loss: 4.5812\n",
      "Epoch: [ 3/ 5], Step: [ 434/ 600], Loss: 0.0665\n",
      "Epoch: [ 3/ 5], Step: [ 435/ 600], Loss: 0.9129\n",
      "Epoch: [ 3/ 5], Step: [ 436/ 600], Loss: 0.3327\n",
      "Epoch: [ 3/ 5], Step: [ 437/ 600], Loss: 0.0121\n",
      "Epoch: [ 3/ 5], Step: [ 438/ 600], Loss: 0.1940\n",
      "Epoch: [ 3/ 5], Step: [ 439/ 600], Loss: 1.3288\n",
      "Epoch: [ 3/ 5], Step: [ 440/ 600], Loss: 0.1404\n",
      "Epoch: [ 3/ 5], Step: [ 441/ 600], Loss: 0.0020\n",
      "Epoch: [ 3/ 5], Step: [ 442/ 600], Loss: 2.8460\n",
      "Epoch: [ 3/ 5], Step: [ 443/ 600], Loss: 0.9978\n",
      "Epoch: [ 3/ 5], Step: [ 444/ 600], Loss: 0.0084\n",
      "Epoch: [ 3/ 5], Step: [ 445/ 600], Loss: 0.0455\n",
      "Epoch: [ 3/ 5], Step: [ 446/ 600], Loss: 0.2964\n",
      "Epoch: [ 3/ 5], Step: [ 447/ 600], Loss: 0.2098\n",
      "Epoch: [ 3/ 5], Step: [ 448/ 600], Loss: 0.0208\n",
      "Epoch: [ 3/ 5], Step: [ 449/ 600], Loss: 0.5086\n",
      "Epoch: [ 3/ 5], Step: [ 450/ 600], Loss: 0.0387\n",
      "Epoch: [ 3/ 5], Step: [ 451/ 600], Loss: 0.4311\n",
      "Epoch: [ 3/ 5], Step: [ 452/ 600], Loss: 0.1083\n",
      "Epoch: [ 3/ 5], Step: [ 453/ 600], Loss: 0.4682\n",
      "Epoch: [ 3/ 5], Step: [ 454/ 600], Loss: 0.0066\n",
      "Epoch: [ 3/ 5], Step: [ 455/ 600], Loss: 1.1763\n",
      "Epoch: [ 3/ 5], Step: [ 456/ 600], Loss: 0.0058\n",
      "Epoch: [ 3/ 5], Step: [ 457/ 600], Loss: 0.0938\n",
      "Epoch: [ 3/ 5], Step: [ 458/ 600], Loss: 0.0048\n",
      "Epoch: [ 3/ 5], Step: [ 459/ 600], Loss: 0.1010\n",
      "Epoch: [ 3/ 5], Step: [ 460/ 600], Loss: 0.0377\n",
      "Epoch: [ 3/ 5], Step: [ 461/ 600], Loss: 0.0022\n",
      "Epoch: [ 3/ 5], Step: [ 462/ 600], Loss: 0.1230\n",
      "Epoch: [ 3/ 5], Step: [ 463/ 600], Loss: 1.1438\n",
      "Epoch: [ 3/ 5], Step: [ 464/ 600], Loss: 0.0001\n",
      "Epoch: [ 3/ 5], Step: [ 465/ 600], Loss: 0.0216\n",
      "Epoch: [ 3/ 5], Step: [ 466/ 600], Loss: 0.0141\n",
      "Epoch: [ 3/ 5], Step: [ 467/ 600], Loss: 0.0193\n",
      "Epoch: [ 3/ 5], Step: [ 468/ 600], Loss: 1.9490\n",
      "Epoch: [ 3/ 5], Step: [ 469/ 600], Loss: 3.7865\n",
      "Epoch: [ 3/ 5], Step: [ 470/ 600], Loss: 0.0633\n",
      "Epoch: [ 3/ 5], Step: [ 471/ 600], Loss: 0.0316\n",
      "Epoch: [ 3/ 5], Step: [ 472/ 600], Loss: 0.2283\n",
      "Epoch: [ 3/ 5], Step: [ 473/ 600], Loss: 0.0041\n",
      "Epoch: [ 3/ 5], Step: [ 474/ 600], Loss: 4.2889\n",
      "Epoch: [ 3/ 5], Step: [ 475/ 600], Loss: 0.1022\n",
      "Epoch: [ 3/ 5], Step: [ 476/ 600], Loss: 0.0114\n",
      "Epoch: [ 3/ 5], Step: [ 477/ 600], Loss: 0.1413\n",
      "Epoch: [ 3/ 5], Step: [ 478/ 600], Loss: 0.0019\n",
      "Epoch: [ 3/ 5], Step: [ 479/ 600], Loss: 1.3558\n",
      "Epoch: [ 3/ 5], Step: [ 480/ 600], Loss: 0.0180\n",
      "Epoch: [ 3/ 5], Step: [ 481/ 600], Loss: 0.0842\n",
      "Epoch: [ 3/ 5], Step: [ 482/ 600], Loss: 0.2037\n",
      "Epoch: [ 3/ 5], Step: [ 483/ 600], Loss: 0.0167\n",
      "Epoch: [ 3/ 5], Step: [ 484/ 600], Loss: 0.0109\n",
      "Epoch: [ 3/ 5], Step: [ 485/ 600], Loss: 0.0056\n",
      "Epoch: [ 3/ 5], Step: [ 486/ 600], Loss: 6.8715\n",
      "Epoch: [ 3/ 5], Step: [ 487/ 600], Loss: 0.1320\n",
      "Epoch: [ 3/ 5], Step: [ 488/ 600], Loss: 0.0351\n",
      "Epoch: [ 3/ 5], Step: [ 489/ 600], Loss: 0.3708\n",
      "Epoch: [ 3/ 5], Step: [ 490/ 600], Loss: 0.1752\n",
      "Epoch: [ 3/ 5], Step: [ 491/ 600], Loss: 1.9711\n",
      "Epoch: [ 3/ 5], Step: [ 492/ 600], Loss: 0.1295\n",
      "Epoch: [ 3/ 5], Step: [ 493/ 600], Loss: 0.0153\n",
      "Epoch: [ 3/ 5], Step: [ 494/ 600], Loss: 0.1959\n",
      "Epoch: [ 3/ 5], Step: [ 495/ 600], Loss: 0.0388\n",
      "Epoch: [ 3/ 5], Step: [ 496/ 600], Loss: 0.1886\n",
      "Epoch: [ 3/ 5], Step: [ 497/ 600], Loss: 0.0962\n",
      "Epoch: [ 3/ 5], Step: [ 498/ 600], Loss: 0.0231\n",
      "Epoch: [ 3/ 5], Step: [ 499/ 600], Loss: 0.1918\n",
      "Epoch: [ 3/ 5], Step: [ 500/ 600], Loss: 0.0187\n",
      "Epoch: [ 3/ 5], Step: [ 501/ 600], Loss: 0.0078\n",
      "Epoch: [ 3/ 5], Step: [ 502/ 600], Loss: 0.0028\n",
      "Epoch: [ 3/ 5], Step: [ 503/ 600], Loss: 0.0259\n",
      "Epoch: [ 3/ 5], Step: [ 504/ 600], Loss: 0.0165\n",
      "Epoch: [ 3/ 5], Step: [ 505/ 600], Loss: 0.0015\n",
      "Epoch: [ 3/ 5], Step: [ 506/ 600], Loss: 3.1538\n",
      "Epoch: [ 3/ 5], Step: [ 507/ 600], Loss: 0.3682\n",
      "Epoch: [ 3/ 5], Step: [ 508/ 600], Loss: 0.0135\n",
      "Epoch: [ 3/ 5], Step: [ 509/ 600], Loss: 1.8766\n",
      "Epoch: [ 3/ 5], Step: [ 510/ 600], Loss: 0.0913\n",
      "Epoch: [ 3/ 5], Step: [ 511/ 600], Loss: 0.3146\n",
      "Epoch: [ 3/ 5], Step: [ 512/ 600], Loss: 0.0029\n",
      "Epoch: [ 3/ 5], Step: [ 513/ 600], Loss: 0.0149\n",
      "Epoch: [ 3/ 5], Step: [ 514/ 600], Loss: 0.2563\n",
      "Epoch: [ 3/ 5], Step: [ 515/ 600], Loss: 0.5850\n",
      "Epoch: [ 3/ 5], Step: [ 516/ 600], Loss: 0.6233\n",
      "Epoch: [ 3/ 5], Step: [ 517/ 600], Loss: 0.0053\n",
      "Epoch: [ 3/ 5], Step: [ 518/ 600], Loss: 0.1019\n",
      "Epoch: [ 3/ 5], Step: [ 519/ 600], Loss: 0.0134\n",
      "Epoch: [ 3/ 5], Step: [ 520/ 600], Loss: 0.0011\n",
      "Epoch: [ 3/ 5], Step: [ 521/ 600], Loss: 0.0096\n",
      "Epoch: [ 3/ 5], Step: [ 522/ 600], Loss: 0.0250\n",
      "Epoch: [ 3/ 5], Step: [ 523/ 600], Loss: 0.0012\n",
      "Epoch: [ 3/ 5], Step: [ 524/ 600], Loss: 0.0210\n",
      "Epoch: [ 3/ 5], Step: [ 525/ 600], Loss: 0.0001\n",
      "Epoch: [ 3/ 5], Step: [ 526/ 600], Loss: 0.0589\n",
      "Epoch: [ 3/ 5], Step: [ 527/ 600], Loss: 1.5025\n",
      "Epoch: [ 3/ 5], Step: [ 528/ 600], Loss: 1.2448\n",
      "Epoch: [ 3/ 5], Step: [ 529/ 600], Loss: 0.3119\n",
      "Epoch: [ 3/ 5], Step: [ 530/ 600], Loss: 0.6797\n",
      "Epoch: [ 3/ 5], Step: [ 531/ 600], Loss: 0.0018\n",
      "Epoch: [ 3/ 5], Step: [ 532/ 600], Loss: 0.0139\n",
      "Epoch: [ 3/ 5], Step: [ 533/ 600], Loss: 0.0299\n",
      "Epoch: [ 3/ 5], Step: [ 534/ 600], Loss: 0.0272\n",
      "Epoch: [ 3/ 5], Step: [ 535/ 600], Loss: 0.0014\n",
      "Epoch: [ 3/ 5], Step: [ 536/ 600], Loss: 1.1122\n",
      "Epoch: [ 3/ 5], Step: [ 537/ 600], Loss: 0.5134\n",
      "Epoch: [ 3/ 5], Step: [ 538/ 600], Loss: 0.2469\n",
      "Epoch: [ 3/ 5], Step: [ 539/ 600], Loss: 0.0014\n",
      "Epoch: [ 3/ 5], Step: [ 540/ 600], Loss: 0.0273\n",
      "Epoch: [ 3/ 5], Step: [ 541/ 600], Loss: 0.0281\n",
      "Epoch: [ 3/ 5], Step: [ 542/ 600], Loss: 0.1215\n",
      "Epoch: [ 3/ 5], Step: [ 543/ 600], Loss: 0.0208\n",
      "Epoch: [ 3/ 5], Step: [ 544/ 600], Loss: 0.0018\n",
      "Epoch: [ 3/ 5], Step: [ 545/ 600], Loss: 0.0985\n",
      "Epoch: [ 3/ 5], Step: [ 546/ 600], Loss: 0.1207\n",
      "Epoch: [ 3/ 5], Step: [ 547/ 600], Loss: 0.0125\n",
      "Epoch: [ 3/ 5], Step: [ 548/ 600], Loss: 0.0208\n",
      "Epoch: [ 3/ 5], Step: [ 549/ 600], Loss: 0.0623\n",
      "Epoch: [ 3/ 5], Step: [ 550/ 600], Loss: 0.0960\n",
      "Epoch: [ 3/ 5], Step: [ 551/ 600], Loss: 0.0939\n",
      "Epoch: [ 3/ 5], Step: [ 552/ 600], Loss: 0.2697\n",
      "Epoch: [ 3/ 5], Step: [ 553/ 600], Loss: 0.1224\n",
      "Epoch: [ 3/ 5], Step: [ 554/ 600], Loss: 0.2900\n",
      "Epoch: [ 3/ 5], Step: [ 555/ 600], Loss: 0.0577\n",
      "Epoch: [ 3/ 5], Step: [ 556/ 600], Loss: 4.0398\n",
      "Epoch: [ 3/ 5], Step: [ 557/ 600], Loss: 0.0106\n",
      "Epoch: [ 3/ 5], Step: [ 558/ 600], Loss: 1.1036\n",
      "Epoch: [ 3/ 5], Step: [ 559/ 600], Loss: 0.1375\n",
      "Epoch: [ 3/ 5], Step: [ 560/ 600], Loss: 0.0710\n",
      "Epoch: [ 3/ 5], Step: [ 561/ 600], Loss: 0.0095\n",
      "Epoch: [ 3/ 5], Step: [ 562/ 600], Loss: 0.0587\n",
      "Epoch: [ 3/ 5], Step: [ 563/ 600], Loss: 0.5610\n",
      "Epoch: [ 3/ 5], Step: [ 564/ 600], Loss: 0.0520\n",
      "Epoch: [ 3/ 5], Step: [ 565/ 600], Loss: 0.0024\n",
      "Epoch: [ 3/ 5], Step: [ 566/ 600], Loss: 3.1603\n",
      "Epoch: [ 3/ 5], Step: [ 567/ 600], Loss: 0.0089\n",
      "Epoch: [ 3/ 5], Step: [ 568/ 600], Loss: 0.0441\n",
      "Epoch: [ 3/ 5], Step: [ 569/ 600], Loss: 0.0905\n",
      "Epoch: [ 3/ 5], Step: [ 570/ 600], Loss: 0.0115\n",
      "Epoch: [ 3/ 5], Step: [ 571/ 600], Loss: 1.4248\n",
      "Epoch: [ 3/ 5], Step: [ 572/ 600], Loss: 0.1052\n",
      "Epoch: [ 3/ 5], Step: [ 573/ 600], Loss: 0.1533\n",
      "Epoch: [ 3/ 5], Step: [ 574/ 600], Loss: 0.1400\n",
      "Epoch: [ 3/ 5], Step: [ 575/ 600], Loss: 0.0747\n",
      "Epoch: [ 3/ 5], Step: [ 576/ 600], Loss: 0.7357\n",
      "Epoch: [ 3/ 5], Step: [ 577/ 600], Loss: 0.0195\n",
      "Epoch: [ 3/ 5], Step: [ 578/ 600], Loss: 0.5718\n",
      "Epoch: [ 3/ 5], Step: [ 579/ 600], Loss: 0.0056\n",
      "Epoch: [ 3/ 5], Step: [ 580/ 600], Loss: 0.5114\n",
      "Epoch: [ 3/ 5], Step: [ 581/ 600], Loss: 2.3710\n",
      "Epoch: [ 3/ 5], Step: [ 582/ 600], Loss: 0.0652\n",
      "Epoch: [ 3/ 5], Step: [ 583/ 600], Loss: 0.0062\n",
      "Epoch: [ 3/ 5], Step: [ 584/ 600], Loss: 0.0326\n",
      "Epoch: [ 3/ 5], Step: [ 585/ 600], Loss: 0.0207\n",
      "Epoch: [ 3/ 5], Step: [ 586/ 600], Loss: 0.0423\n",
      "Epoch: [ 3/ 5], Step: [ 587/ 600], Loss: 0.0710\n",
      "Epoch: [ 3/ 5], Step: [ 588/ 600], Loss: 0.0290\n",
      "Epoch: [ 3/ 5], Step: [ 589/ 600], Loss: 0.0208\n",
      "Epoch: [ 3/ 5], Step: [ 590/ 600], Loss: 0.0505\n",
      "Epoch: [ 3/ 5], Step: [ 591/ 600], Loss: 0.4889\n",
      "Epoch: [ 3/ 5], Step: [ 592/ 600], Loss: 0.0304\n",
      "Epoch: [ 3/ 5], Step: [ 593/ 600], Loss: 0.2317\n",
      "Epoch: [ 3/ 5], Step: [ 594/ 600], Loss: 0.2343\n",
      "Epoch: [ 3/ 5], Step: [ 595/ 600], Loss: 0.5798\n",
      "Epoch: [ 3/ 5], Step: [ 596/ 600], Loss: 0.1171\n",
      "Epoch: [ 3/ 5], Step: [ 597/ 600], Loss: 0.1779\n",
      "Epoch: [ 3/ 5], Step: [ 598/ 600], Loss: 0.0374\n",
      "Epoch: [ 3/ 5], Step: [ 599/ 600], Loss: 0.7078\n",
      "Epoch: [ 3/ 5], Step: [ 600/ 600], Loss: 0.0036\n",
      "Epoch: [ 4/ 5], Step: [ 1/ 600], Loss: 0.0245\n",
      "Epoch: [ 4/ 5], Step: [ 2/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 3/ 600], Loss: 0.0076\n",
      "Epoch: [ 4/ 5], Step: [ 4/ 600], Loss: 0.0123\n",
      "Epoch: [ 4/ 5], Step: [ 5/ 600], Loss: 0.0030\n",
      "Epoch: [ 4/ 5], Step: [ 6/ 600], Loss: 0.2044\n",
      "Epoch: [ 4/ 5], Step: [ 7/ 600], Loss: 0.0908\n",
      "Epoch: [ 4/ 5], Step: [ 8/ 600], Loss: 0.9658\n",
      "Epoch: [ 4/ 5], Step: [ 9/ 600], Loss: 0.3190\n",
      "Epoch: [ 4/ 5], Step: [ 10/ 600], Loss: 0.0908\n",
      "Epoch: [ 4/ 5], Step: [ 11/ 600], Loss: 0.0022\n",
      "Epoch: [ 4/ 5], Step: [ 12/ 600], Loss: 1.0513\n",
      "Epoch: [ 4/ 5], Step: [ 13/ 600], Loss: 0.0961\n",
      "Epoch: [ 4/ 5], Step: [ 14/ 600], Loss: 0.3534\n",
      "Epoch: [ 4/ 5], Step: [ 15/ 600], Loss: 0.0199\n",
      "Epoch: [ 4/ 5], Step: [ 16/ 600], Loss: 0.1558\n",
      "Epoch: [ 4/ 5], Step: [ 17/ 600], Loss: 0.3847\n",
      "Epoch: [ 4/ 5], Step: [ 18/ 600], Loss: 0.0764\n",
      "Epoch: [ 4/ 5], Step: [ 19/ 600], Loss: 0.0788\n",
      "Epoch: [ 4/ 5], Step: [ 20/ 600], Loss: 0.0865\n",
      "Epoch: [ 4/ 5], Step: [ 21/ 600], Loss: 0.0029\n",
      "Epoch: [ 4/ 5], Step: [ 22/ 600], Loss: 0.0308\n",
      "Epoch: [ 4/ 5], Step: [ 23/ 600], Loss: 0.0272\n",
      "Epoch: [ 4/ 5], Step: [ 24/ 600], Loss: 0.0034\n",
      "Epoch: [ 4/ 5], Step: [ 25/ 600], Loss: 0.0574\n",
      "Epoch: [ 4/ 5], Step: [ 26/ 600], Loss: 0.0749\n",
      "Epoch: [ 4/ 5], Step: [ 27/ 600], Loss: 0.1563\n",
      "Epoch: [ 4/ 5], Step: [ 28/ 600], Loss: 0.0227\n",
      "Epoch: [ 4/ 5], Step: [ 29/ 600], Loss: 0.0408\n",
      "Epoch: [ 4/ 5], Step: [ 30/ 600], Loss: 0.0446\n",
      "Epoch: [ 4/ 5], Step: [ 31/ 600], Loss: 0.0566\n",
      "Epoch: [ 4/ 5], Step: [ 32/ 600], Loss: 0.0355\n",
      "Epoch: [ 4/ 5], Step: [ 33/ 600], Loss: 0.0272\n",
      "Epoch: [ 4/ 5], Step: [ 34/ 600], Loss: 0.0239\n",
      "Epoch: [ 4/ 5], Step: [ 35/ 600], Loss: 0.2154\n",
      "Epoch: [ 4/ 5], Step: [ 36/ 600], Loss: 1.2106\n",
      "Epoch: [ 4/ 5], Step: [ 37/ 600], Loss: 0.1113\n",
      "Epoch: [ 4/ 5], Step: [ 38/ 600], Loss: 0.1876\n",
      "Epoch: [ 4/ 5], Step: [ 39/ 600], Loss: 0.0218\n",
      "Epoch: [ 4/ 5], Step: [ 40/ 600], Loss: 0.0489\n",
      "Epoch: [ 4/ 5], Step: [ 41/ 600], Loss: 0.0022\n",
      "Epoch: [ 4/ 5], Step: [ 42/ 600], Loss: 0.1358\n",
      "Epoch: [ 4/ 5], Step: [ 43/ 600], Loss: 0.0076\n",
      "Epoch: [ 4/ 5], Step: [ 44/ 600], Loss: 0.0104\n",
      "Epoch: [ 4/ 5], Step: [ 45/ 600], Loss: 0.0118\n",
      "Epoch: [ 4/ 5], Step: [ 46/ 600], Loss: 1.5174\n",
      "Epoch: [ 4/ 5], Step: [ 47/ 600], Loss: 0.0613\n",
      "Epoch: [ 4/ 5], Step: [ 48/ 600], Loss: 0.0013\n",
      "Epoch: [ 4/ 5], Step: [ 49/ 600], Loss: 0.0250\n",
      "Epoch: [ 4/ 5], Step: [ 50/ 600], Loss: 0.8414\n",
      "Epoch: [ 4/ 5], Step: [ 51/ 600], Loss: 0.0792\n",
      "Epoch: [ 4/ 5], Step: [ 52/ 600], Loss: 0.1433\n",
      "Epoch: [ 4/ 5], Step: [ 53/ 600], Loss: 0.0784\n",
      "Epoch: [ 4/ 5], Step: [ 54/ 600], Loss: 0.1826\n",
      "Epoch: [ 4/ 5], Step: [ 55/ 600], Loss: 0.2416\n",
      "Epoch: [ 4/ 5], Step: [ 56/ 600], Loss: 0.0026\n",
      "Epoch: [ 4/ 5], Step: [ 57/ 600], Loss: 0.3327\n",
      "Epoch: [ 4/ 5], Step: [ 58/ 600], Loss: 2.9550\n",
      "Epoch: [ 4/ 5], Step: [ 59/ 600], Loss: 0.0335\n",
      "Epoch: [ 4/ 5], Step: [ 60/ 600], Loss: 0.0744\n",
      "Epoch: [ 4/ 5], Step: [ 61/ 600], Loss: 0.0575\n",
      "Epoch: [ 4/ 5], Step: [ 62/ 600], Loss: 0.0075\n",
      "Epoch: [ 4/ 5], Step: [ 63/ 600], Loss: 0.0008\n",
      "Epoch: [ 4/ 5], Step: [ 64/ 600], Loss: 0.0618\n",
      "Epoch: [ 4/ 5], Step: [ 65/ 600], Loss: 0.0117\n",
      "Epoch: [ 4/ 5], Step: [ 66/ 600], Loss: 0.0017\n",
      "Epoch: [ 4/ 5], Step: [ 67/ 600], Loss: 0.0510\n",
      "Epoch: [ 4/ 5], Step: [ 68/ 600], Loss: 0.4661\n",
      "Epoch: [ 4/ 5], Step: [ 69/ 600], Loss: 0.0151\n",
      "Epoch: [ 4/ 5], Step: [ 70/ 600], Loss: 0.0804\n",
      "Epoch: [ 4/ 5], Step: [ 71/ 600], Loss: 0.0013\n",
      "Epoch: [ 4/ 5], Step: [ 72/ 600], Loss: 0.0018\n",
      "Epoch: [ 4/ 5], Step: [ 73/ 600], Loss: 0.0008\n",
      "Epoch: [ 4/ 5], Step: [ 74/ 600], Loss: 0.0120\n",
      "Epoch: [ 4/ 5], Step: [ 75/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 76/ 600], Loss: 0.1205\n",
      "Epoch: [ 4/ 5], Step: [ 77/ 600], Loss: 0.0764\n",
      "Epoch: [ 4/ 5], Step: [ 78/ 600], Loss: 2.2571\n",
      "Epoch: [ 4/ 5], Step: [ 79/ 600], Loss: 0.0530\n",
      "Epoch: [ 4/ 5], Step: [ 80/ 600], Loss: 0.0067\n",
      "Epoch: [ 4/ 5], Step: [ 81/ 600], Loss: 0.4886\n",
      "Epoch: [ 4/ 5], Step: [ 82/ 600], Loss: 0.0017\n",
      "Epoch: [ 4/ 5], Step: [ 83/ 600], Loss: 0.0231\n",
      "Epoch: [ 4/ 5], Step: [ 84/ 600], Loss: 0.2213\n",
      "Epoch: [ 4/ 5], Step: [ 85/ 600], Loss: 0.0386\n",
      "Epoch: [ 4/ 5], Step: [ 86/ 600], Loss: 0.0591\n",
      "Epoch: [ 4/ 5], Step: [ 87/ 600], Loss: 0.1525\n",
      "Epoch: [ 4/ 5], Step: [ 88/ 600], Loss: 0.0329\n",
      "Epoch: [ 4/ 5], Step: [ 89/ 600], Loss: 0.1882\n",
      "Epoch: [ 4/ 5], Step: [ 90/ 600], Loss: 0.2585\n",
      "Epoch: [ 4/ 5], Step: [ 91/ 600], Loss: 0.0611\n",
      "Epoch: [ 4/ 5], Step: [ 92/ 600], Loss: 0.3299\n",
      "Epoch: [ 4/ 5], Step: [ 93/ 600], Loss: 0.2103\n",
      "Epoch: [ 4/ 5], Step: [ 94/ 600], Loss: 0.0006\n",
      "Epoch: [ 4/ 5], Step: [ 95/ 600], Loss: 0.0107\n",
      "Epoch: [ 4/ 5], Step: [ 96/ 600], Loss: 0.0069\n",
      "Epoch: [ 4/ 5], Step: [ 97/ 600], Loss: 0.1638\n",
      "Epoch: [ 4/ 5], Step: [ 98/ 600], Loss: 0.0237\n",
      "Epoch: [ 4/ 5], Step: [ 99/ 600], Loss: 0.0266\n",
      "Epoch: [ 4/ 5], Step: [ 100/ 600], Loss: 1.8175\n",
      "Epoch: [ 4/ 5], Step: [ 101/ 600], Loss: 0.0010\n",
      "Epoch: [ 4/ 5], Step: [ 102/ 600], Loss: 0.0062\n",
      "Epoch: [ 4/ 5], Step: [ 103/ 600], Loss: 0.0011\n",
      "Epoch: [ 4/ 5], Step: [ 104/ 600], Loss: 0.0148\n",
      "Epoch: [ 4/ 5], Step: [ 105/ 600], Loss: 0.3921\n",
      "Epoch: [ 4/ 5], Step: [ 106/ 600], Loss: 0.1653\n",
      "Epoch: [ 4/ 5], Step: [ 107/ 600], Loss: 0.0007\n",
      "Epoch: [ 4/ 5], Step: [ 108/ 600], Loss: 0.4353\n",
      "Epoch: [ 4/ 5], Step: [ 109/ 600], Loss: 2.1918\n",
      "Epoch: [ 4/ 5], Step: [ 110/ 600], Loss: 0.0250\n",
      "Epoch: [ 4/ 5], Step: [ 111/ 600], Loss: 0.5825\n",
      "Epoch: [ 4/ 5], Step: [ 112/ 600], Loss: 0.0314\n",
      "Epoch: [ 4/ 5], Step: [ 113/ 600], Loss: 0.0541\n",
      "Epoch: [ 4/ 5], Step: [ 114/ 600], Loss: 0.1059\n",
      "Epoch: [ 4/ 5], Step: [ 115/ 600], Loss: 0.0733\n",
      "Epoch: [ 4/ 5], Step: [ 116/ 600], Loss: 4.1363\n",
      "Epoch: [ 4/ 5], Step: [ 117/ 600], Loss: 0.0314\n",
      "Epoch: [ 4/ 5], Step: [ 118/ 600], Loss: 0.0056\n",
      "Epoch: [ 4/ 5], Step: [ 119/ 600], Loss: 0.3690\n",
      "Epoch: [ 4/ 5], Step: [ 120/ 600], Loss: 0.3067\n",
      "Epoch: [ 4/ 5], Step: [ 121/ 600], Loss: 0.6038\n",
      "Epoch: [ 4/ 5], Step: [ 122/ 600], Loss: 0.0785\n",
      "Epoch: [ 4/ 5], Step: [ 123/ 600], Loss: 0.0238\n",
      "Epoch: [ 4/ 5], Step: [ 124/ 600], Loss: 0.0042\n",
      "Epoch: [ 4/ 5], Step: [ 125/ 600], Loss: 0.0403\n",
      "Epoch: [ 4/ 5], Step: [ 126/ 600], Loss: 0.0145\n",
      "Epoch: [ 4/ 5], Step: [ 127/ 600], Loss: 0.0638\n",
      "Epoch: [ 4/ 5], Step: [ 128/ 600], Loss: 0.4900\n",
      "Epoch: [ 4/ 5], Step: [ 129/ 600], Loss: 0.0362\n",
      "Epoch: [ 4/ 5], Step: [ 130/ 600], Loss: 0.8923\n",
      "Epoch: [ 4/ 5], Step: [ 131/ 600], Loss: 0.0268\n",
      "Epoch: [ 4/ 5], Step: [ 132/ 600], Loss: 0.2506\n",
      "Epoch: [ 4/ 5], Step: [ 133/ 600], Loss: 0.1026\n",
      "Epoch: [ 4/ 5], Step: [ 134/ 600], Loss: 0.0056\n",
      "Epoch: [ 4/ 5], Step: [ 135/ 600], Loss: 0.4858\n",
      "Epoch: [ 4/ 5], Step: [ 136/ 600], Loss: 0.0014\n",
      "Epoch: [ 4/ 5], Step: [ 137/ 600], Loss: 3.4531\n",
      "Epoch: [ 4/ 5], Step: [ 138/ 600], Loss: 5.5121\n",
      "Epoch: [ 4/ 5], Step: [ 139/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 140/ 600], Loss: 0.0089\n",
      "Epoch: [ 4/ 5], Step: [ 141/ 600], Loss: 0.0098\n",
      "Epoch: [ 4/ 5], Step: [ 142/ 600], Loss: 0.0481\n",
      "Epoch: [ 4/ 5], Step: [ 143/ 600], Loss: 1.1844\n",
      "Epoch: [ 4/ 5], Step: [ 144/ 600], Loss: 0.0012\n",
      "Epoch: [ 4/ 5], Step: [ 145/ 600], Loss: 0.1493\n",
      "Epoch: [ 4/ 5], Step: [ 146/ 600], Loss: 0.0431\n",
      "Epoch: [ 4/ 5], Step: [ 147/ 600], Loss: 0.0640\n",
      "Epoch: [ 4/ 5], Step: [ 148/ 600], Loss: 0.0018\n",
      "Epoch: [ 4/ 5], Step: [ 149/ 600], Loss: 0.0791\n",
      "Epoch: [ 4/ 5], Step: [ 150/ 600], Loss: 2.1044\n",
      "Epoch: [ 4/ 5], Step: [ 151/ 600], Loss: 0.6407\n",
      "Epoch: [ 4/ 5], Step: [ 152/ 600], Loss: 2.0785\n",
      "Epoch: [ 4/ 5], Step: [ 153/ 600], Loss: 1.5465\n",
      "Epoch: [ 4/ 5], Step: [ 154/ 600], Loss: 0.0269\n",
      "Epoch: [ 4/ 5], Step: [ 155/ 600], Loss: 0.3076\n",
      "Epoch: [ 4/ 5], Step: [ 156/ 600], Loss: 0.3462\n",
      "Epoch: [ 4/ 5], Step: [ 157/ 600], Loss: 0.0165\n",
      "Epoch: [ 4/ 5], Step: [ 158/ 600], Loss: 0.0030\n",
      "Epoch: [ 4/ 5], Step: [ 159/ 600], Loss: 0.0323\n",
      "Epoch: [ 4/ 5], Step: [ 160/ 600], Loss: 0.3418\n",
      "Epoch: [ 4/ 5], Step: [ 161/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 162/ 600], Loss: 0.0004\n",
      "Epoch: [ 4/ 5], Step: [ 163/ 600], Loss: 0.0269\n",
      "Epoch: [ 4/ 5], Step: [ 164/ 600], Loss: 0.0043\n",
      "Epoch: [ 4/ 5], Step: [ 165/ 600], Loss: 0.0009\n",
      "Epoch: [ 4/ 5], Step: [ 166/ 600], Loss: 0.0560\n",
      "Epoch: [ 4/ 5], Step: [ 167/ 600], Loss: 0.0499\n",
      "Epoch: [ 4/ 5], Step: [ 168/ 600], Loss: 0.8489\n",
      "Epoch: [ 4/ 5], Step: [ 169/ 600], Loss: 0.0110\n",
      "Epoch: [ 4/ 5], Step: [ 170/ 600], Loss: 0.0770\n",
      "Epoch: [ 4/ 5], Step: [ 171/ 600], Loss: 0.5096\n",
      "Epoch: [ 4/ 5], Step: [ 172/ 600], Loss: 0.1241\n",
      "Epoch: [ 4/ 5], Step: [ 173/ 600], Loss: 0.0012\n",
      "Epoch: [ 4/ 5], Step: [ 174/ 600], Loss: 0.0425\n",
      "Epoch: [ 4/ 5], Step: [ 175/ 600], Loss: 0.0514\n",
      "Epoch: [ 4/ 5], Step: [ 176/ 600], Loss: 0.0655\n",
      "Epoch: [ 4/ 5], Step: [ 177/ 600], Loss: 1.5047\n",
      "Epoch: [ 4/ 5], Step: [ 178/ 600], Loss: 0.1010\n",
      "Epoch: [ 4/ 5], Step: [ 179/ 600], Loss: 0.0401\n",
      "Epoch: [ 4/ 5], Step: [ 180/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 181/ 600], Loss: 0.0397\n",
      "Epoch: [ 4/ 5], Step: [ 182/ 600], Loss: 1.2622\n",
      "Epoch: [ 4/ 5], Step: [ 183/ 600], Loss: 0.1863\n",
      "Epoch: [ 4/ 5], Step: [ 184/ 600], Loss: 0.2149\n",
      "Epoch: [ 4/ 5], Step: [ 185/ 600], Loss: 0.0133\n",
      "Epoch: [ 4/ 5], Step: [ 186/ 600], Loss: 0.0452\n",
      "Epoch: [ 4/ 5], Step: [ 187/ 600], Loss: 0.7549\n",
      "Epoch: [ 4/ 5], Step: [ 188/ 600], Loss: 0.0011\n",
      "Epoch: [ 4/ 5], Step: [ 189/ 600], Loss: 0.2209\n",
      "Epoch: [ 4/ 5], Step: [ 190/ 600], Loss: 0.6732\n",
      "Epoch: [ 4/ 5], Step: [ 191/ 600], Loss: 0.0213\n",
      "Epoch: [ 4/ 5], Step: [ 192/ 600], Loss: 0.0670\n",
      "Epoch: [ 4/ 5], Step: [ 193/ 600], Loss: 0.2677\n",
      "Epoch: [ 4/ 5], Step: [ 194/ 600], Loss: 0.0296\n",
      "Epoch: [ 4/ 5], Step: [ 195/ 600], Loss: 0.0002\n",
      "Epoch: [ 4/ 5], Step: [ 196/ 600], Loss: 0.0350\n",
      "Epoch: [ 4/ 5], Step: [ 197/ 600], Loss: 0.0228\n",
      "Epoch: [ 4/ 5], Step: [ 198/ 600], Loss: 0.7761\n",
      "Epoch: [ 4/ 5], Step: [ 199/ 600], Loss: 0.0274\n",
      "Epoch: [ 4/ 5], Step: [ 200/ 600], Loss: 0.1476\n",
      "Epoch: [ 4/ 5], Step: [ 201/ 600], Loss: 0.3969\n",
      "Epoch: [ 4/ 5], Step: [ 202/ 600], Loss: 0.0023\n",
      "Epoch: [ 4/ 5], Step: [ 203/ 600], Loss: 0.0117\n",
      "Epoch: [ 4/ 5], Step: [ 204/ 600], Loss: 0.0310\n",
      "Epoch: [ 4/ 5], Step: [ 205/ 600], Loss: 0.0335\n",
      "Epoch: [ 4/ 5], Step: [ 206/ 600], Loss: 0.1348\n",
      "Epoch: [ 4/ 5], Step: [ 207/ 600], Loss: 0.0217\n",
      "Epoch: [ 4/ 5], Step: [ 208/ 600], Loss: 1.3900\n",
      "Epoch: [ 4/ 5], Step: [ 209/ 600], Loss: 0.0097\n",
      "Epoch: [ 4/ 5], Step: [ 210/ 600], Loss: 0.4447\n",
      "Epoch: [ 4/ 5], Step: [ 211/ 600], Loss: 0.1230\n",
      "Epoch: [ 4/ 5], Step: [ 212/ 600], Loss: 0.0060\n",
      "Epoch: [ 4/ 5], Step: [ 213/ 600], Loss: 0.0348\n",
      "Epoch: [ 4/ 5], Step: [ 214/ 600], Loss: 0.2240\n",
      "Epoch: [ 4/ 5], Step: [ 215/ 600], Loss: 0.0147\n",
      "Epoch: [ 4/ 5], Step: [ 216/ 600], Loss: 0.0147\n",
      "Epoch: [ 4/ 5], Step: [ 217/ 600], Loss: 0.0113\n",
      "Epoch: [ 4/ 5], Step: [ 218/ 600], Loss: 0.2513\n",
      "Epoch: [ 4/ 5], Step: [ 219/ 600], Loss: 0.0186\n",
      "Epoch: [ 4/ 5], Step: [ 220/ 600], Loss: 0.0838\n",
      "Epoch: [ 4/ 5], Step: [ 221/ 600], Loss: 0.3318\n",
      "Epoch: [ 4/ 5], Step: [ 222/ 600], Loss: 0.6050\n",
      "Epoch: [ 4/ 5], Step: [ 223/ 600], Loss: 0.0823\n",
      "Epoch: [ 4/ 5], Step: [ 224/ 600], Loss: 0.0717\n",
      "Epoch: [ 4/ 5], Step: [ 225/ 600], Loss: 0.0046\n",
      "Epoch: [ 4/ 5], Step: [ 226/ 600], Loss: 0.0075\n",
      "Epoch: [ 4/ 5], Step: [ 227/ 600], Loss: 0.0500\n",
      "Epoch: [ 4/ 5], Step: [ 228/ 600], Loss: 0.6848\n",
      "Epoch: [ 4/ 5], Step: [ 229/ 600], Loss: 0.0468\n",
      "Epoch: [ 4/ 5], Step: [ 230/ 600], Loss: 0.2982\n",
      "Epoch: [ 4/ 5], Step: [ 231/ 600], Loss: 0.1828\n",
      "Epoch: [ 4/ 5], Step: [ 232/ 600], Loss: 2.2450\n",
      "Epoch: [ 4/ 5], Step: [ 233/ 600], Loss: 0.0287\n",
      "Epoch: [ 4/ 5], Step: [ 234/ 600], Loss: 0.0422\n",
      "Epoch: [ 4/ 5], Step: [ 235/ 600], Loss: 0.4605\n",
      "Epoch: [ 4/ 5], Step: [ 236/ 600], Loss: 0.0141\n",
      "Epoch: [ 4/ 5], Step: [ 237/ 600], Loss: 0.0051\n",
      "Epoch: [ 4/ 5], Step: [ 238/ 600], Loss: 0.0029\n",
      "Epoch: [ 4/ 5], Step: [ 239/ 600], Loss: 0.0049\n",
      "Epoch: [ 4/ 5], Step: [ 240/ 600], Loss: 0.0121\n",
      "Epoch: [ 4/ 5], Step: [ 241/ 600], Loss: 1.2611\n",
      "Epoch: [ 4/ 5], Step: [ 242/ 600], Loss: 1.6309\n",
      "Epoch: [ 4/ 5], Step: [ 243/ 600], Loss: 0.0009\n",
      "Epoch: [ 4/ 5], Step: [ 244/ 600], Loss: 0.1348\n",
      "Epoch: [ 4/ 5], Step: [ 245/ 600], Loss: 0.0158\n",
      "Epoch: [ 4/ 5], Step: [ 246/ 600], Loss: 0.0048\n",
      "Epoch: [ 4/ 5], Step: [ 247/ 600], Loss: 0.0013\n",
      "Epoch: [ 4/ 5], Step: [ 248/ 600], Loss: 0.0270\n",
      "Epoch: [ 4/ 5], Step: [ 249/ 600], Loss: 0.1548\n",
      "Epoch: [ 4/ 5], Step: [ 250/ 600], Loss: 0.1996\n",
      "Epoch: [ 4/ 5], Step: [ 251/ 600], Loss: 4.4161\n",
      "Epoch: [ 4/ 5], Step: [ 252/ 600], Loss: 0.0519\n",
      "Epoch: [ 4/ 5], Step: [ 253/ 600], Loss: 0.0418\n",
      "Epoch: [ 4/ 5], Step: [ 254/ 600], Loss: 0.0539\n",
      "Epoch: [ 4/ 5], Step: [ 255/ 600], Loss: 1.5415\n",
      "Epoch: [ 4/ 5], Step: [ 256/ 600], Loss: 0.0634\n",
      "Epoch: [ 4/ 5], Step: [ 257/ 600], Loss: 1.0496\n",
      "Epoch: [ 4/ 5], Step: [ 258/ 600], Loss: 5.0116\n",
      "Epoch: [ 4/ 5], Step: [ 259/ 600], Loss: 0.3464\n",
      "Epoch: [ 4/ 5], Step: [ 260/ 600], Loss: 0.0137\n",
      "Epoch: [ 4/ 5], Step: [ 261/ 600], Loss: 0.0714\n",
      "Epoch: [ 4/ 5], Step: [ 262/ 600], Loss: 0.0422\n",
      "Epoch: [ 4/ 5], Step: [ 263/ 600], Loss: 0.0763\n",
      "Epoch: [ 4/ 5], Step: [ 264/ 600], Loss: 0.1612\n",
      "Epoch: [ 4/ 5], Step: [ 265/ 600], Loss: 0.2191\n",
      "Epoch: [ 4/ 5], Step: [ 266/ 600], Loss: 0.0121\n",
      "Epoch: [ 4/ 5], Step: [ 267/ 600], Loss: 0.2355\n",
      "Epoch: [ 4/ 5], Step: [ 268/ 600], Loss: 0.1613\n",
      "Epoch: [ 4/ 5], Step: [ 269/ 600], Loss: 0.0091\n",
      "Epoch: [ 4/ 5], Step: [ 270/ 600], Loss: 0.0006\n",
      "Epoch: [ 4/ 5], Step: [ 271/ 600], Loss: 0.0092\n",
      "Epoch: [ 4/ 5], Step: [ 272/ 600], Loss: 0.1499\n",
      "Epoch: [ 4/ 5], Step: [ 273/ 600], Loss: 0.0075\n",
      "Epoch: [ 4/ 5], Step: [ 274/ 600], Loss: 1.2522\n",
      "Epoch: [ 4/ 5], Step: [ 275/ 600], Loss: 0.0065\n",
      "Epoch: [ 4/ 5], Step: [ 276/ 600], Loss: 0.2596\n",
      "Epoch: [ 4/ 5], Step: [ 277/ 600], Loss: 0.0024\n",
      "Epoch: [ 4/ 5], Step: [ 278/ 600], Loss: 2.8936\n",
      "Epoch: [ 4/ 5], Step: [ 279/ 600], Loss: 0.0307\n",
      "Epoch: [ 4/ 5], Step: [ 280/ 600], Loss: 0.0245\n",
      "Epoch: [ 4/ 5], Step: [ 281/ 600], Loss: 1.8040\n",
      "Epoch: [ 4/ 5], Step: [ 282/ 600], Loss: 0.0166\n",
      "Epoch: [ 4/ 5], Step: [ 283/ 600], Loss: 0.0644\n",
      "Epoch: [ 4/ 5], Step: [ 284/ 600], Loss: 0.0467\n",
      "Epoch: [ 4/ 5], Step: [ 285/ 600], Loss: 3.7638\n",
      "Epoch: [ 4/ 5], Step: [ 286/ 600], Loss: 2.2289\n",
      "Epoch: [ 4/ 5], Step: [ 287/ 600], Loss: 0.0004\n",
      "Epoch: [ 4/ 5], Step: [ 288/ 600], Loss: 0.7676\n",
      "Epoch: [ 4/ 5], Step: [ 289/ 600], Loss: 0.0100\n",
      "Epoch: [ 4/ 5], Step: [ 290/ 600], Loss: 0.0493\n",
      "Epoch: [ 4/ 5], Step: [ 291/ 600], Loss: 0.0163\n",
      "Epoch: [ 4/ 5], Step: [ 292/ 600], Loss: 0.1101\n",
      "Epoch: [ 4/ 5], Step: [ 293/ 600], Loss: 0.0159\n",
      "Epoch: [ 4/ 5], Step: [ 294/ 600], Loss: 0.3143\n",
      "Epoch: [ 4/ 5], Step: [ 295/ 600], Loss: 0.0371\n",
      "Epoch: [ 4/ 5], Step: [ 296/ 600], Loss: 0.0076\n",
      "Epoch: [ 4/ 5], Step: [ 297/ 600], Loss: 0.1273\n",
      "Epoch: [ 4/ 5], Step: [ 298/ 600], Loss: 0.2728\n",
      "Epoch: [ 4/ 5], Step: [ 299/ 600], Loss: 0.0111\n",
      "Epoch: [ 4/ 5], Step: [ 300/ 600], Loss: 0.0376\n",
      "Epoch: [ 4/ 5], Step: [ 301/ 600], Loss: 0.0212\n",
      "Epoch: [ 4/ 5], Step: [ 302/ 600], Loss: 0.0033\n",
      "Epoch: [ 4/ 5], Step: [ 303/ 600], Loss: 0.3523\n",
      "Epoch: [ 4/ 5], Step: [ 304/ 600], Loss: 0.1728\n",
      "Epoch: [ 4/ 5], Step: [ 305/ 600], Loss: 0.0591\n",
      "Epoch: [ 4/ 5], Step: [ 306/ 600], Loss: 0.1608\n",
      "Epoch: [ 4/ 5], Step: [ 307/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 308/ 600], Loss: 0.1117\n",
      "Epoch: [ 4/ 5], Step: [ 309/ 600], Loss: 0.0902\n",
      "Epoch: [ 4/ 5], Step: [ 310/ 600], Loss: 1.1790\n",
      "Epoch: [ 4/ 5], Step: [ 311/ 600], Loss: 0.0136\n",
      "Epoch: [ 4/ 5], Step: [ 312/ 600], Loss: 0.0140\n",
      "Epoch: [ 4/ 5], Step: [ 313/ 600], Loss: 0.3482\n",
      "Epoch: [ 4/ 5], Step: [ 314/ 600], Loss: 2.6092\n",
      "Epoch: [ 4/ 5], Step: [ 315/ 600], Loss: 0.1692\n",
      "Epoch: [ 4/ 5], Step: [ 316/ 600], Loss: 0.0022\n",
      "Epoch: [ 4/ 5], Step: [ 317/ 600], Loss: 0.0012\n",
      "Epoch: [ 4/ 5], Step: [ 318/ 600], Loss: 0.0042\n",
      "Epoch: [ 4/ 5], Step: [ 319/ 600], Loss: 0.0013\n",
      "Epoch: [ 4/ 5], Step: [ 320/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 321/ 600], Loss: 0.1502\n",
      "Epoch: [ 4/ 5], Step: [ 322/ 600], Loss: 0.0409\n",
      "Epoch: [ 4/ 5], Step: [ 323/ 600], Loss: 0.0014\n",
      "Epoch: [ 4/ 5], Step: [ 324/ 600], Loss: 0.0031\n",
      "Epoch: [ 4/ 5], Step: [ 325/ 600], Loss: 0.0789\n",
      "Epoch: [ 4/ 5], Step: [ 326/ 600], Loss: 0.0528\n",
      "Epoch: [ 4/ 5], Step: [ 327/ 600], Loss: 0.3487\n",
      "Epoch: [ 4/ 5], Step: [ 328/ 600], Loss: 0.0830\n",
      "Epoch: [ 4/ 5], Step: [ 329/ 600], Loss: 0.0159\n",
      "Epoch: [ 4/ 5], Step: [ 330/ 600], Loss: 0.0429\n",
      "Epoch: [ 4/ 5], Step: [ 331/ 600], Loss: 0.1208\n",
      "Epoch: [ 4/ 5], Step: [ 332/ 600], Loss: 0.1643\n",
      "Epoch: [ 4/ 5], Step: [ 333/ 600], Loss: 0.0483\n",
      "Epoch: [ 4/ 5], Step: [ 334/ 600], Loss: 0.0690\n",
      "Epoch: [ 4/ 5], Step: [ 335/ 600], Loss: 0.6557\n",
      "Epoch: [ 4/ 5], Step: [ 336/ 600], Loss: 1.4060\n",
      "Epoch: [ 4/ 5], Step: [ 337/ 600], Loss: 0.1164\n",
      "Epoch: [ 4/ 5], Step: [ 338/ 600], Loss: 0.0005\n",
      "Epoch: [ 4/ 5], Step: [ 339/ 600], Loss: 0.6572\n",
      "Epoch: [ 4/ 5], Step: [ 340/ 600], Loss: 0.1593\n",
      "Epoch: [ 4/ 5], Step: [ 341/ 600], Loss: 0.0045\n",
      "Epoch: [ 4/ 5], Step: [ 342/ 600], Loss: 0.0384\n",
      "Epoch: [ 4/ 5], Step: [ 343/ 600], Loss: 0.0281\n",
      "Epoch: [ 4/ 5], Step: [ 344/ 600], Loss: 0.6470\n",
      "Epoch: [ 4/ 5], Step: [ 345/ 600], Loss: 0.0271\n",
      "Epoch: [ 4/ 5], Step: [ 346/ 600], Loss: 0.0490\n",
      "Epoch: [ 4/ 5], Step: [ 347/ 600], Loss: 0.0348\n",
      "Epoch: [ 4/ 5], Step: [ 348/ 600], Loss: 0.8289\n",
      "Epoch: [ 4/ 5], Step: [ 349/ 600], Loss: 0.0468\n",
      "Epoch: [ 4/ 5], Step: [ 350/ 600], Loss: 2.6502\n",
      "Epoch: [ 4/ 5], Step: [ 351/ 600], Loss: 0.2724\n",
      "Epoch: [ 4/ 5], Step: [ 352/ 600], Loss: 2.4347\n",
      "Epoch: [ 4/ 5], Step: [ 353/ 600], Loss: 0.0139\n",
      "Epoch: [ 4/ 5], Step: [ 354/ 600], Loss: 0.1256\n",
      "Epoch: [ 4/ 5], Step: [ 355/ 600], Loss: 0.5026\n",
      "Epoch: [ 4/ 5], Step: [ 356/ 600], Loss: 0.7682\n",
      "Epoch: [ 4/ 5], Step: [ 357/ 600], Loss: 0.0049\n",
      "Epoch: [ 4/ 5], Step: [ 358/ 600], Loss: 0.0025\n",
      "Epoch: [ 4/ 5], Step: [ 359/ 600], Loss: 0.0519\n",
      "Epoch: [ 4/ 5], Step: [ 360/ 600], Loss: 0.0298\n",
      "Epoch: [ 4/ 5], Step: [ 361/ 600], Loss: 0.2390\n",
      "Epoch: [ 4/ 5], Step: [ 362/ 600], Loss: 0.1145\n",
      "Epoch: [ 4/ 5], Step: [ 363/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 364/ 600], Loss: 0.0853\n",
      "Epoch: [ 4/ 5], Step: [ 365/ 600], Loss: 1.1932\n",
      "Epoch: [ 4/ 5], Step: [ 366/ 600], Loss: 0.0736\n",
      "Epoch: [ 4/ 5], Step: [ 367/ 600], Loss: 0.0155\n",
      "Epoch: [ 4/ 5], Step: [ 368/ 600], Loss: 0.5874\n",
      "Epoch: [ 4/ 5], Step: [ 369/ 600], Loss: 0.0092\n",
      "Epoch: [ 4/ 5], Step: [ 370/ 600], Loss: 0.8401\n",
      "Epoch: [ 4/ 5], Step: [ 371/ 600], Loss: 0.0022\n",
      "Epoch: [ 4/ 5], Step: [ 372/ 600], Loss: 0.0004\n",
      "Epoch: [ 4/ 5], Step: [ 373/ 600], Loss: 0.1469\n",
      "Epoch: [ 4/ 5], Step: [ 374/ 600], Loss: 0.0167\n",
      "Epoch: [ 4/ 5], Step: [ 375/ 600], Loss: 0.0154\n",
      "Epoch: [ 4/ 5], Step: [ 376/ 600], Loss: 0.0045\n",
      "Epoch: [ 4/ 5], Step: [ 377/ 600], Loss: 0.0050\n",
      "Epoch: [ 4/ 5], Step: [ 378/ 600], Loss: 0.1383\n",
      "Epoch: [ 4/ 5], Step: [ 379/ 600], Loss: 0.7870\n",
      "Epoch: [ 4/ 5], Step: [ 380/ 600], Loss: 0.1228\n",
      "Epoch: [ 4/ 5], Step: [ 381/ 600], Loss: 0.0090\n",
      "Epoch: [ 4/ 5], Step: [ 382/ 600], Loss: 0.0073\n",
      "Epoch: [ 4/ 5], Step: [ 383/ 600], Loss: 0.0046\n",
      "Epoch: [ 4/ 5], Step: [ 384/ 600], Loss: 0.0456\n",
      "Epoch: [ 4/ 5], Step: [ 385/ 600], Loss: 0.0200\n",
      "Epoch: [ 4/ 5], Step: [ 386/ 600], Loss: 0.1880\n",
      "Epoch: [ 4/ 5], Step: [ 387/ 600], Loss: 0.0002\n",
      "Epoch: [ 4/ 5], Step: [ 388/ 600], Loss: 0.0050\n",
      "Epoch: [ 4/ 5], Step: [ 389/ 600], Loss: 0.0104\n",
      "Epoch: [ 4/ 5], Step: [ 390/ 600], Loss: 0.0129\n",
      "Epoch: [ 4/ 5], Step: [ 391/ 600], Loss: 0.0133\n",
      "Epoch: [ 4/ 5], Step: [ 392/ 600], Loss: 0.0147\n",
      "Epoch: [ 4/ 5], Step: [ 393/ 600], Loss: 0.0015\n",
      "Epoch: [ 4/ 5], Step: [ 394/ 600], Loss: 0.0044\n",
      "Epoch: [ 4/ 5], Step: [ 395/ 600], Loss: 0.1196\n",
      "Epoch: [ 4/ 5], Step: [ 396/ 600], Loss: 0.0008\n",
      "Epoch: [ 4/ 5], Step: [ 397/ 600], Loss: 0.0075\n",
      "Epoch: [ 4/ 5], Step: [ 398/ 600], Loss: 0.0069\n",
      "Epoch: [ 4/ 5], Step: [ 399/ 600], Loss: 0.1454\n",
      "Epoch: [ 4/ 5], Step: [ 400/ 600], Loss: 0.0021\n",
      "Epoch: [ 4/ 5], Step: [ 401/ 600], Loss: 0.0068\n",
      "Epoch: [ 4/ 5], Step: [ 402/ 600], Loss: 0.1835\n",
      "Epoch: [ 4/ 5], Step: [ 403/ 600], Loss: 0.0729\n",
      "Epoch: [ 4/ 5], Step: [ 404/ 600], Loss: 0.3007\n",
      "Epoch: [ 4/ 5], Step: [ 405/ 600], Loss: 0.0271\n",
      "Epoch: [ 4/ 5], Step: [ 406/ 600], Loss: 0.0003\n",
      "Epoch: [ 4/ 5], Step: [ 407/ 600], Loss: 0.0192\n",
      "Epoch: [ 4/ 5], Step: [ 408/ 600], Loss: 0.0352\n",
      "Epoch: [ 4/ 5], Step: [ 409/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 410/ 600], Loss: 0.0028\n",
      "Epoch: [ 4/ 5], Step: [ 411/ 600], Loss: 0.0200\n",
      "Epoch: [ 4/ 5], Step: [ 412/ 600], Loss: 0.0067\n",
      "Epoch: [ 4/ 5], Step: [ 413/ 600], Loss: 0.0413\n",
      "Epoch: [ 4/ 5], Step: [ 414/ 600], Loss: 0.0124\n",
      "Epoch: [ 4/ 5], Step: [ 415/ 600], Loss: 0.0676\n",
      "Epoch: [ 4/ 5], Step: [ 416/ 600], Loss: 0.0018\n",
      "Epoch: [ 4/ 5], Step: [ 417/ 600], Loss: 0.1766\n",
      "Epoch: [ 4/ 5], Step: [ 418/ 600], Loss: 0.0114\n",
      "Epoch: [ 4/ 5], Step: [ 419/ 600], Loss: 0.9168\n",
      "Epoch: [ 4/ 5], Step: [ 420/ 600], Loss: 0.0822\n",
      "Epoch: [ 4/ 5], Step: [ 421/ 600], Loss: 0.4025\n",
      "Epoch: [ 4/ 5], Step: [ 422/ 600], Loss: 0.0194\n",
      "Epoch: [ 4/ 5], Step: [ 423/ 600], Loss: 1.1028\n",
      "Epoch: [ 4/ 5], Step: [ 424/ 600], Loss: 0.0121\n",
      "Epoch: [ 4/ 5], Step: [ 425/ 600], Loss: 0.0618\n",
      "Epoch: [ 4/ 5], Step: [ 426/ 600], Loss: 0.0135\n",
      "Epoch: [ 4/ 5], Step: [ 427/ 600], Loss: 0.0841\n",
      "Epoch: [ 4/ 5], Step: [ 428/ 600], Loss: 1.0790\n",
      "Epoch: [ 4/ 5], Step: [ 429/ 600], Loss: 0.0353\n",
      "Epoch: [ 4/ 5], Step: [ 430/ 600], Loss: 3.7365\n",
      "Epoch: [ 4/ 5], Step: [ 431/ 600], Loss: 0.0877\n",
      "Epoch: [ 4/ 5], Step: [ 432/ 600], Loss: 0.0200\n",
      "Epoch: [ 4/ 5], Step: [ 433/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 434/ 600], Loss: 0.0544\n",
      "Epoch: [ 4/ 5], Step: [ 435/ 600], Loss: 0.0658\n",
      "Epoch: [ 4/ 5], Step: [ 436/ 600], Loss: 0.0813\n",
      "Epoch: [ 4/ 5], Step: [ 437/ 600], Loss: 0.0930\n",
      "Epoch: [ 4/ 5], Step: [ 438/ 600], Loss: 2.1013\n",
      "Epoch: [ 4/ 5], Step: [ 439/ 600], Loss: 0.0417\n",
      "Epoch: [ 4/ 5], Step: [ 440/ 600], Loss: 0.1377\n",
      "Epoch: [ 4/ 5], Step: [ 441/ 600], Loss: 0.0185\n",
      "Epoch: [ 4/ 5], Step: [ 442/ 600], Loss: 0.8792\n",
      "Epoch: [ 4/ 5], Step: [ 443/ 600], Loss: 0.0854\n",
      "Epoch: [ 4/ 5], Step: [ 444/ 600], Loss: 0.0104\n",
      "Epoch: [ 4/ 5], Step: [ 445/ 600], Loss: 0.1576\n",
      "Epoch: [ 4/ 5], Step: [ 446/ 600], Loss: 0.0347\n",
      "Epoch: [ 4/ 5], Step: [ 447/ 600], Loss: 0.5613\n",
      "Epoch: [ 4/ 5], Step: [ 448/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 449/ 600], Loss: 0.0434\n",
      "Epoch: [ 4/ 5], Step: [ 450/ 600], Loss: 0.2603\n",
      "Epoch: [ 4/ 5], Step: [ 451/ 600], Loss: 0.0132\n",
      "Epoch: [ 4/ 5], Step: [ 452/ 600], Loss: 0.1133\n",
      "Epoch: [ 4/ 5], Step: [ 453/ 600], Loss: 0.0790\n",
      "Epoch: [ 4/ 5], Step: [ 454/ 600], Loss: 0.0487\n",
      "Epoch: [ 4/ 5], Step: [ 455/ 600], Loss: 0.0031\n",
      "Epoch: [ 4/ 5], Step: [ 456/ 600], Loss: 3.0339\n",
      "Epoch: [ 4/ 5], Step: [ 457/ 600], Loss: 1.3710\n",
      "Epoch: [ 4/ 5], Step: [ 458/ 600], Loss: 0.0174\n",
      "Epoch: [ 4/ 5], Step: [ 459/ 600], Loss: 0.0168\n",
      "Epoch: [ 4/ 5], Step: [ 460/ 600], Loss: 2.1209\n",
      "Epoch: [ 4/ 5], Step: [ 461/ 600], Loss: 0.2073\n",
      "Epoch: [ 4/ 5], Step: [ 462/ 600], Loss: 0.0016\n",
      "Epoch: [ 4/ 5], Step: [ 463/ 600], Loss: 2.0125\n",
      "Epoch: [ 4/ 5], Step: [ 464/ 600], Loss: 0.0125\n",
      "Epoch: [ 4/ 5], Step: [ 465/ 600], Loss: 0.0410\n",
      "Epoch: [ 4/ 5], Step: [ 466/ 600], Loss: 0.1471\n",
      "Epoch: [ 4/ 5], Step: [ 467/ 600], Loss: 0.7297\n",
      "Epoch: [ 4/ 5], Step: [ 468/ 600], Loss: 0.2204\n",
      "Epoch: [ 4/ 5], Step: [ 469/ 600], Loss: 0.1092\n",
      "Epoch: [ 4/ 5], Step: [ 470/ 600], Loss: 0.0142\n",
      "Epoch: [ 4/ 5], Step: [ 471/ 600], Loss: 0.0047\n",
      "Epoch: [ 4/ 5], Step: [ 472/ 600], Loss: 3.6342\n",
      "Epoch: [ 4/ 5], Step: [ 473/ 600], Loss: 0.0031\n",
      "Epoch: [ 4/ 5], Step: [ 474/ 600], Loss: 0.0650\n",
      "Epoch: [ 4/ 5], Step: [ 475/ 600], Loss: 0.1825\n",
      "Epoch: [ 4/ 5], Step: [ 476/ 600], Loss: 0.0134\n",
      "Epoch: [ 4/ 5], Step: [ 477/ 600], Loss: 1.4656\n",
      "Epoch: [ 4/ 5], Step: [ 478/ 600], Loss: 0.5846\n",
      "Epoch: [ 4/ 5], Step: [ 479/ 600], Loss: 0.0193\n",
      "Epoch: [ 4/ 5], Step: [ 480/ 600], Loss: 0.0891\n",
      "Epoch: [ 4/ 5], Step: [ 481/ 600], Loss: 3.1840\n",
      "Epoch: [ 4/ 5], Step: [ 482/ 600], Loss: 0.0175\n",
      "Epoch: [ 4/ 5], Step: [ 483/ 600], Loss: 0.0042\n",
      "Epoch: [ 4/ 5], Step: [ 484/ 600], Loss: 0.2192\n",
      "Epoch: [ 4/ 5], Step: [ 485/ 600], Loss: 0.1651\n",
      "Epoch: [ 4/ 5], Step: [ 486/ 600], Loss: 0.8720\n",
      "Epoch: [ 4/ 5], Step: [ 487/ 600], Loss: 0.0072\n",
      "Epoch: [ 4/ 5], Step: [ 488/ 600], Loss: 0.0011\n",
      "Epoch: [ 4/ 5], Step: [ 489/ 600], Loss: 0.1265\n",
      "Epoch: [ 4/ 5], Step: [ 490/ 600], Loss: 0.0530\n",
      "Epoch: [ 4/ 5], Step: [ 491/ 600], Loss: 0.0217\n",
      "Epoch: [ 4/ 5], Step: [ 492/ 600], Loss: 0.0006\n",
      "Epoch: [ 4/ 5], Step: [ 493/ 600], Loss: 0.0005\n",
      "Epoch: [ 4/ 5], Step: [ 494/ 600], Loss: 0.0058\n",
      "Epoch: [ 4/ 5], Step: [ 495/ 600], Loss: 0.0273\n",
      "Epoch: [ 4/ 5], Step: [ 496/ 600], Loss: 2.5872\n",
      "Epoch: [ 4/ 5], Step: [ 497/ 600], Loss: 0.0501\n",
      "Epoch: [ 4/ 5], Step: [ 498/ 600], Loss: 0.0010\n",
      "Epoch: [ 4/ 5], Step: [ 499/ 600], Loss: 0.0677\n",
      "Epoch: [ 4/ 5], Step: [ 500/ 600], Loss: 0.0626\n",
      "Epoch: [ 4/ 5], Step: [ 501/ 600], Loss: 0.1141\n",
      "Epoch: [ 4/ 5], Step: [ 502/ 600], Loss: 0.0285\n",
      "Epoch: [ 4/ 5], Step: [ 503/ 600], Loss: 0.2112\n",
      "Epoch: [ 4/ 5], Step: [ 504/ 600], Loss: 0.0335\n",
      "Epoch: [ 4/ 5], Step: [ 505/ 600], Loss: 0.0029\n",
      "Epoch: [ 4/ 5], Step: [ 506/ 600], Loss: 0.0588\n",
      "Epoch: [ 4/ 5], Step: [ 507/ 600], Loss: 0.3617\n",
      "Epoch: [ 4/ 5], Step: [ 508/ 600], Loss: 0.1284\n",
      "Epoch: [ 4/ 5], Step: [ 509/ 600], Loss: 0.0065\n",
      "Epoch: [ 4/ 5], Step: [ 510/ 600], Loss: 0.0188\n",
      "Epoch: [ 4/ 5], Step: [ 511/ 600], Loss: 0.0489\n",
      "Epoch: [ 4/ 5], Step: [ 512/ 600], Loss: 0.0010\n",
      "Epoch: [ 4/ 5], Step: [ 513/ 600], Loss: 0.0001\n",
      "Epoch: [ 4/ 5], Step: [ 514/ 600], Loss: 10.2172\n",
      "Epoch: [ 4/ 5], Step: [ 515/ 600], Loss: 0.0243\n",
      "Epoch: [ 4/ 5], Step: [ 516/ 600], Loss: 0.0267\n",
      "Epoch: [ 4/ 5], Step: [ 517/ 600], Loss: 0.0347\n",
      "Epoch: [ 4/ 5], Step: [ 518/ 600], Loss: 0.0011\n",
      "Epoch: [ 4/ 5], Step: [ 519/ 600], Loss: 0.1814\n",
      "Epoch: [ 4/ 5], Step: [ 520/ 600], Loss: 0.3758\n",
      "Epoch: [ 4/ 5], Step: [ 521/ 600], Loss: 0.1353\n",
      "Epoch: [ 4/ 5], Step: [ 522/ 600], Loss: 0.0363\n",
      "Epoch: [ 4/ 5], Step: [ 523/ 600], Loss: 0.0314\n",
      "Epoch: [ 4/ 5], Step: [ 524/ 600], Loss: 0.0117\n",
      "Epoch: [ 4/ 5], Step: [ 525/ 600], Loss: 0.0026\n",
      "Epoch: [ 4/ 5], Step: [ 526/ 600], Loss: 0.0384\n",
      "Epoch: [ 4/ 5], Step: [ 527/ 600], Loss: 0.5042\n",
      "Epoch: [ 4/ 5], Step: [ 528/ 600], Loss: 0.0025\n",
      "Epoch: [ 4/ 5], Step: [ 529/ 600], Loss: 0.0463\n",
      "Epoch: [ 4/ 5], Step: [ 530/ 600], Loss: 0.0005\n",
      "Epoch: [ 4/ 5], Step: [ 531/ 600], Loss: 0.0875\n",
      "Epoch: [ 4/ 5], Step: [ 532/ 600], Loss: 0.6125\n",
      "Epoch: [ 4/ 5], Step: [ 533/ 600], Loss: 0.1871\n",
      "Epoch: [ 4/ 5], Step: [ 534/ 600], Loss: 0.0046\n",
      "Epoch: [ 4/ 5], Step: [ 535/ 600], Loss: 0.4608\n",
      "Epoch: [ 4/ 5], Step: [ 536/ 600], Loss: 0.6106\n",
      "Epoch: [ 4/ 5], Step: [ 537/ 600], Loss: 0.0025\n",
      "Epoch: [ 4/ 5], Step: [ 538/ 600], Loss: 0.0478\n",
      "Epoch: [ 4/ 5], Step: [ 539/ 600], Loss: 0.0029\n",
      "Epoch: [ 4/ 5], Step: [ 540/ 600], Loss: 0.0981\n",
      "Epoch: [ 4/ 5], Step: [ 541/ 600], Loss: 0.8592\n",
      "Epoch: [ 4/ 5], Step: [ 542/ 600], Loss: 0.2965\n",
      "Epoch: [ 4/ 5], Step: [ 543/ 600], Loss: 0.4042\n",
      "Epoch: [ 4/ 5], Step: [ 544/ 600], Loss: 0.0010\n",
      "Epoch: [ 4/ 5], Step: [ 545/ 600], Loss: 0.0008\n",
      "Epoch: [ 4/ 5], Step: [ 546/ 600], Loss: 0.1095\n",
      "Epoch: [ 4/ 5], Step: [ 547/ 600], Loss: 0.1308\n",
      "Epoch: [ 4/ 5], Step: [ 548/ 600], Loss: 0.3721\n",
      "Epoch: [ 4/ 5], Step: [ 549/ 600], Loss: 0.1629\n",
      "Epoch: [ 4/ 5], Step: [ 550/ 600], Loss: 0.0140\n",
      "Epoch: [ 4/ 5], Step: [ 551/ 600], Loss: 0.0086\n",
      "Epoch: [ 4/ 5], Step: [ 552/ 600], Loss: 0.0418\n",
      "Epoch: [ 4/ 5], Step: [ 553/ 600], Loss: 0.2436\n",
      "Epoch: [ 4/ 5], Step: [ 554/ 600], Loss: 0.0219\n",
      "Epoch: [ 4/ 5], Step: [ 555/ 600], Loss: 0.1181\n",
      "Epoch: [ 4/ 5], Step: [ 556/ 600], Loss: 0.1373\n",
      "Epoch: [ 4/ 5], Step: [ 557/ 600], Loss: 0.0315\n",
      "Epoch: [ 4/ 5], Step: [ 558/ 600], Loss: 0.0043\n",
      "Epoch: [ 4/ 5], Step: [ 559/ 600], Loss: 0.0602\n",
      "Epoch: [ 4/ 5], Step: [ 560/ 600], Loss: 0.3069\n",
      "Epoch: [ 4/ 5], Step: [ 561/ 600], Loss: 0.1235\n",
      "Epoch: [ 4/ 5], Step: [ 562/ 600], Loss: 0.0034\n",
      "Epoch: [ 4/ 5], Step: [ 563/ 600], Loss: 0.0625\n",
      "Epoch: [ 4/ 5], Step: [ 564/ 600], Loss: 0.0531\n",
      "Epoch: [ 4/ 5], Step: [ 565/ 600], Loss: 0.1472\n",
      "Epoch: [ 4/ 5], Step: [ 566/ 600], Loss: 1.0970\n",
      "Epoch: [ 4/ 5], Step: [ 567/ 600], Loss: 0.0242\n",
      "Epoch: [ 4/ 5], Step: [ 568/ 600], Loss: 0.0538\n",
      "Epoch: [ 4/ 5], Step: [ 569/ 600], Loss: 1.4652\n",
      "Epoch: [ 4/ 5], Step: [ 570/ 600], Loss: 0.0007\n",
      "Epoch: [ 4/ 5], Step: [ 571/ 600], Loss: 0.0595\n",
      "Epoch: [ 4/ 5], Step: [ 572/ 600], Loss: 0.0228\n",
      "Epoch: [ 4/ 5], Step: [ 573/ 600], Loss: 0.0146\n",
      "Epoch: [ 4/ 5], Step: [ 574/ 600], Loss: 0.0009\n",
      "Epoch: [ 4/ 5], Step: [ 575/ 600], Loss: 0.0037\n",
      "Epoch: [ 4/ 5], Step: [ 576/ 600], Loss: 0.4094\n",
      "Epoch: [ 4/ 5], Step: [ 577/ 600], Loss: 0.0400\n",
      "Epoch: [ 4/ 5], Step: [ 578/ 600], Loss: 1.2085\n",
      "Epoch: [ 4/ 5], Step: [ 579/ 600], Loss: 0.0431\n",
      "Epoch: [ 4/ 5], Step: [ 580/ 600], Loss: 0.0510\n",
      "Epoch: [ 4/ 5], Step: [ 581/ 600], Loss: 1.4544\n",
      "Epoch: [ 4/ 5], Step: [ 582/ 600], Loss: 0.3477\n",
      "Epoch: [ 4/ 5], Step: [ 583/ 600], Loss: 6.3578\n",
      "Epoch: [ 4/ 5], Step: [ 584/ 600], Loss: 0.0265\n",
      "Epoch: [ 4/ 5], Step: [ 585/ 600], Loss: 0.0046\n",
      "Epoch: [ 4/ 5], Step: [ 586/ 600], Loss: 0.0541\n",
      "Epoch: [ 4/ 5], Step: [ 587/ 600], Loss: 0.0050\n",
      "Epoch: [ 4/ 5], Step: [ 588/ 600], Loss: 0.0402\n",
      "Epoch: [ 4/ 5], Step: [ 589/ 600], Loss: 0.2140\n",
      "Epoch: [ 4/ 5], Step: [ 590/ 600], Loss: 0.0006\n",
      "Epoch: [ 4/ 5], Step: [ 591/ 600], Loss: 0.0168\n",
      "Epoch: [ 4/ 5], Step: [ 592/ 600], Loss: 0.0645\n",
      "Epoch: [ 4/ 5], Step: [ 593/ 600], Loss: 0.0002\n",
      "Epoch: [ 4/ 5], Step: [ 594/ 600], Loss: 0.8455\n",
      "Epoch: [ 4/ 5], Step: [ 595/ 600], Loss: 0.0132\n",
      "Epoch: [ 4/ 5], Step: [ 596/ 600], Loss: 0.0474\n",
      "Epoch: [ 4/ 5], Step: [ 597/ 600], Loss: 0.0317\n",
      "Epoch: [ 4/ 5], Step: [ 598/ 600], Loss: 4.1344\n",
      "Epoch: [ 4/ 5], Step: [ 599/ 600], Loss: 0.1530\n",
      "Epoch: [ 4/ 5], Step: [ 600/ 600], Loss: 9.4919\n",
      "Epoch: [ 5/ 5], Step: [ 1/ 600], Loss: 0.0525\n",
      "Epoch: [ 5/ 5], Step: [ 2/ 600], Loss: 0.6707\n",
      "Epoch: [ 5/ 5], Step: [ 3/ 600], Loss: 0.0008\n",
      "Epoch: [ 5/ 5], Step: [ 4/ 600], Loss: 0.5980\n",
      "Epoch: [ 5/ 5], Step: [ 5/ 600], Loss: 0.1938\n",
      "Epoch: [ 5/ 5], Step: [ 6/ 600], Loss: 0.4211\n",
      "Epoch: [ 5/ 5], Step: [ 7/ 600], Loss: 0.0192\n",
      "Epoch: [ 5/ 5], Step: [ 8/ 600], Loss: 0.0003\n",
      "Epoch: [ 5/ 5], Step: [ 9/ 600], Loss: 0.0206\n",
      "Epoch: [ 5/ 5], Step: [ 10/ 600], Loss: 0.0782\n",
      "Epoch: [ 5/ 5], Step: [ 11/ 600], Loss: 0.0296\n",
      "Epoch: [ 5/ 5], Step: [ 12/ 600], Loss: 0.9656\n",
      "Epoch: [ 5/ 5], Step: [ 13/ 600], Loss: 0.0003\n",
      "Epoch: [ 5/ 5], Step: [ 14/ 600], Loss: 0.2143\n",
      "Epoch: [ 5/ 5], Step: [ 15/ 600], Loss: 0.1063\n",
      "Epoch: [ 5/ 5], Step: [ 16/ 600], Loss: 0.0530\n",
      "Epoch: [ 5/ 5], Step: [ 17/ 600], Loss: 0.1394\n",
      "Epoch: [ 5/ 5], Step: [ 18/ 600], Loss: 0.0038\n",
      "Epoch: [ 5/ 5], Step: [ 19/ 600], Loss: 0.0452\n",
      "Epoch: [ 5/ 5], Step: [ 20/ 600], Loss: 0.2854\n",
      "Epoch: [ 5/ 5], Step: [ 21/ 600], Loss: 0.0135\n",
      "Epoch: [ 5/ 5], Step: [ 22/ 600], Loss: 0.3222\n",
      "Epoch: [ 5/ 5], Step: [ 23/ 600], Loss: 0.0233\n",
      "Epoch: [ 5/ 5], Step: [ 24/ 600], Loss: 0.1194\n",
      "Epoch: [ 5/ 5], Step: [ 25/ 600], Loss: 0.0089\n",
      "Epoch: [ 5/ 5], Step: [ 26/ 600], Loss: 0.2149\n",
      "Epoch: [ 5/ 5], Step: [ 27/ 600], Loss: 0.0320\n",
      "Epoch: [ 5/ 5], Step: [ 28/ 600], Loss: 0.7177\n",
      "Epoch: [ 5/ 5], Step: [ 29/ 600], Loss: 0.0379\n",
      "Epoch: [ 5/ 5], Step: [ 30/ 600], Loss: 0.0105\n",
      "Epoch: [ 5/ 5], Step: [ 31/ 600], Loss: 0.4217\n",
      "Epoch: [ 5/ 5], Step: [ 32/ 600], Loss: 0.0394\n",
      "Epoch: [ 5/ 5], Step: [ 33/ 600], Loss: 0.0056\n",
      "Epoch: [ 5/ 5], Step: [ 34/ 600], Loss: 0.2968\n",
      "Epoch: [ 5/ 5], Step: [ 35/ 600], Loss: 0.0021\n",
      "Epoch: [ 5/ 5], Step: [ 36/ 600], Loss: 0.0005\n",
      "Epoch: [ 5/ 5], Step: [ 37/ 600], Loss: 0.0143\n",
      "Epoch: [ 5/ 5], Step: [ 38/ 600], Loss: 2.6008\n",
      "Epoch: [ 5/ 5], Step: [ 39/ 600], Loss: 0.0134\n",
      "Epoch: [ 5/ 5], Step: [ 40/ 600], Loss: 0.0156\n",
      "Epoch: [ 5/ 5], Step: [ 41/ 600], Loss: 0.0018\n",
      "Epoch: [ 5/ 5], Step: [ 42/ 600], Loss: 0.0033\n",
      "Epoch: [ 5/ 5], Step: [ 43/ 600], Loss: 1.7041\n",
      "Epoch: [ 5/ 5], Step: [ 44/ 600], Loss: 0.0024\n",
      "Epoch: [ 5/ 5], Step: [ 45/ 600], Loss: 0.0199\n",
      "Epoch: [ 5/ 5], Step: [ 46/ 600], Loss: 0.0782\n",
      "Epoch: [ 5/ 5], Step: [ 47/ 600], Loss: 0.0133\n",
      "Epoch: [ 5/ 5], Step: [ 48/ 600], Loss: 0.0273\n",
      "Epoch: [ 5/ 5], Step: [ 49/ 600], Loss: 0.0254\n",
      "Epoch: [ 5/ 5], Step: [ 50/ 600], Loss: 0.0006\n",
      "Epoch: [ 5/ 5], Step: [ 51/ 600], Loss: 0.0186\n",
      "Epoch: [ 5/ 5], Step: [ 52/ 600], Loss: 0.0094\n",
      "Epoch: [ 5/ 5], Step: [ 53/ 600], Loss: 0.1331\n",
      "Epoch: [ 5/ 5], Step: [ 54/ 600], Loss: 0.0741\n",
      "Epoch: [ 5/ 5], Step: [ 55/ 600], Loss: 0.2320\n",
      "Epoch: [ 5/ 5], Step: [ 56/ 600], Loss: 0.1051\n",
      "Epoch: [ 5/ 5], Step: [ 57/ 600], Loss: 0.0317\n",
      "Epoch: [ 5/ 5], Step: [ 58/ 600], Loss: 0.3137\n",
      "Epoch: [ 5/ 5], Step: [ 59/ 600], Loss: 0.0048\n",
      "Epoch: [ 5/ 5], Step: [ 60/ 600], Loss: 0.0199\n",
      "Epoch: [ 5/ 5], Step: [ 61/ 600], Loss: 0.8181\n",
      "Epoch: [ 5/ 5], Step: [ 62/ 600], Loss: 0.0010\n",
      "Epoch: [ 5/ 5], Step: [ 63/ 600], Loss: 0.1327\n",
      "Epoch: [ 5/ 5], Step: [ 64/ 600], Loss: 0.0583\n",
      "Epoch: [ 5/ 5], Step: [ 65/ 600], Loss: 0.0243\n",
      "Epoch: [ 5/ 5], Step: [ 66/ 600], Loss: 0.0484\n",
      "Epoch: [ 5/ 5], Step: [ 67/ 600], Loss: 0.2644\n",
      "Epoch: [ 5/ 5], Step: [ 68/ 600], Loss: 0.0310\n",
      "Epoch: [ 5/ 5], Step: [ 69/ 600], Loss: 0.0418\n",
      "Epoch: [ 5/ 5], Step: [ 70/ 600], Loss: 0.0717\n",
      "Epoch: [ 5/ 5], Step: [ 71/ 600], Loss: 0.0000\n",
      "Epoch: [ 5/ 5], Step: [ 72/ 600], Loss: 0.0093\n",
      "Epoch: [ 5/ 5], Step: [ 73/ 600], Loss: 0.0638\n",
      "Epoch: [ 5/ 5], Step: [ 74/ 600], Loss: 0.0047\n",
      "Epoch: [ 5/ 5], Step: [ 75/ 600], Loss: 0.0037\n",
      "Epoch: [ 5/ 5], Step: [ 76/ 600], Loss: 3.8822\n",
      "Epoch: [ 5/ 5], Step: [ 77/ 600], Loss: 0.0646\n",
      "Epoch: [ 5/ 5], Step: [ 78/ 600], Loss: 0.0090\n",
      "Epoch: [ 5/ 5], Step: [ 79/ 600], Loss: 0.2203\n",
      "Epoch: [ 5/ 5], Step: [ 80/ 600], Loss: 0.0349\n",
      "Epoch: [ 5/ 5], Step: [ 81/ 600], Loss: 0.0137\n",
      "Epoch: [ 5/ 5], Step: [ 82/ 600], Loss: 0.0112\n",
      "Epoch: [ 5/ 5], Step: [ 83/ 600], Loss: 0.0333\n",
      "Epoch: [ 5/ 5], Step: [ 84/ 600], Loss: 0.0482\n",
      "Epoch: [ 5/ 5], Step: [ 85/ 600], Loss: 0.0973\n",
      "Epoch: [ 5/ 5], Step: [ 86/ 600], Loss: 0.5120\n",
      "Epoch: [ 5/ 5], Step: [ 87/ 600], Loss: 0.0989\n",
      "Epoch: [ 5/ 5], Step: [ 88/ 600], Loss: 0.4225\n",
      "Epoch: [ 5/ 5], Step: [ 89/ 600], Loss: 0.0873\n",
      "Epoch: [ 5/ 5], Step: [ 90/ 600], Loss: 0.0246\n",
      "Epoch: [ 5/ 5], Step: [ 91/ 600], Loss: 0.0102\n",
      "Epoch: [ 5/ 5], Step: [ 92/ 600], Loss: 0.0387\n",
      "Epoch: [ 5/ 5], Step: [ 93/ 600], Loss: 0.0159\n",
      "Epoch: [ 5/ 5], Step: [ 94/ 600], Loss: 0.2925\n",
      "Epoch: [ 5/ 5], Step: [ 95/ 600], Loss: 0.5594\n",
      "Epoch: [ 5/ 5], Step: [ 96/ 600], Loss: 0.1339\n",
      "Epoch: [ 5/ 5], Step: [ 97/ 600], Loss: 0.0013\n",
      "Epoch: [ 5/ 5], Step: [ 98/ 600], Loss: 0.0026\n",
      "Epoch: [ 5/ 5], Step: [ 99/ 600], Loss: 0.0098\n",
      "Epoch: [ 5/ 5], Step: [ 100/ 600], Loss: 0.0164\n",
      "Epoch: [ 5/ 5], Step: [ 101/ 600], Loss: 1.2052\n",
      "Epoch: [ 5/ 5], Step: [ 102/ 600], Loss: 0.1414\n",
      "Epoch: [ 5/ 5], Step: [ 103/ 600], Loss: 0.1483\n",
      "Epoch: [ 5/ 5], Step: [ 104/ 600], Loss: 0.0093\n",
      "Epoch: [ 5/ 5], Step: [ 105/ 600], Loss: 0.0410\n",
      "Epoch: [ 5/ 5], Step: [ 106/ 600], Loss: 0.0102\n",
      "Epoch: [ 5/ 5], Step: [ 107/ 600], Loss: 0.0145\n",
      "Epoch: [ 5/ 5], Step: [ 108/ 600], Loss: 0.0312\n",
      "Epoch: [ 5/ 5], Step: [ 109/ 600], Loss: 0.0314\n",
      "Epoch: [ 5/ 5], Step: [ 110/ 600], Loss: 0.1455\n",
      "Epoch: [ 5/ 5], Step: [ 111/ 600], Loss: 0.0032\n",
      "Epoch: [ 5/ 5], Step: [ 112/ 600], Loss: 0.0108\n",
      "Epoch: [ 5/ 5], Step: [ 113/ 600], Loss: 0.0004\n",
      "Epoch: [ 5/ 5], Step: [ 114/ 600], Loss: 0.1502\n",
      "Epoch: [ 5/ 5], Step: [ 115/ 600], Loss: 0.0491\n",
      "Epoch: [ 5/ 5], Step: [ 116/ 600], Loss: 1.8041\n",
      "Epoch: [ 5/ 5], Step: [ 117/ 600], Loss: 0.5848\n",
      "Epoch: [ 5/ 5], Step: [ 118/ 600], Loss: 0.0313\n",
      "Epoch: [ 5/ 5], Step: [ 119/ 600], Loss: 0.0004\n",
      "Epoch: [ 5/ 5], Step: [ 120/ 600], Loss: 0.1516\n",
      "Epoch: [ 5/ 5], Step: [ 121/ 600], Loss: 0.0733\n",
      "Epoch: [ 5/ 5], Step: [ 122/ 600], Loss: 0.0603\n",
      "Epoch: [ 5/ 5], Step: [ 123/ 600], Loss: 0.0058\n",
      "Epoch: [ 5/ 5], Step: [ 124/ 600], Loss: 0.0033\n",
      "Epoch: [ 5/ 5], Step: [ 125/ 600], Loss: 0.0592\n",
      "Epoch: [ 5/ 5], Step: [ 126/ 600], Loss: 0.0914\n",
      "Epoch: [ 5/ 5], Step: [ 127/ 600], Loss: 0.0061\n",
      "Epoch: [ 5/ 5], Step: [ 128/ 600], Loss: 0.0847\n",
      "Epoch: [ 5/ 5], Step: [ 129/ 600], Loss: 0.0581\n",
      "Epoch: [ 5/ 5], Step: [ 130/ 600], Loss: 0.5283\n",
      "Epoch: [ 5/ 5], Step: [ 131/ 600], Loss: 0.0137\n",
      "Epoch: [ 5/ 5], Step: [ 132/ 600], Loss: 0.5674\n",
      "Epoch: [ 5/ 5], Step: [ 133/ 600], Loss: 0.2824\n",
      "Epoch: [ 5/ 5], Step: [ 134/ 600], Loss: 0.0143\n",
      "Epoch: [ 5/ 5], Step: [ 135/ 600], Loss: 2.0324\n",
      "Epoch: [ 5/ 5], Step: [ 136/ 600], Loss: 0.1445\n",
      "Epoch: [ 5/ 5], Step: [ 137/ 600], Loss: 2.4320\n",
      "Epoch: [ 5/ 5], Step: [ 138/ 600], Loss: 0.1550\n",
      "Epoch: [ 5/ 5], Step: [ 139/ 600], Loss: 0.0512\n",
      "Epoch: [ 5/ 5], Step: [ 140/ 600], Loss: 0.5343\n",
      "Epoch: [ 5/ 5], Step: [ 141/ 600], Loss: 0.2429\n",
      "Epoch: [ 5/ 5], Step: [ 142/ 600], Loss: 0.0108\n",
      "Epoch: [ 5/ 5], Step: [ 143/ 600], Loss: 0.1008\n",
      "Epoch: [ 5/ 5], Step: [ 144/ 600], Loss: 0.0343\n",
      "Epoch: [ 5/ 5], Step: [ 145/ 600], Loss: 0.3559\n",
      "Epoch: [ 5/ 5], Step: [ 146/ 600], Loss: 0.1820\n",
      "Epoch: [ 5/ 5], Step: [ 147/ 600], Loss: 0.4010\n",
      "Epoch: [ 5/ 5], Step: [ 148/ 600], Loss: 0.0126\n",
      "Epoch: [ 5/ 5], Step: [ 149/ 600], Loss: 0.0279\n",
      "Epoch: [ 5/ 5], Step: [ 150/ 600], Loss: 0.3413\n",
      "Epoch: [ 5/ 5], Step: [ 151/ 600], Loss: 0.0258\n",
      "Epoch: [ 5/ 5], Step: [ 152/ 600], Loss: 0.0682\n",
      "Epoch: [ 5/ 5], Step: [ 153/ 600], Loss: 0.4008\n",
      "Epoch: [ 5/ 5], Step: [ 154/ 600], Loss: 1.0926\n",
      "Epoch: [ 5/ 5], Step: [ 155/ 600], Loss: 0.5491\n",
      "Epoch: [ 5/ 5], Step: [ 156/ 600], Loss: 0.0363\n",
      "Epoch: [ 5/ 5], Step: [ 157/ 600], Loss: 1.2334\n",
      "Epoch: [ 5/ 5], Step: [ 158/ 600], Loss: 0.0002\n",
      "Epoch: [ 5/ 5], Step: [ 159/ 600], Loss: 0.0325\n",
      "Epoch: [ 5/ 5], Step: [ 160/ 600], Loss: 0.0012\n",
      "Epoch: [ 5/ 5], Step: [ 161/ 600], Loss: 0.0896\n",
      "Epoch: [ 5/ 5], Step: [ 162/ 600], Loss: 0.0578\n",
      "Epoch: [ 5/ 5], Step: [ 163/ 600], Loss: 0.0818\n",
      "Epoch: [ 5/ 5], Step: [ 164/ 600], Loss: 0.0738\n",
      "Epoch: [ 5/ 5], Step: [ 165/ 600], Loss: 1.7781\n",
      "Epoch: [ 5/ 5], Step: [ 166/ 600], Loss: 0.0095\n",
      "Epoch: [ 5/ 5], Step: [ 167/ 600], Loss: 0.2139\n",
      "Epoch: [ 5/ 5], Step: [ 168/ 600], Loss: 0.1262\n",
      "Epoch: [ 5/ 5], Step: [ 169/ 600], Loss: 0.4789\n",
      "Epoch: [ 5/ 5], Step: [ 170/ 600], Loss: 0.0870\n",
      "Epoch: [ 5/ 5], Step: [ 171/ 600], Loss: 0.0154\n",
      "Epoch: [ 5/ 5], Step: [ 172/ 600], Loss: 0.1655\n",
      "Epoch: [ 5/ 5], Step: [ 173/ 600], Loss: 0.2573\n",
      "Epoch: [ 5/ 5], Step: [ 174/ 600], Loss: 0.0085\n",
      "Epoch: [ 5/ 5], Step: [ 175/ 600], Loss: 0.4646\n",
      "Epoch: [ 5/ 5], Step: [ 176/ 600], Loss: 0.0459\n",
      "Epoch: [ 5/ 5], Step: [ 177/ 600], Loss: 1.2891\n",
      "Epoch: [ 5/ 5], Step: [ 178/ 600], Loss: 0.0030\n",
      "Epoch: [ 5/ 5], Step: [ 179/ 600], Loss: 0.0441\n",
      "Epoch: [ 5/ 5], Step: [ 180/ 600], Loss: 0.1808\n",
      "Epoch: [ 5/ 5], Step: [ 181/ 600], Loss: 0.0346\n",
      "Epoch: [ 5/ 5], Step: [ 182/ 600], Loss: 0.1069\n",
      "Epoch: [ 5/ 5], Step: [ 183/ 600], Loss: 1.5095\n",
      "Epoch: [ 5/ 5], Step: [ 184/ 600], Loss: 0.0119\n",
      "Epoch: [ 5/ 5], Step: [ 185/ 600], Loss: 1.2685\n",
      "Epoch: [ 5/ 5], Step: [ 186/ 600], Loss: 0.0193\n",
      "Epoch: [ 5/ 5], Step: [ 187/ 600], Loss: 0.0006\n",
      "Epoch: [ 5/ 5], Step: [ 188/ 600], Loss: 1.7258\n",
      "Epoch: [ 5/ 5], Step: [ 189/ 600], Loss: 0.0003\n",
      "Epoch: [ 5/ 5], Step: [ 190/ 600], Loss: 0.0069\n",
      "Epoch: [ 5/ 5], Step: [ 191/ 600], Loss: 0.7353\n",
      "Epoch: [ 5/ 5], Step: [ 192/ 600], Loss: 0.0138\n",
      "Epoch: [ 5/ 5], Step: [ 193/ 600], Loss: 0.0686\n",
      "Epoch: [ 5/ 5], Step: [ 194/ 600], Loss: 0.1334\n",
      "Epoch: [ 5/ 5], Step: [ 195/ 600], Loss: 0.0008\n",
      "Epoch: [ 5/ 5], Step: [ 196/ 600], Loss: 0.6564\n",
      "Epoch: [ 5/ 5], Step: [ 197/ 600], Loss: 2.3553\n",
      "Epoch: [ 5/ 5], Step: [ 198/ 600], Loss: 0.1047\n",
      "Epoch: [ 5/ 5], Step: [ 199/ 600], Loss: 0.2536\n",
      "Epoch: [ 5/ 5], Step: [ 200/ 600], Loss: 0.0937\n",
      "Epoch: [ 5/ 5], Step: [ 201/ 600], Loss: 0.2311\n",
      "Epoch: [ 5/ 5], Step: [ 202/ 600], Loss: 0.0118\n",
      "Epoch: [ 5/ 5], Step: [ 203/ 600], Loss: 0.0351\n",
      "Epoch: [ 5/ 5], Step: [ 204/ 600], Loss: 0.0417\n",
      "Epoch: [ 5/ 5], Step: [ 205/ 600], Loss: 0.0081\n",
      "Epoch: [ 5/ 5], Step: [ 206/ 600], Loss: 0.0418\n",
      "Epoch: [ 5/ 5], Step: [ 207/ 600], Loss: 0.0192\n",
      "Epoch: [ 5/ 5], Step: [ 208/ 600], Loss: 0.0232\n",
      "Epoch: [ 5/ 5], Step: [ 209/ 600], Loss: 0.0506\n",
      "Epoch: [ 5/ 5], Step: [ 210/ 600], Loss: 0.0067\n",
      "Epoch: [ 5/ 5], Step: [ 211/ 600], Loss: 0.0158\n",
      "Epoch: [ 5/ 5], Step: [ 212/ 600], Loss: 0.2454\n",
      "Epoch: [ 5/ 5], Step: [ 213/ 600], Loss: 0.1584\n",
      "Epoch: [ 5/ 5], Step: [ 214/ 600], Loss: 0.5244\n",
      "Epoch: [ 5/ 5], Step: [ 215/ 600], Loss: 0.0108\n",
      "Epoch: [ 5/ 5], Step: [ 216/ 600], Loss: 0.0239\n",
      "Epoch: [ 5/ 5], Step: [ 217/ 600], Loss: 0.8902\n",
      "Epoch: [ 5/ 5], Step: [ 218/ 600], Loss: 0.0445\n",
      "Epoch: [ 5/ 5], Step: [ 219/ 600], Loss: 0.0546\n",
      "Epoch: [ 5/ 5], Step: [ 220/ 600], Loss: 0.0115\n",
      "Epoch: [ 5/ 5], Step: [ 221/ 600], Loss: 0.1762\n",
      "Epoch: [ 5/ 5], Step: [ 222/ 600], Loss: 0.0007\n",
      "Epoch: [ 5/ 5], Step: [ 223/ 600], Loss: 0.0079\n",
      "Epoch: [ 5/ 5], Step: [ 224/ 600], Loss: 0.2015\n",
      "Epoch: [ 5/ 5], Step: [ 225/ 600], Loss: 0.0047\n",
      "Epoch: [ 5/ 5], Step: [ 226/ 600], Loss: 0.1128\n",
      "Epoch: [ 5/ 5], Step: [ 227/ 600], Loss: 0.0034\n",
      "Epoch: [ 5/ 5], Step: [ 228/ 600], Loss: 0.0012\n",
      "Epoch: [ 5/ 5], Step: [ 229/ 600], Loss: 0.0038\n",
      "Epoch: [ 5/ 5], Step: [ 230/ 600], Loss: 1.1225\n",
      "Epoch: [ 5/ 5], Step: [ 231/ 600], Loss: 0.5258\n",
      "Epoch: [ 5/ 5], Step: [ 232/ 600], Loss: 0.3252\n",
      "Epoch: [ 5/ 5], Step: [ 233/ 600], Loss: 0.0074\n",
      "Epoch: [ 5/ 5], Step: [ 234/ 600], Loss: 0.0035\n",
      "Epoch: [ 5/ 5], Step: [ 235/ 600], Loss: 0.0047\n",
      "Epoch: [ 5/ 5], Step: [ 236/ 600], Loss: 0.0108\n",
      "Epoch: [ 5/ 5], Step: [ 237/ 600], Loss: 0.0850\n",
      "Epoch: [ 5/ 5], Step: [ 238/ 600], Loss: 0.2083\n",
      "Epoch: [ 5/ 5], Step: [ 239/ 600], Loss: 0.2249\n",
      "Epoch: [ 5/ 5], Step: [ 240/ 600], Loss: 0.0005\n",
      "Epoch: [ 5/ 5], Step: [ 241/ 600], Loss: 0.0094\n",
      "Epoch: [ 5/ 5], Step: [ 242/ 600], Loss: 0.0120\n",
      "Epoch: [ 5/ 5], Step: [ 243/ 600], Loss: 0.1088\n",
      "Epoch: [ 5/ 5], Step: [ 244/ 600], Loss: 0.0121\n",
      "Epoch: [ 5/ 5], Step: [ 245/ 600], Loss: 0.0132\n",
      "Epoch: [ 5/ 5], Step: [ 246/ 600], Loss: 2.2752\n",
      "Epoch: [ 5/ 5], Step: [ 247/ 600], Loss: 1.0735\n",
      "Epoch: [ 5/ 5], Step: [ 248/ 600], Loss: 0.0005\n",
      "Epoch: [ 5/ 5], Step: [ 249/ 600], Loss: 0.1314\n",
      "Epoch: [ 5/ 5], Step: [ 250/ 600], Loss: 0.1474\n",
      "Epoch: [ 5/ 5], Step: [ 251/ 600], Loss: 0.0040\n",
      "Epoch: [ 5/ 5], Step: [ 252/ 600], Loss: 0.2420\n",
      "Epoch: [ 5/ 5], Step: [ 253/ 600], Loss: 1.1104\n",
      "Epoch: [ 5/ 5], Step: [ 254/ 600], Loss: 0.0327\n",
      "Epoch: [ 5/ 5], Step: [ 255/ 600], Loss: 0.0001\n",
      "Epoch: [ 5/ 5], Step: [ 256/ 600], Loss: 0.7515\n",
      "Epoch: [ 5/ 5], Step: [ 257/ 600], Loss: 0.0162\n",
      "Epoch: [ 5/ 5], Step: [ 258/ 600], Loss: 0.0645\n",
      "Epoch: [ 5/ 5], Step: [ 259/ 600], Loss: 0.0041\n",
      "Epoch: [ 5/ 5], Step: [ 260/ 600], Loss: 0.0722\n",
      "Epoch: [ 5/ 5], Step: [ 261/ 600], Loss: 1.3959\n",
      "Epoch: [ 5/ 5], Step: [ 262/ 600], Loss: 0.3183\n",
      "Epoch: [ 5/ 5], Step: [ 263/ 600], Loss: 0.0238\n",
      "Epoch: [ 5/ 5], Step: [ 264/ 600], Loss: 0.5522\n",
      "Epoch: [ 5/ 5], Step: [ 265/ 600], Loss: 0.0050\n",
      "Epoch: [ 5/ 5], Step: [ 266/ 600], Loss: 0.0138\n",
      "Epoch: [ 5/ 5], Step: [ 267/ 600], Loss: 0.0368\n",
      "Epoch: [ 5/ 5], Step: [ 268/ 600], Loss: 0.6000\n",
      "Epoch: [ 5/ 5], Step: [ 269/ 600], Loss: 0.0548\n",
      "Epoch: [ 5/ 5], Step: [ 270/ 600], Loss: 2.9675\n",
      "Epoch: [ 5/ 5], Step: [ 271/ 600], Loss: 0.0062\n",
      "Epoch: [ 5/ 5], Step: [ 272/ 600], Loss: 0.0069\n",
      "Epoch: [ 5/ 5], Step: [ 273/ 600], Loss: 0.0247\n",
      "Epoch: [ 5/ 5], Step: [ 274/ 600], Loss: 0.1732\n",
      "Epoch: [ 5/ 5], Step: [ 275/ 600], Loss: 0.0182\n",
      "Epoch: [ 5/ 5], Step: [ 276/ 600], Loss: 0.0227\n",
      "Epoch: [ 5/ 5], Step: [ 277/ 600], Loss: 0.1384\n",
      "Epoch: [ 5/ 5], Step: [ 278/ 600], Loss: 0.0060\n",
      "Epoch: [ 5/ 5], Step: [ 279/ 600], Loss: 0.0081\n",
      "Epoch: [ 5/ 5], Step: [ 280/ 600], Loss: 0.0940\n",
      "Epoch: [ 5/ 5], Step: [ 281/ 600], Loss: 0.2216\n",
      "Epoch: [ 5/ 5], Step: [ 282/ 600], Loss: 0.0094\n",
      "Epoch: [ 5/ 5], Step: [ 283/ 600], Loss: 0.0305\n",
      "Epoch: [ 5/ 5], Step: [ 284/ 600], Loss: 0.1209\n",
      "Epoch: [ 5/ 5], Step: [ 285/ 600], Loss: 0.1087\n",
      "Epoch: [ 5/ 5], Step: [ 286/ 600], Loss: 0.2638\n",
      "Epoch: [ 5/ 5], Step: [ 287/ 600], Loss: 0.1918\n",
      "Epoch: [ 5/ 5], Step: [ 288/ 600], Loss: 0.0003\n",
      "Epoch: [ 5/ 5], Step: [ 289/ 600], Loss: 0.0004\n",
      "Epoch: [ 5/ 5], Step: [ 290/ 600], Loss: 0.1695\n",
      "Epoch: [ 5/ 5], Step: [ 291/ 600], Loss: 0.0008\n",
      "Epoch: [ 5/ 5], Step: [ 292/ 600], Loss: 1.9328\n",
      "Epoch: [ 5/ 5], Step: [ 293/ 600], Loss: 0.7200\n",
      "Epoch: [ 5/ 5], Step: [ 294/ 600], Loss: 0.0261\n",
      "Epoch: [ 5/ 5], Step: [ 295/ 600], Loss: 0.0956\n",
      "Epoch: [ 5/ 5], Step: [ 296/ 600], Loss: 0.6887\n",
      "Epoch: [ 5/ 5], Step: [ 297/ 600], Loss: 0.2856\n",
      "Epoch: [ 5/ 5], Step: [ 298/ 600], Loss: 0.1260\n",
      "Epoch: [ 5/ 5], Step: [ 299/ 600], Loss: 0.0009\n",
      "Epoch: [ 5/ 5], Step: [ 300/ 600], Loss: 0.0015\n",
      "Epoch: [ 5/ 5], Step: [ 301/ 600], Loss: 0.1552\n",
      "Epoch: [ 5/ 5], Step: [ 302/ 600], Loss: 0.0097\n",
      "Epoch: [ 5/ 5], Step: [ 303/ 600], Loss: 0.2541\n",
      "Epoch: [ 5/ 5], Step: [ 304/ 600], Loss: 4.4978\n",
      "Epoch: [ 5/ 5], Step: [ 305/ 600], Loss: 0.0188\n",
      "Epoch: [ 5/ 5], Step: [ 306/ 600], Loss: 3.5722\n",
      "Epoch: [ 5/ 5], Step: [ 307/ 600], Loss: 0.0314\n",
      "Epoch: [ 5/ 5], Step: [ 308/ 600], Loss: 0.0038\n",
      "Epoch: [ 5/ 5], Step: [ 309/ 600], Loss: 0.0206\n",
      "Epoch: [ 5/ 5], Step: [ 310/ 600], Loss: 0.0077\n",
      "Epoch: [ 5/ 5], Step: [ 311/ 600], Loss: 0.0233\n",
      "Epoch: [ 5/ 5], Step: [ 312/ 600], Loss: 0.0175\n",
      "Epoch: [ 5/ 5], Step: [ 313/ 600], Loss: 0.7665\n",
      "Epoch: [ 5/ 5], Step: [ 314/ 600], Loss: 0.6144\n",
      "Epoch: [ 5/ 5], Step: [ 315/ 600], Loss: 0.0306\n",
      "Epoch: [ 5/ 5], Step: [ 316/ 600], Loss: 0.1948\n",
      "Epoch: [ 5/ 5], Step: [ 317/ 600], Loss: 0.1551\n",
      "Epoch: [ 5/ 5], Step: [ 318/ 600], Loss: 0.0307\n",
      "Epoch: [ 5/ 5], Step: [ 319/ 600], Loss: 0.0162\n",
      "Epoch: [ 5/ 5], Step: [ 320/ 600], Loss: 0.2574\n",
      "Epoch: [ 5/ 5], Step: [ 321/ 600], Loss: 0.0059\n",
      "Epoch: [ 5/ 5], Step: [ 322/ 600], Loss: 1.5028\n",
      "Epoch: [ 5/ 5], Step: [ 323/ 600], Loss: 0.9305\n",
      "Epoch: [ 5/ 5], Step: [ 324/ 600], Loss: 0.8715\n",
      "Epoch: [ 5/ 5], Step: [ 325/ 600], Loss: 0.0055\n",
      "Epoch: [ 5/ 5], Step: [ 326/ 600], Loss: 0.0052\n",
      "Epoch: [ 5/ 5], Step: [ 327/ 600], Loss: 0.0193\n",
      "Epoch: [ 5/ 5], Step: [ 328/ 600], Loss: 0.0882\n",
      "Epoch: [ 5/ 5], Step: [ 329/ 600], Loss: 0.0806\n",
      "Epoch: [ 5/ 5], Step: [ 330/ 600], Loss: 0.0186\n",
      "Epoch: [ 5/ 5], Step: [ 331/ 600], Loss: 0.0109\n",
      "Epoch: [ 5/ 5], Step: [ 332/ 600], Loss: 0.0204\n",
      "Epoch: [ 5/ 5], Step: [ 333/ 600], Loss: 0.0006\n",
      "Epoch: [ 5/ 5], Step: [ 334/ 600], Loss: 0.0575\n",
      "Epoch: [ 5/ 5], Step: [ 335/ 600], Loss: 0.4698\n",
      "Epoch: [ 5/ 5], Step: [ 336/ 600], Loss: 0.0272\n",
      "Epoch: [ 5/ 5], Step: [ 337/ 600], Loss: 6.6199\n",
      "Epoch: [ 5/ 5], Step: [ 338/ 600], Loss: 0.0042\n",
      "Epoch: [ 5/ 5], Step: [ 339/ 600], Loss: 0.1674\n",
      "Epoch: [ 5/ 5], Step: [ 340/ 600], Loss: 0.0281\n",
      "Epoch: [ 5/ 5], Step: [ 341/ 600], Loss: 1.2956\n",
      "Epoch: [ 5/ 5], Step: [ 342/ 600], Loss: 0.1559\n",
      "Epoch: [ 5/ 5], Step: [ 343/ 600], Loss: 0.4607\n",
      "Epoch: [ 5/ 5], Step: [ 344/ 600], Loss: 0.0151\n",
      "Epoch: [ 5/ 5], Step: [ 345/ 600], Loss: 0.7932\n",
      "Epoch: [ 5/ 5], Step: [ 346/ 600], Loss: 0.0753\n",
      "Epoch: [ 5/ 5], Step: [ 347/ 600], Loss: 0.1468\n",
      "Epoch: [ 5/ 5], Step: [ 348/ 600], Loss: 0.0658\n",
      "Epoch: [ 5/ 5], Step: [ 349/ 600], Loss: 0.0130\n",
      "Epoch: [ 5/ 5], Step: [ 350/ 600], Loss: 0.2454\n",
      "Epoch: [ 5/ 5], Step: [ 351/ 600], Loss: 0.1278\n",
      "Epoch: [ 5/ 5], Step: [ 352/ 600], Loss: 0.0068\n",
      "Epoch: [ 5/ 5], Step: [ 353/ 600], Loss: 0.0715\n",
      "Epoch: [ 5/ 5], Step: [ 354/ 600], Loss: 0.0238\n",
      "Epoch: [ 5/ 5], Step: [ 355/ 600], Loss: 0.0286\n",
      "Epoch: [ 5/ 5], Step: [ 356/ 600], Loss: 0.0430\n",
      "Epoch: [ 5/ 5], Step: [ 357/ 600], Loss: 0.4279\n",
      "Epoch: [ 5/ 5], Step: [ 358/ 600], Loss: 0.1336\n",
      "Epoch: [ 5/ 5], Step: [ 359/ 600], Loss: 0.0202\n",
      "Epoch: [ 5/ 5], Step: [ 360/ 600], Loss: 0.3633\n",
      "Epoch: [ 5/ 5], Step: [ 361/ 600], Loss: 0.6860\n",
      "Epoch: [ 5/ 5], Step: [ 362/ 600], Loss: 0.0478\n",
      "Epoch: [ 5/ 5], Step: [ 363/ 600], Loss: 0.0057\n",
      "Epoch: [ 5/ 5], Step: [ 364/ 600], Loss: 0.0221\n",
      "Epoch: [ 5/ 5], Step: [ 365/ 600], Loss: 0.0594\n",
      "Epoch: [ 5/ 5], Step: [ 366/ 600], Loss: 0.0837\n",
      "Epoch: [ 5/ 5], Step: [ 367/ 600], Loss: 3.9731\n",
      "Epoch: [ 5/ 5], Step: [ 368/ 600], Loss: 0.1344\n",
      "Epoch: [ 5/ 5], Step: [ 369/ 600], Loss: 0.3524\n",
      "Epoch: [ 5/ 5], Step: [ 370/ 600], Loss: 0.1095\n",
      "Epoch: [ 5/ 5], Step: [ 371/ 600], Loss: 0.0391\n",
      "Epoch: [ 5/ 5], Step: [ 372/ 600], Loss: 0.5426\n",
      "Epoch: [ 5/ 5], Step: [ 373/ 600], Loss: 0.0083\n",
      "Epoch: [ 5/ 5], Step: [ 374/ 600], Loss: 0.1960\n",
      "Epoch: [ 5/ 5], Step: [ 375/ 600], Loss: 1.3571\n",
      "Epoch: [ 5/ 5], Step: [ 376/ 600], Loss: 0.0247\n",
      "Epoch: [ 5/ 5], Step: [ 377/ 600], Loss: 0.0012\n",
      "Epoch: [ 5/ 5], Step: [ 378/ 600], Loss: 3.9380\n",
      "Epoch: [ 5/ 5], Step: [ 379/ 600], Loss: 0.0532\n",
      "Epoch: [ 5/ 5], Step: [ 380/ 600], Loss: 0.1113\n",
      "Epoch: [ 5/ 5], Step: [ 381/ 600], Loss: 0.0143\n",
      "Epoch: [ 5/ 5], Step: [ 382/ 600], Loss: 0.0001\n",
      "Epoch: [ 5/ 5], Step: [ 383/ 600], Loss: 0.2917\n",
      "Epoch: [ 5/ 5], Step: [ 384/ 600], Loss: 0.0861\n",
      "Epoch: [ 5/ 5], Step: [ 385/ 600], Loss: 0.0659\n",
      "Epoch: [ 5/ 5], Step: [ 386/ 600], Loss: 0.0084\n",
      "Epoch: [ 5/ 5], Step: [ 387/ 600], Loss: 0.0008\n",
      "Epoch: [ 5/ 5], Step: [ 388/ 600], Loss: 0.0146\n",
      "Epoch: [ 5/ 5], Step: [ 389/ 600], Loss: 0.0094\n",
      "Epoch: [ 5/ 5], Step: [ 390/ 600], Loss: 1.5475\n",
      "Epoch: [ 5/ 5], Step: [ 391/ 600], Loss: 0.5121\n",
      "Epoch: [ 5/ 5], Step: [ 392/ 600], Loss: 0.0785\n",
      "Epoch: [ 5/ 5], Step: [ 393/ 600], Loss: 0.0692\n",
      "Epoch: [ 5/ 5], Step: [ 394/ 600], Loss: 5.5062\n",
      "Epoch: [ 5/ 5], Step: [ 395/ 600], Loss: 0.5109\n",
      "Epoch: [ 5/ 5], Step: [ 396/ 600], Loss: 0.6080\n",
      "Epoch: [ 5/ 5], Step: [ 397/ 600], Loss: 0.0140\n",
      "Epoch: [ 5/ 5], Step: [ 398/ 600], Loss: 0.0563\n",
      "Epoch: [ 5/ 5], Step: [ 399/ 600], Loss: 0.0550\n",
      "Epoch: [ 5/ 5], Step: [ 400/ 600], Loss: 0.0781\n",
      "Epoch: [ 5/ 5], Step: [ 401/ 600], Loss: 0.2478\n",
      "Epoch: [ 5/ 5], Step: [ 402/ 600], Loss: 0.0344\n",
      "Epoch: [ 5/ 5], Step: [ 403/ 600], Loss: 1.6764\n",
      "Epoch: [ 5/ 5], Step: [ 404/ 600], Loss: 0.0081\n",
      "Epoch: [ 5/ 5], Step: [ 405/ 600], Loss: 2.4004\n",
      "Epoch: [ 5/ 5], Step: [ 406/ 600], Loss: 0.1254\n",
      "Epoch: [ 5/ 5], Step: [ 407/ 600], Loss: 0.0401\n",
      "Epoch: [ 5/ 5], Step: [ 408/ 600], Loss: 0.0318\n",
      "Epoch: [ 5/ 5], Step: [ 409/ 600], Loss: 0.0155\n",
      "Epoch: [ 5/ 5], Step: [ 410/ 600], Loss: 0.0500\n",
      "Epoch: [ 5/ 5], Step: [ 411/ 600], Loss: 0.0207\n",
      "Epoch: [ 5/ 5], Step: [ 412/ 600], Loss: 0.0638\n",
      "Epoch: [ 5/ 5], Step: [ 413/ 600], Loss: 1.4784\n",
      "Epoch: [ 5/ 5], Step: [ 414/ 600], Loss: 5.6501\n",
      "Epoch: [ 5/ 5], Step: [ 415/ 600], Loss: 0.0131\n",
      "Epoch: [ 5/ 5], Step: [ 416/ 600], Loss: 2.5391\n",
      "Epoch: [ 5/ 5], Step: [ 417/ 600], Loss: 0.0187\n",
      "Epoch: [ 5/ 5], Step: [ 418/ 600], Loss: 0.0004\n",
      "Epoch: [ 5/ 5], Step: [ 419/ 600], Loss: 0.0246\n",
      "Epoch: [ 5/ 5], Step: [ 420/ 600], Loss: 0.0243\n",
      "Epoch: [ 5/ 5], Step: [ 421/ 600], Loss: 0.1324\n",
      "Epoch: [ 5/ 5], Step: [ 422/ 600], Loss: 0.0067\n",
      "Epoch: [ 5/ 5], Step: [ 423/ 600], Loss: 5.1056\n",
      "Epoch: [ 5/ 5], Step: [ 424/ 600], Loss: 1.2675\n",
      "Epoch: [ 5/ 5], Step: [ 425/ 600], Loss: 2.6843\n",
      "Epoch: [ 5/ 5], Step: [ 426/ 600], Loss: 0.0529\n",
      "Epoch: [ 5/ 5], Step: [ 427/ 600], Loss: 0.0071\n",
      "Epoch: [ 5/ 5], Step: [ 428/ 600], Loss: 0.8936\n",
      "Epoch: [ 5/ 5], Step: [ 429/ 600], Loss: 0.1534\n",
      "Epoch: [ 5/ 5], Step: [ 430/ 600], Loss: 0.0017\n",
      "Epoch: [ 5/ 5], Step: [ 431/ 600], Loss: 0.0079\n",
      "Epoch: [ 5/ 5], Step: [ 432/ 600], Loss: 0.0146\n",
      "Epoch: [ 5/ 5], Step: [ 433/ 600], Loss: 0.0011\n",
      "Epoch: [ 5/ 5], Step: [ 434/ 600], Loss: 2.6979\n",
      "Epoch: [ 5/ 5], Step: [ 435/ 600], Loss: 0.0323\n",
      "Epoch: [ 5/ 5], Step: [ 436/ 600], Loss: 0.0065\n",
      "Epoch: [ 5/ 5], Step: [ 437/ 600], Loss: 0.1082\n",
      "Epoch: [ 5/ 5], Step: [ 438/ 600], Loss: 0.0163\n",
      "Epoch: [ 5/ 5], Step: [ 439/ 600], Loss: 0.0109\n",
      "Epoch: [ 5/ 5], Step: [ 440/ 600], Loss: 0.2507\n",
      "Epoch: [ 5/ 5], Step: [ 441/ 600], Loss: 0.0205\n",
      "Epoch: [ 5/ 5], Step: [ 442/ 600], Loss: 0.4642\n",
      "Epoch: [ 5/ 5], Step: [ 443/ 600], Loss: 0.0812\n",
      "Epoch: [ 5/ 5], Step: [ 444/ 600], Loss: 0.0034\n",
      "Epoch: [ 5/ 5], Step: [ 445/ 600], Loss: 1.4817\n",
      "Epoch: [ 5/ 5], Step: [ 446/ 600], Loss: 1.4926\n",
      "Epoch: [ 5/ 5], Step: [ 447/ 600], Loss: 0.6748\n",
      "Epoch: [ 5/ 5], Step: [ 448/ 600], Loss: 0.6899\n",
      "Epoch: [ 5/ 5], Step: [ 449/ 600], Loss: 0.0984\n",
      "Epoch: [ 5/ 5], Step: [ 450/ 600], Loss: 0.1964\n",
      "Epoch: [ 5/ 5], Step: [ 451/ 600], Loss: 0.0195\n",
      "Epoch: [ 5/ 5], Step: [ 452/ 600], Loss: 0.0226\n",
      "Epoch: [ 5/ 5], Step: [ 453/ 600], Loss: 0.3756\n",
      "Epoch: [ 5/ 5], Step: [ 454/ 600], Loss: 0.3086\n",
      "Epoch: [ 5/ 5], Step: [ 455/ 600], Loss: 0.3682\n",
      "Epoch: [ 5/ 5], Step: [ 456/ 600], Loss: 0.1032\n",
      "Epoch: [ 5/ 5], Step: [ 457/ 600], Loss: 0.4963\n",
      "Epoch: [ 5/ 5], Step: [ 458/ 600], Loss: 0.4614\n",
      "Epoch: [ 5/ 5], Step: [ 459/ 600], Loss: 0.0024\n",
      "Epoch: [ 5/ 5], Step: [ 460/ 600], Loss: 0.0484\n",
      "Epoch: [ 5/ 5], Step: [ 461/ 600], Loss: 1.0781\n",
      "Epoch: [ 5/ 5], Step: [ 462/ 600], Loss: 0.1283\n",
      "Epoch: [ 5/ 5], Step: [ 463/ 600], Loss: 0.1019\n",
      "Epoch: [ 5/ 5], Step: [ 464/ 600], Loss: 0.1918\n",
      "Epoch: [ 5/ 5], Step: [ 465/ 600], Loss: 0.0321\n",
      "Epoch: [ 5/ 5], Step: [ 466/ 600], Loss: 0.0388\n",
      "Epoch: [ 5/ 5], Step: [ 467/ 600], Loss: 0.0002\n",
      "Epoch: [ 5/ 5], Step: [ 468/ 600], Loss: 1.2423\n",
      "Epoch: [ 5/ 5], Step: [ 469/ 600], Loss: 0.2136\n",
      "Epoch: [ 5/ 5], Step: [ 470/ 600], Loss: 0.0061\n",
      "Epoch: [ 5/ 5], Step: [ 471/ 600], Loss: 0.0012\n",
      "Epoch: [ 5/ 5], Step: [ 472/ 600], Loss: 0.0450\n",
      "Epoch: [ 5/ 5], Step: [ 473/ 600], Loss: 0.0191\n",
      "Epoch: [ 5/ 5], Step: [ 474/ 600], Loss: 0.0006\n",
      "Epoch: [ 5/ 5], Step: [ 475/ 600], Loss: 0.1610\n",
      "Epoch: [ 5/ 5], Step: [ 476/ 600], Loss: 0.0297\n",
      "Epoch: [ 5/ 5], Step: [ 477/ 600], Loss: 0.0254\n",
      "Epoch: [ 5/ 5], Step: [ 478/ 600], Loss: 0.1116\n",
      "Epoch: [ 5/ 5], Step: [ 479/ 600], Loss: 0.0396\n",
      "Epoch: [ 5/ 5], Step: [ 480/ 600], Loss: 0.0087\n",
      "Epoch: [ 5/ 5], Step: [ 481/ 600], Loss: 0.0924\n",
      "Epoch: [ 5/ 5], Step: [ 482/ 600], Loss: 0.4280\n",
      "Epoch: [ 5/ 5], Step: [ 483/ 600], Loss: 0.0747\n",
      "Epoch: [ 5/ 5], Step: [ 484/ 600], Loss: 1.0485\n",
      "Epoch: [ 5/ 5], Step: [ 485/ 600], Loss: 0.0087\n",
      "Epoch: [ 5/ 5], Step: [ 486/ 600], Loss: 1.4105\n",
      "Epoch: [ 5/ 5], Step: [ 487/ 600], Loss: 0.0439\n",
      "Epoch: [ 5/ 5], Step: [ 488/ 600], Loss: 0.0238\n",
      "Epoch: [ 5/ 5], Step: [ 489/ 600], Loss: 0.1174\n",
      "Epoch: [ 5/ 5], Step: [ 490/ 600], Loss: 0.0001\n",
      "Epoch: [ 5/ 5], Step: [ 491/ 600], Loss: 0.0039\n",
      "Epoch: [ 5/ 5], Step: [ 492/ 600], Loss: 0.0826\n",
      "Epoch: [ 5/ 5], Step: [ 493/ 600], Loss: 0.0863\n",
      "Epoch: [ 5/ 5], Step: [ 494/ 600], Loss: 0.0782\n",
      "Epoch: [ 5/ 5], Step: [ 495/ 600], Loss: 0.8294\n",
      "Epoch: [ 5/ 5], Step: [ 496/ 600], Loss: 0.0029\n",
      "Epoch: [ 5/ 5], Step: [ 497/ 600], Loss: 0.0116\n",
      "Epoch: [ 5/ 5], Step: [ 498/ 600], Loss: 0.2693\n",
      "Epoch: [ 5/ 5], Step: [ 499/ 600], Loss: 0.0045\n",
      "Epoch: [ 5/ 5], Step: [ 500/ 600], Loss: 0.0198\n",
      "Epoch: [ 5/ 5], Step: [ 501/ 600], Loss: 1.5622\n",
      "Epoch: [ 5/ 5], Step: [ 502/ 600], Loss: 0.0071\n",
      "Epoch: [ 5/ 5], Step: [ 503/ 600], Loss: 0.6584\n",
      "Epoch: [ 5/ 5], Step: [ 504/ 600], Loss: 0.0103\n",
      "Epoch: [ 5/ 5], Step: [ 505/ 600], Loss: 0.0228\n",
      "Epoch: [ 5/ 5], Step: [ 506/ 600], Loss: 0.2119\n",
      "Epoch: [ 5/ 5], Step: [ 507/ 600], Loss: 0.0328\n",
      "Epoch: [ 5/ 5], Step: [ 508/ 600], Loss: 0.0459\n",
      "Epoch: [ 5/ 5], Step: [ 509/ 600], Loss: 0.0039\n",
      "Epoch: [ 5/ 5], Step: [ 510/ 600], Loss: 0.0223\n",
      "Epoch: [ 5/ 5], Step: [ 511/ 600], Loss: 0.0944\n",
      "Epoch: [ 5/ 5], Step: [ 512/ 600], Loss: 0.0120\n",
      "Epoch: [ 5/ 5], Step: [ 513/ 600], Loss: 0.1701\n",
      "Epoch: [ 5/ 5], Step: [ 514/ 600], Loss: 0.0521\n",
      "Epoch: [ 5/ 5], Step: [ 515/ 600], Loss: 0.7202\n",
      "Epoch: [ 5/ 5], Step: [ 516/ 600], Loss: 0.0118\n",
      "Epoch: [ 5/ 5], Step: [ 517/ 600], Loss: 0.8928\n",
      "Epoch: [ 5/ 5], Step: [ 518/ 600], Loss: 0.0283\n",
      "Epoch: [ 5/ 5], Step: [ 519/ 600], Loss: 0.0920\n",
      "Epoch: [ 5/ 5], Step: [ 520/ 600], Loss: 0.0108\n",
      "Epoch: [ 5/ 5], Step: [ 521/ 600], Loss: 0.1478\n",
      "Epoch: [ 5/ 5], Step: [ 522/ 600], Loss: 0.1641\n",
      "Epoch: [ 5/ 5], Step: [ 523/ 600], Loss: 0.2651\n",
      "Epoch: [ 5/ 5], Step: [ 524/ 600], Loss: 0.0041\n",
      "Epoch: [ 5/ 5], Step: [ 525/ 600], Loss: 0.0277\n",
      "Epoch: [ 5/ 5], Step: [ 526/ 600], Loss: 0.0137\n",
      "Epoch: [ 5/ 5], Step: [ 527/ 600], Loss: 0.0678\n",
      "Epoch: [ 5/ 5], Step: [ 528/ 600], Loss: 0.0111\n",
      "Epoch: [ 5/ 5], Step: [ 529/ 600], Loss: 0.0066\n",
      "Epoch: [ 5/ 5], Step: [ 530/ 600], Loss: 0.0129\n",
      "Epoch: [ 5/ 5], Step: [ 531/ 600], Loss: 0.1972\n",
      "Epoch: [ 5/ 5], Step: [ 532/ 600], Loss: 0.0040\n",
      "Epoch: [ 5/ 5], Step: [ 533/ 600], Loss: 0.0003\n",
      "Epoch: [ 5/ 5], Step: [ 534/ 600], Loss: 0.0693\n",
      "Epoch: [ 5/ 5], Step: [ 535/ 600], Loss: 0.0307\n",
      "Epoch: [ 5/ 5], Step: [ 536/ 600], Loss: 0.4455\n",
      "Epoch: [ 5/ 5], Step: [ 537/ 600], Loss: 0.0378\n",
      "Epoch: [ 5/ 5], Step: [ 538/ 600], Loss: 0.0291\n",
      "Epoch: [ 5/ 5], Step: [ 539/ 600], Loss: 0.0546\n",
      "Epoch: [ 5/ 5], Step: [ 540/ 600], Loss: 0.7393\n",
      "Epoch: [ 5/ 5], Step: [ 541/ 600], Loss: 0.0853\n",
      "Epoch: [ 5/ 5], Step: [ 542/ 600], Loss: 0.0014\n",
      "Epoch: [ 5/ 5], Step: [ 543/ 600], Loss: 0.1119\n",
      "Epoch: [ 5/ 5], Step: [ 544/ 600], Loss: 0.0348\n",
      "Epoch: [ 5/ 5], Step: [ 545/ 600], Loss: 0.0409\n",
      "Epoch: [ 5/ 5], Step: [ 546/ 600], Loss: 0.0079\n",
      "Epoch: [ 5/ 5], Step: [ 547/ 600], Loss: 0.1702\n",
      "Epoch: [ 5/ 5], Step: [ 548/ 600], Loss: 0.0578\n",
      "Epoch: [ 5/ 5], Step: [ 549/ 600], Loss: 0.0068\n",
      "Epoch: [ 5/ 5], Step: [ 550/ 600], Loss: 0.9943\n",
      "Epoch: [ 5/ 5], Step: [ 551/ 600], Loss: 0.0133\n",
      "Epoch: [ 5/ 5], Step: [ 552/ 600], Loss: 0.0400\n",
      "Epoch: [ 5/ 5], Step: [ 553/ 600], Loss: 0.1121\n",
      "Epoch: [ 5/ 5], Step: [ 554/ 600], Loss: 0.1372\n",
      "Epoch: [ 5/ 5], Step: [ 555/ 600], Loss: 0.2372\n",
      "Epoch: [ 5/ 5], Step: [ 556/ 600], Loss: 0.1332\n",
      "Epoch: [ 5/ 5], Step: [ 557/ 600], Loss: 0.0290\n",
      "Epoch: [ 5/ 5], Step: [ 558/ 600], Loss: 0.0579\n",
      "Epoch: [ 5/ 5], Step: [ 559/ 600], Loss: 1.5062\n",
      "Epoch: [ 5/ 5], Step: [ 560/ 600], Loss: 0.0283\n",
      "Epoch: [ 5/ 5], Step: [ 561/ 600], Loss: 0.0234\n",
      "Epoch: [ 5/ 5], Step: [ 562/ 600], Loss: 0.2038\n",
      "Epoch: [ 5/ 5], Step: [ 563/ 600], Loss: 1.2218\n",
      "Epoch: [ 5/ 5], Step: [ 564/ 600], Loss: 0.1128\n",
      "Epoch: [ 5/ 5], Step: [ 565/ 600], Loss: 0.0040\n",
      "Epoch: [ 5/ 5], Step: [ 566/ 600], Loss: 0.0294\n",
      "Epoch: [ 5/ 5], Step: [ 567/ 600], Loss: 0.1565\n",
      "Epoch: [ 5/ 5], Step: [ 568/ 600], Loss: 0.0046\n",
      "Epoch: [ 5/ 5], Step: [ 569/ 600], Loss: 0.8396\n",
      "Epoch: [ 5/ 5], Step: [ 570/ 600], Loss: 0.0093\n",
      "Epoch: [ 5/ 5], Step: [ 571/ 600], Loss: 0.0784\n",
      "Epoch: [ 5/ 5], Step: [ 572/ 600], Loss: 0.0155\n",
      "Epoch: [ 5/ 5], Step: [ 573/ 600], Loss: 0.0207\n",
      "Epoch: [ 5/ 5], Step: [ 574/ 600], Loss: 0.0132\n",
      "Epoch: [ 5/ 5], Step: [ 575/ 600], Loss: 0.4531\n",
      "Epoch: [ 5/ 5], Step: [ 576/ 600], Loss: 0.0361\n",
      "Epoch: [ 5/ 5], Step: [ 577/ 600], Loss: 0.0206\n",
      "Epoch: [ 5/ 5], Step: [ 578/ 600], Loss: 0.0196\n",
      "Epoch: [ 5/ 5], Step: [ 579/ 600], Loss: 3.3376\n",
      "Epoch: [ 5/ 5], Step: [ 580/ 600], Loss: 0.0077\n",
      "Epoch: [ 5/ 5], Step: [ 581/ 600], Loss: 1.2435\n",
      "Epoch: [ 5/ 5], Step: [ 582/ 600], Loss: 3.9745\n",
      "Epoch: [ 5/ 5], Step: [ 583/ 600], Loss: 0.0627\n",
      "Epoch: [ 5/ 5], Step: [ 584/ 600], Loss: 0.0089\n",
      "Epoch: [ 5/ 5], Step: [ 585/ 600], Loss: 0.4697\n",
      "Epoch: [ 5/ 5], Step: [ 586/ 600], Loss: 0.0001\n",
      "Epoch: [ 5/ 5], Step: [ 587/ 600], Loss: 0.0542\n",
      "Epoch: [ 5/ 5], Step: [ 588/ 600], Loss: 0.0293\n",
      "Epoch: [ 5/ 5], Step: [ 589/ 600], Loss: 0.0034\n",
      "Epoch: [ 5/ 5], Step: [ 590/ 600], Loss: 0.0357\n",
      "Epoch: [ 5/ 5], Step: [ 591/ 600], Loss: 0.5892\n",
      "Epoch: [ 5/ 5], Step: [ 592/ 600], Loss: 0.0182\n",
      "Epoch: [ 5/ 5], Step: [ 593/ 600], Loss: 1.4008\n",
      "Epoch: [ 5/ 5], Step: [ 594/ 600], Loss: 0.0111\n",
      "Epoch: [ 5/ 5], Step: [ 595/ 600], Loss: 0.1204\n",
      "Epoch: [ 5/ 5], Step: [ 596/ 600], Loss: 0.0204\n",
      "Epoch: [ 5/ 5], Step: [ 597/ 600], Loss: 0.8723\n",
      "Epoch: [ 5/ 5], Step: [ 598/ 600], Loss: 0.1893\n",
      "Epoch: [ 5/ 5], Step: [ 599/ 600], Loss: 0.0084\n",
      "Epoch: [ 5/ 5], Step: [ 600/ 600], Loss: 0.5732\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Validate the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvEDm4McyPj8",
    "outputId": "af2c41ed-9508-4e96-cd95-22192763015c",
    "ExecuteTime": {
     "start_time": "2023-04-19T00:20:46.592509Z",
     "end_time": "2023-04-19T00:20:49.797126Z"
    }
   },
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28 * 28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the model on the 10000 test images: % d %%' % (\n",
    "        100 * correct / total))\n"
   ],
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images:  91 %\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The correct way to do it\n",
    "\n",
    "[Convolutional Neural Network](https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/MNIST.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
